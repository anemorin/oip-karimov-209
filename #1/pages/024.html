<!DOCTYPE html>
<html class="client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 skin-theme-clientpref-day vector-sticky-header-enabled wp25eastereggs-enable-clientpref-1 vector-toc-available" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<title>Naive Bayes classifier - Wikipedia</title>
<script>(function(){var className="client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-pinned-clientpref-1 skin-theme-clientpref-day vector-sticky-header-enabled wp25eastereggs-enable-clientpref-1 vector-toc-available";var cookie=document.cookie.match(/(?:^|; )enwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\w+$|[^\w-]+/g,'')+'-clientpref-\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={"wgBreakFrames":false,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"96d31464-d72d-45b3-b184-05c7d8068576","wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Naive_Bayes_classifier","wgTitle":"Naive Bayes classifier","wgCurRevisionId":1335953607,"wgRevisionId":1335953607,"wgArticleId":87339,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 maint: archived copy as title","All articles with dead external links","Articles with dead external links from February 2018","Articles with permanently dead external links","Webarchive template wayback links","Articles with short description","Short description is different from Wikidata","Spamming","Classification algorithms","Statistical classification","Bayesian statistics"],"wgPageViewLanguage":"en","wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Naive_Bayes_classifier","wgRelevantArticleId":87339,"wgTempUserName":null,"wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgNoticeProject":"wikipedia","wgFlaggedRevsParams":{"tags":{"status":{"levels":1}}},"wgConfirmEditCaptchaNeededForGenericEdit":"hcaptcha","wgConfirmEditHCaptchaVisualEditorOnLoadIntegrationEnabled":false,"wgConfirmEditHCaptchaSiteKey":"5d0c670e-a5f4-4258-ad16-1f42792c9c62","wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":true,"wgPopupsFlags":0,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":true,"watchlist":true,"tagline":false,"nearby":true},"wgWMESchemaEditAttemptStepOversample":false,"wgWMEPageLength":50000,"wgEditSubmitButtonLabelPublish":true,"wgVisualEditorPageIsDisambiguation":false,"wgULSPosition":"interlanguage","wgULSisCompactLinksEnabled":false,"wgVector2022LanguageInHeader":true,"wgULSisLanguageSelectorEmpty":false,"wgWikibaseItemId":"Q812530","wgCheckUserClientHintsHeadersJsApi":["brands","architecture","bitness","fullVersionList","mobile","model","platform","platformVersion"],"GEHomepageSuggestedEditsEnableTopics":true,"wgGESuggestedEditsTaskTypes":{"taskTypes":["copyedit","link-recommendation"],"unavailableTaskTypes":[]},"wgGETopicsMatchModeEnabled":false,"wgGELevelingUpEnabledForUser":false,"wgGEUseTestKitchenExtension":true,"wgMetricsPlatformUserExperiments":{"active_experiments":[],"overrides":[],"enrolled":[],"assigned":[],"subject_ids":[],"sampling_units":[],"coordinator":[]},"wgTestKitchenUserExperiments":{"active_experiments":[],"overrides":[],"enrolled":[],"assigned":[],"subject_ids":[],"sampling_units":[],"coordinator":[]}};
RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.wikimediamessages.styles":"ready","ext.cite.styles":"ready","ext.math.styles":"ready","skins.vector.search.codex.styles":"ready","skins.vector.styles":"ready","skins.vector.icons":"ready","jquery.makeCollapsible.styles":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","wikibase.client.init":"ready","ext.wikimediaBadges":"ready","ext.wp25EasterEggs.styles":"ready"};RLPAGEMODULES=["ext.parsermigration.survey","ext.cite.ux-enhancements","ext.math.polyfills","mediawiki.page.media","site","mediawiki.page.ready","jquery.makeCollapsible","mediawiki.toc","skins.vector.js","ext.centralNotice.geoIP","ext.centralNotice.startUp","ext.gadget.ReferenceTooltips","ext.gadget.switcher","ext.urlShortener.toolbar","ext.centralauth.centralautologin","mmv.bootstrap","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.echo.centralauth","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.cx.uls.quick.actions","wikibase.client.vector-2022","wikibase.databox.fromWikidata","ext.checkUser.clientHints","ext.quicksurveys.init","ext.growthExperiments.SuggestedEditSession","ext.xLab","ext.testKitchen","ext.wp25EasterEggs"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.impl(function(){return["user.options@12s5i",function($,jQuery,require,module){mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
}];});});</script>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cext.wikimediamessages.styles%7Cext.wp25EasterEggs.styles%7Cjquery.makeCollapsible.styles%7Cskins.vector.icons%2Cstyles%7Cskins.vector.search.codex.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector-2022">
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector-2022"></script>
<meta name="ResourceLoaderDynamicStyles" content="">
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector-2022">
<meta name="generator" content="MediaWiki 1.46.0-wmf.16">
<meta name="referrer" content="origin">
<meta name="referrer" content="origin-when-cross-origin">
<meta name="robots" content="max-image-preview:standard">
<meta name="format-detection" content="telephone=no">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/d/de/Naive_corral.png">
<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="961">
<meta name="viewport" content="width=1120">
<meta property="og:title" content="Naive Bayes classifier - Wikipedia">
<meta property="og:type" content="website">
<link rel="preconnect" href="//upload.wikimedia.org">
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit">
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png">
<link rel="icon" href="/static/favicon/wikipedia.ico">
<link rel="search" type="application/opensearchdescription+xml" href="/w/rest.php/v1/search" title="Wikipedia (en)">
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd">
<link rel="canonical" href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">
<link rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">
<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom">
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<link rel="dns-prefetch" href="auth.wikimedia.org">
</head>
<body class="skin--responsive skin-vector skin-vector-search-vue mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Naive_Bayes_classifier rootpage-Naive_Bayes_classifier skin-vector-2022 action-view">
<div id="mw-aria-live-region" class="mw-aria-live-region" aria-live="polite"></div><a class="mw-jump-link" href="#bodyContent">Jump to content</a>
<div class="vector-header-container">
	<header class="vector-header mw-header no-font-mode-scale">
		<div class="vector-header-start">
			<nav class="vector-main-menu-landmark" aria-label="Site">
				
<div id="vector-main-menu-dropdown" class="vector-dropdown vector-main-menu-dropdown vector-button-flush-left vector-button-flush-right"  title="Main menu" >
	<input type="checkbox" id="vector-main-menu-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-main-menu-dropdown" class="vector-dropdown-checkbox "  aria-label="Main menu"  >
	<label id="vector-main-menu-dropdown-label" for="vector-main-menu-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-menu mw-ui-icon-wikimedia-menu"></span>

<span class="vector-dropdown-label-text">Main menu</span>
	</label>
	<div class="vector-dropdown-content">


				<div id="vector-main-menu-unpinned-container" class="vector-unpinned-container">
		
<div id="vector-main-menu" class="vector-main-menu vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-main-menu-pinnable-header vector-pinnable-header-unpinned"
	data-feature-name="main-menu-pinned"
	data-pinnable-element-id="vector-main-menu"
	data-pinned-container-id="vector-main-menu-pinned-container"
	data-unpinned-container-id="vector-main-menu-unpinned-container"
>
	<div class="vector-pinnable-header-label">Main menu</div>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-main-menu.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-main-menu.unpin">hide</button>
</div>

	
<div id="p-navigation" class="vector-menu mw-portlet mw-portlet-navigation"  >
	<div class="vector-menu-heading">
		Navigation
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-mainpage-description" class="mw-list-item"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"><span>Main page</span></a></li><li id="n-contents" class="mw-list-item"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia"><span>Contents</span></a></li><li id="n-currentevents" class="mw-list-item"><a href="/wiki/Portal:Current_events" title="Articles related to current events"><span>Current events</span></a></li><li id="n-randompage" class="mw-list-item"><a href="/wiki/Special:Random" title="Visit a randomly selected article [x]" accesskey="x"><span>Random article</span></a></li><li id="n-aboutsite" class="mw-list-item"><a href="/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works"><span>About Wikipedia</span></a></li><li id="n-contactpage" class="mw-list-item"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia"><span>Contact us</span></a></li>
		</ul>
		
	</div>
</div>

	
<div id="p-interaction" class="vector-menu mw-portlet mw-portlet-interaction"  >
	<div class="vector-menu-heading">
		Contribute
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-help" class="mw-list-item"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia"><span>Help</span></a></li><li id="n-introduction" class="mw-list-item"><a href="/wiki/Help:Introduction" title="Learn how to edit Wikipedia"><span>Learn to edit</span></a></li><li id="n-portal" class="mw-list-item"><a href="/wiki/Wikipedia:Community_portal" title="The hub for editors"><span>Community portal</span></a></li><li id="n-recentchanges" class="mw-list-item"><a href="/wiki/Special:RecentChanges" title="A list of recent changes to Wikipedia [r]" accesskey="r"><span>Recent changes</span></a></li><li id="n-upload" class="mw-list-item"><a href="/wiki/Wikipedia:File_upload_wizard" title="Add images or other media for use on Wikipedia"><span>Upload file</span></a></li><li id="n-specialpages" class="mw-list-item"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q"><span>Special pages</span></a></li>
		</ul>
		
	</div>
</div>

</div>

				</div>

	</div>
</div>

		</nav>
			
<a href="/wiki/Main_Page" class="mw-logo">
	<img class="mw-logo-icon" src="/static/images/icons/enwiki-25.svg" alt="" aria-hidden="true" height="50" width="50">
	<span class="mw-logo-container skin-invert">
		<img class="mw-logo-wordmark" alt="Wikipedia" src="/static/images/mobile/copyright/wikipedia-wordmark-en-25.svg" style="width: 8.75em; height: 1.375em;">
		<img class="mw-logo-tagline" alt="The Free Encyclopedia" src="/static/images/mobile/copyright/wikipedia-tagline-en-25.svg" width="140" height="11" style="width: 8.75em; height: 0.6875em;">
	</span>
</a>

		</div>
		<div class="vector-header-end">
			
<div id="p-search" role="search" class="vector-search-box-vue  vector-search-box-collapses vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box">
	<a href="/wiki/Special:Search" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only search-toggle" title="Search Wikipedia [f]" accesskey="f"><span class="vector-icon mw-ui-icon-search mw-ui-icon-wikimedia-search"></span>

<span>Search</span>
	</a>
	<div class="vector-typeahead-search-container">
		<div class="cdx-typeahead-search cdx-typeahead-search--show-thumbnail cdx-typeahead-search--auto-expand-width">
			<form action="/w/index.php" id="searchform" class="cdx-search-input cdx-search-input--has-end-button">
				<div id="simpleSearch" class="cdx-search-input__input-wrapper"  data-search-loc="header-moved">
					<div class="cdx-text-input cdx-text-input--has-start-icon">
						<input
							class="cdx-text-input__input mw-searchInput" autocomplete="off"
							 type="search" name="search" placeholder="Search Wikipedia" aria-label="Search Wikipedia" autocapitalize="none" spellcheck="false" title="Search Wikipedia [f]" accesskey="f" id="searchInput"
							>
						<span class="cdx-text-input__icon cdx-text-input__start-icon"></span>
					</div>
					<input type="hidden" name="title" value="Special:Search">
				</div>
				<button class="cdx-button cdx-search-input__end-button">Search</button>
			</form>
		</div>
	</div>
</div>

			<nav class="vector-user-links vector-user-links-wide" aria-label="Personal tools">
	<div class="vector-user-links-main">
	
<div id="p-vector-user-menu-preferences" class="vector-menu mw-portlet emptyPortlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

	
<div id="p-vector-user-menu-userpage" class="vector-menu mw-portlet emptyPortlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

	<nav class="vector-appearance-landmark" aria-label="Appearance">
		
<div id="vector-appearance-dropdown" class="vector-dropdown "  title="Change the appearance of the page&#039;s font size, width, and color" >
	<input type="checkbox" id="vector-appearance-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-appearance-dropdown" class="vector-dropdown-checkbox "  aria-label="Appearance"  >
	<label id="vector-appearance-dropdown-label" for="vector-appearance-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-appearance mw-ui-icon-wikimedia-appearance"></span>

<span class="vector-dropdown-label-text">Appearance</span>
	</label>
	<div class="vector-dropdown-content">


			<div id="vector-appearance-unpinned-container" class="vector-unpinned-container">
				
			</div>
		
	</div>
</div>

	</nav>
	
<div id="p-vector-user-menu-notifications" class="vector-menu mw-portlet emptyPortlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

	
<div id="p-vector-user-menu-overflow" class="vector-menu mw-portlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			<li id="pt-sitesupport-2" class="user-links-collapsible-item mw-list-item user-links-collapsible-item"><a data-mw-interface  href="https://donate.wikimedia.org/?wmf_source=donate&amp;wmf_medium=sidebar&amp;wmf_campaign=en.wikipedia.org&amp;uselang=en" class=""><span>Donate</span></a>
</li>
<li id="pt-createaccount-2" class="user-links-collapsible-item mw-list-item user-links-collapsible-item"><a data-mw-interface  href="/w/index.php?title=Special:CreateAccount&amp;returnto=Naive+Bayes+classifier" title="You are encouraged to create an account and log in; however, it is not mandatory" class=""><span>Create account</span></a>
</li>
<li id="pt-login-2" class="user-links-collapsible-item mw-list-item user-links-collapsible-item"><a data-mw-interface  href="/w/index.php?title=Special:UserLogin&amp;returnto=Naive+Bayes+classifier" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o" class=""><span>Log in</span></a>
</li>

			
		</ul>
		
	</div>
</div>

	</div>
	
<div id="vector-user-links-dropdown" class="vector-dropdown vector-user-menu vector-button-flush-right vector-user-menu-logged-out user-links-collapsible-item"  title="Log in and more options" >
	<input type="checkbox" id="vector-user-links-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-user-links-dropdown" class="vector-dropdown-checkbox "  aria-label="Personal tools"  >
	<label id="vector-user-links-dropdown-label" for="vector-user-links-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-ellipsis mw-ui-icon-wikimedia-ellipsis"></span>

<span class="vector-dropdown-label-text">Personal tools</span>
	</label>
	<div class="vector-dropdown-content">


		
<div id="p-personal" class="vector-menu mw-portlet mw-portlet-personal user-links-collapsible-item"  title="User menu" >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="pt-sitesupport" class="user-links-collapsible-item mw-list-item"><a href="https://donate.wikimedia.org/?wmf_source=donate&amp;wmf_medium=sidebar&amp;wmf_campaign=en.wikipedia.org&amp;uselang=en"><span>Donate</span></a></li><li id="pt-createaccount" class="user-links-collapsible-item mw-list-item"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Naive+Bayes+classifier" title="You are encouraged to create an account and log in; however, it is not mandatory"><span class="vector-icon mw-ui-icon-userAdd mw-ui-icon-wikimedia-userAdd"></span> <span>Create account</span></a></li><li id="pt-login" class="user-links-collapsible-item mw-list-item"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Naive+Bayes+classifier" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o"><span class="vector-icon mw-ui-icon-logIn mw-ui-icon-wikimedia-logIn"></span> <span>Log in</span></a></li>
		</ul>
		
	</div>
</div>

	
	</div>
</div>

</nav>

		</div>
	</header>
</div>
<div class="mw-page-container">
	<div class="mw-page-container-inner">
		<div class="vector-sitenotice-container">
			<div id="siteNotice"><!-- CentralNotice --><div class="wp25eastereggs-sitenotice"><div class="wp25eastereggs-sitenotice-landmark"></div></div></div>
		</div>
		<div class="vector-column-start">
			<div class="vector-main-menu-container">
		<div id="mw-navigation">
			<nav id="mw-panel" class="vector-main-menu-landmark" aria-label="Site">
				<div id="vector-main-menu-pinned-container" class="vector-pinned-container">
				
				</div>
		</nav>
		</div>
	</div>
	<div class="vector-sticky-pinned-container">
				<nav id="mw-panel-toc" aria-label="Contents" data-event-name="ui.sidebar-toc" class="mw-table-of-contents-container vector-toc-landmark">
					<div id="vector-toc-pinned-container" class="vector-pinned-container">
					<div id="vector-toc" class="vector-toc vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-toc-pinnable-header vector-pinnable-header-pinned"
	data-feature-name="toc-pinned"
	data-pinnable-element-id="vector-toc"
	
	
>
	<h2 class="vector-pinnable-header-label">Contents</h2>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-toc.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-toc.unpin">hide</button>
</div>


	<ul class="vector-toc-contents" id="mw-panel-toc-list">
		<li id="toc-mw-content-text"
			class="vector-toc-list-item vector-toc-level-1">
			<a href="#" class="vector-toc-link">
				<div class="vector-toc-text">(Top)</div>
			</a>
		</li>
		<li id="toc-Introduction"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Introduction">
			<div class="vector-toc-text">
				<span class="vector-toc-numb">1</span>
				<span>Introduction</span>
			</div>
		</a>
		
		<ul id="toc-Introduction-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Probabilistic_model"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Probabilistic_model">
			<div class="vector-toc-text">
				<span class="vector-toc-numb">2</span>
				<span>Probabilistic model</span>
			</div>
		</a>
		
			<button aria-controls="toc-Probabilistic_model-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Probabilistic model subsection</span>
			</button>
		
		<ul id="toc-Probabilistic_model-sublist" class="vector-toc-list">
			<li id="toc-Constructing_a_classifier_from_the_probability_model"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Constructing_a_classifier_from_the_probability_model">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">2.1</span>
					<span>Constructing a classifier from the probability model</span>
				</div>
			</a>
			
			<ul id="toc-Constructing_a_classifier_from_the_probability_model-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Parameter_estimation_and_event_models"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Parameter_estimation_and_event_models">
			<div class="vector-toc-text">
				<span class="vector-toc-numb">3</span>
				<span>Parameter estimation and event models</span>
			</div>
		</a>
		
			<button aria-controls="toc-Parameter_estimation_and_event_models-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Parameter estimation and event models subsection</span>
			</button>
		
		<ul id="toc-Parameter_estimation_and_event_models-sublist" class="vector-toc-list">
			<li id="toc-Gaussian_naive_Bayes"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Gaussian_naive_Bayes">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">3.1</span>
					<span>Gaussian naive Bayes</span>
				</div>
			</a>
			
			<ul id="toc-Gaussian_naive_Bayes-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Multinomial_naive_Bayes"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Multinomial_naive_Bayes">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">3.2</span>
					<span>Multinomial naive Bayes</span>
				</div>
			</a>
			
			<ul id="toc-Multinomial_naive_Bayes-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Bernoulli_naive_Bayes"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Bernoulli_naive_Bayes">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">3.3</span>
					<span>Bernoulli naive Bayes</span>
				</div>
			</a>
			
			<ul id="toc-Bernoulli_naive_Bayes-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Semi-supervised_parameter_estimation"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Semi-supervised_parameter_estimation">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">3.4</span>
					<span>Semi-supervised parameter estimation</span>
				</div>
			</a>
			
			<ul id="toc-Semi-supervised_parameter_estimation-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Discussion"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Discussion">
			<div class="vector-toc-text">
				<span class="vector-toc-numb">4</span>
				<span>Discussion</span>
			</div>
		</a>
		
			<button aria-controls="toc-Discussion-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Discussion subsection</span>
			</button>
		
		<ul id="toc-Discussion-sublist" class="vector-toc-list">
			<li id="toc-Relation_to_logistic_regression"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Relation_to_logistic_regression">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">4.1</span>
					<span>Relation to logistic regression</span>
				</div>
			</a>
			
			<ul id="toc-Relation_to_logistic_regression-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Examples"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Examples">
			<div class="vector-toc-text">
				<span class="vector-toc-numb">5</span>
				<span>Examples</span>
			</div>
		</a>
		
			<button aria-controls="toc-Examples-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Examples subsection</span>
			</button>
		
		<ul id="toc-Examples-sublist" class="vector-toc-list">
			<li id="toc-Person_classification"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Person_classification">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">5.1</span>
					<span>Person classification</span>
				</div>
			</a>
			
			<ul id="toc-Person_classification-sublist" class="vector-toc-list">
				<li id="toc-Training"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Training">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">5.1.1</span>
					<span>Training</span>
				</div>
			</a>
			
			<ul id="toc-Training-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Testing"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Testing">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">5.1.2</span>
					<span>Testing</span>
				</div>
			</a>
			
			<ul id="toc-Testing-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Document_classification"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Document_classification">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">5.2</span>
					<span>Document classification</span>
				</div>
			</a>
			
			<ul id="toc-Document_classification-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Spam_filtering"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Spam_filtering">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">5.3</span>
					<span>Spam filtering</span>
				</div>
			</a>
			
			<ul id="toc-Spam_filtering-sublist" class="vector-toc-list">
				<li id="toc-Dealing_with_rare_words"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Dealing_with_rare_words">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">5.3.1</span>
					<span>Dealing with rare words</span>
				</div>
			</a>
			
			<ul id="toc-Dealing_with_rare_words-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Other_heuristics"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Other_heuristics">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">5.3.2</span>
					<span>Other heuristics</span>
				</div>
			</a>
			
			<ul id="toc-Other_heuristics-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Disadvantages"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Disadvantages">
				<div class="vector-toc-text">
					<span class="vector-toc-numb">5.3.3</span>
					<span>Disadvantages</span>
				</div>
			</a>
			
			<ul id="toc-Disadvantages-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
	</ul>
	</li>
	<li id="toc-See_also"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#See_also">
			<div class="vector-toc-text">
				<span class="vector-toc-numb">6</span>
				<span>See also</span>
			</div>
		</a>
		
		<ul id="toc-See_also-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-References"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#References">
			<div class="vector-toc-text">
				<span class="vector-toc-numb">7</span>
				<span>References</span>
			</div>
		</a>
		
		<ul id="toc-References-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Further_reading"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#Further_reading">
			<div class="vector-toc-text">
				<span class="vector-toc-numb">8</span>
				<span>Further reading</span>
			</div>
		</a>
		
		<ul id="toc-Further_reading-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-External_links"
		class="vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded">
		<a class="vector-toc-link" href="#External_links">
			<div class="vector-toc-text">
				<span class="vector-toc-numb">9</span>
				<span>External links</span>
			</div>
		</a>
		
		<ul id="toc-External_links-sublist" class="vector-toc-list">
		</ul>
	</li>
</ul>
</div>

					</div>
		</nav>
			</div>
		</div>
		<div class="mw-content-container">
			<main id="content" class="mw-body">
				<header class="mw-body-header vector-page-titlebar no-font-mode-scale">
					<nav aria-label="Contents" class="vector-toc-landmark">
						
<div id="vector-page-titlebar-toc" class="vector-dropdown vector-page-titlebar-toc vector-button-flush-left"  title="Table of Contents" >
	<input type="checkbox" id="vector-page-titlebar-toc-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-page-titlebar-toc" class="vector-dropdown-checkbox "  aria-label="Toggle the table of contents"  >
	<label id="vector-page-titlebar-toc-label" for="vector-page-titlebar-toc-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-listBullet mw-ui-icon-wikimedia-listBullet"></span>

<span class="vector-dropdown-label-text">Toggle the table of contents</span>
	</label>
	<div class="vector-dropdown-content">


							<div id="vector-page-titlebar-toc-unpinned-container" class="vector-unpinned-container">
			</div>
		
	</div>
</div>

					</nav>
					<h1 id="firstHeading" class="firstHeading mw-first-heading"><span class="mw-page-title-main">Naive Bayes classifier</span></h1>
							
<div id="p-lang-btn" class="vector-dropdown mw-portlet mw-portlet-lang"  >
	<input type="checkbox" id="p-lang-btn-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-p-lang-btn" class="vector-dropdown-checkbox mw-interlanguage-selector" aria-label="Go to an article in another language. Available in 24 languages"   >
	<label id="p-lang-btn-label" for="p-lang-btn-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--action-progressive mw-portlet-lang-heading-24" aria-hidden="true"  ><span class="vector-icon mw-ui-icon-language-progressive mw-ui-icon-wikimedia-language-progressive"></span>

<span class="vector-dropdown-label-text">24 languages</span>
	</label>
	<div class="vector-dropdown-content">

		<div class="vector-menu-content">
			
			<ul class="vector-menu-content-list">
				
				<li class="interlanguage-link interwiki-ar mw-list-item"><a href="https://ar.wikipedia.org/wiki/%D8%A7%D9%84%D9%85%D8%B5%D9%86%D9%81_%D8%A8%D8%A7%D9%8A%D8%B2_%D8%B3%D8%A7%D8%B0%D8%AC" title="المصنف بايز ساذج – Arabic" lang="ar" hreflang="ar" data-title="المصنف بايز ساذج" data-language-autonym="العربية" data-language-local-name="Arabic" class="interlanguage-link-target"><span>العربية</span></a></li><li class="interlanguage-link interwiki-ca mw-list-item"><a href="https://ca.wikipedia.org/wiki/Classificador_Bayes_primari" title="Classificador Bayes primari – Catalan" lang="ca" hreflang="ca" data-title="Classificador Bayes primari" data-language-autonym="Català" data-language-local-name="Catalan" class="interlanguage-link-target"><span>Català</span></a></li><li class="interlanguage-link interwiki-ckb mw-list-item"><a href="https://ckb.wikipedia.org/wiki/%D9%BE%DB%86%D9%84%DB%8E%D9%86%DA%A9%DB%95%D8%B1%DB%8C_%D8%A8%DB%95%DB%8C%D8%B2%DB%8C_%D8%B3%D8%A7%D9%88%DB%8C%D9%84%DA%A9%DB%95" title="پۆلێنکەری بەیزی ساویلکە – Central Kurdish" lang="ckb" hreflang="ckb" data-title="پۆلێنکەری بەیزی ساویلکە" data-language-autonym="کوردی" data-language-local-name="Central Kurdish" class="interlanguage-link-target"><span>کوردی</span></a></li><li class="interlanguage-link interwiki-da mw-list-item"><a href="https://da.wikipedia.org/wiki/Naiv_Bayes_klassifikator" title="Naiv Bayes klassifikator – Danish" lang="da" hreflang="da" data-title="Naiv Bayes klassifikator" data-language-autonym="Dansk" data-language-local-name="Danish" class="interlanguage-link-target"><span>Dansk</span></a></li><li class="interlanguage-link interwiki-de badge-Q70894304 mw-list-item" title=""><a href="https://de.wikipedia.org/wiki/Naiver_Bayes-Klassifikator" title="Naiver Bayes-Klassifikator – German" lang="de" hreflang="de" data-title="Naiver Bayes-Klassifikator" data-language-autonym="Deutsch" data-language-local-name="German" class="interlanguage-link-target"><span>Deutsch</span></a></li><li class="interlanguage-link interwiki-es mw-list-item"><a href="https://es.wikipedia.org/wiki/Clasificador_bayesiano_ingenuo" title="Clasificador bayesiano ingenuo – Spanish" lang="es" hreflang="es" data-title="Clasificador bayesiano ingenuo" data-language-autonym="Español" data-language-local-name="Spanish" class="interlanguage-link-target"><span>Español</span></a></li><li class="interlanguage-link interwiki-eu mw-list-item"><a href="https://eu.wikipedia.org/wiki/Naive_Bayes_sailkatzaile" title="Naive Bayes sailkatzaile – Basque" lang="eu" hreflang="eu" data-title="Naive Bayes sailkatzaile" data-language-autonym="Euskara" data-language-local-name="Basque" class="interlanguage-link-target"><span>Euskara</span></a></li><li class="interlanguage-link interwiki-fa mw-list-item"><a href="https://fa.wikipedia.org/wiki/%D8%AF%D8%B3%D8%AA%D9%87%E2%80%8C%D8%A8%D9%86%D8%AF%DB%8C%E2%80%8C%DA%A9%D9%86%D9%86%D8%AF%D9%87_%D8%A8%DB%8C%D8%B2_%D8%B3%D8%A7%D8%AF%D9%87" title="دسته‌بندی‌کننده بیز ساده – Persian" lang="fa" hreflang="fa" data-title="دسته‌بندی‌کننده بیز ساده" data-language-autonym="فارسی" data-language-local-name="Persian" class="interlanguage-link-target"><span>فارسی</span></a></li><li class="interlanguage-link interwiki-fr mw-list-item"><a href="https://fr.wikipedia.org/wiki/Classification_na%C3%AFve_bay%C3%A9sienne" title="Classification naïve bayésienne – French" lang="fr" hreflang="fr" data-title="Classification naïve bayésienne" data-language-autonym="Français" data-language-local-name="French" class="interlanguage-link-target"><span>Français</span></a></li><li class="interlanguage-link interwiki-he mw-list-item"><a href="https://he.wikipedia.org/wiki/%D7%A1%D7%99%D7%95%D7%95%D7%92_%D7%91%D7%99%D7%99%D7%A1%D7%99%D7%90%D7%A0%D7%99_%D7%A0%D7%90%D7%99%D7%91%D7%99" title="סיווג בייסיאני נאיבי – Hebrew" lang="he" hreflang="he" data-title="סיווג בייסיאני נאיבי" data-language-autonym="עברית" data-language-local-name="Hebrew" class="interlanguage-link-target"><span>עברית</span></a></li><li class="interlanguage-link interwiki-id mw-list-item"><a href="https://id.wikipedia.org/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier – Indonesian" lang="id" hreflang="id" data-title="Naive Bayes classifier" data-language-autonym="Bahasa Indonesia" data-language-local-name="Indonesian" class="interlanguage-link-target"><span>Bahasa Indonesia</span></a></li><li class="interlanguage-link interwiki-ja mw-list-item"><a href="https://ja.wikipedia.org/wiki/%E5%8D%98%E7%B4%94%E3%83%99%E3%82%A4%E3%82%BA%E5%88%86%E9%A1%9E%E5%99%A8" title="単純ベイズ分類器 – Japanese" lang="ja" hreflang="ja" data-title="単純ベイズ分類器" data-language-autonym="日本語" data-language-local-name="Japanese" class="interlanguage-link-target"><span>日本語</span></a></li><li class="interlanguage-link interwiki-ko mw-list-item"><a href="https://ko.wikipedia.org/wiki/%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A6%88_%EB%B6%84%EB%A5%98" title="나이브 베이즈 분류 – Korean" lang="ko" hreflang="ko" data-title="나이브 베이즈 분류" data-language-autonym="한국어" data-language-local-name="Korean" class="interlanguage-link-target"><span>한국어</span></a></li><li class="interlanguage-link interwiki-mk mw-list-item"><a href="https://mk.wikipedia.org/wiki/%D0%9D%D0%B0%D0%B8%D0%B2%D0%B5%D0%BD_%D0%91%D0%B0%D0%B5%D1%81%D0%BE%D0%B2_%D0%BA%D0%BB%D0%B0%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80" title="Наивен Баесов класификатор – Macedonian" lang="mk" hreflang="mk" data-title="Наивен Баесов класификатор" data-language-autonym="Македонски" data-language-local-name="Macedonian" class="interlanguage-link-target"><span>Македонски</span></a></li><li class="interlanguage-link interwiki-pl mw-list-item"><a href="https://pl.wikipedia.org/wiki/Naiwny_klasyfikator_bayesowski" title="Naiwny klasyfikator bayesowski – Polish" lang="pl" hreflang="pl" data-title="Naiwny klasyfikator bayesowski" data-language-autonym="Polski" data-language-local-name="Polish" class="interlanguage-link-target"><span>Polski</span></a></li><li class="interlanguage-link interwiki-pt mw-list-item"><a href="https://pt.wikipedia.org/wiki/Naive_Bayes" title="Naive Bayes – Portuguese" lang="pt" hreflang="pt" data-title="Naive Bayes" data-language-autonym="Português" data-language-local-name="Portuguese" class="interlanguage-link-target"><span>Português</span></a></li><li class="interlanguage-link interwiki-ro mw-list-item"><a href="https://ro.wikipedia.org/wiki/Clasificator_bayesian_naiv" title="Clasificator bayesian naiv – Romanian" lang="ro" hreflang="ro" data-title="Clasificator bayesian naiv" data-language-autonym="Română" data-language-local-name="Romanian" class="interlanguage-link-target"><span>Română</span></a></li><li class="interlanguage-link interwiki-ru mw-list-item"><a href="https://ru.wikipedia.org/wiki/%D0%9D%D0%B0%D0%B8%D0%B2%D0%BD%D1%8B%D0%B9_%D0%B1%D0%B0%D0%B9%D0%B5%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B9_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80" title="Наивный байесовский классификатор – Russian" lang="ru" hreflang="ru" data-title="Наивный байесовский классификатор" data-language-autonym="Русский" data-language-local-name="Russian" class="interlanguage-link-target"><span>Русский</span></a></li><li class="interlanguage-link interwiki-sr mw-list-item"><a href="https://sr.wikipedia.org/wiki/Naivni_Bajesov_klasifikator" title="Naivni Bajesov klasifikator – Serbian" lang="sr" hreflang="sr" data-title="Naivni Bajesov klasifikator" data-language-autonym="Српски / srpski" data-language-local-name="Serbian" class="interlanguage-link-target"><span>Српски / srpski</span></a></li><li class="interlanguage-link interwiki-su mw-list-item"><a href="https://su.wikipedia.org/wiki/Klasifikasi_naif_Bay%C3%A9sian" title="Klasifikasi naif Bayésian – Sundanese" lang="su" hreflang="su" data-title="Klasifikasi naif Bayésian" data-language-autonym="Sunda" data-language-local-name="Sundanese" class="interlanguage-link-target"><span>Sunda</span></a></li><li class="interlanguage-link interwiki-sv mw-list-item"><a href="https://sv.wikipedia.org/wiki/Naiv_bayesiansk_klassificerare" title="Naiv bayesiansk klassificerare – Swedish" lang="sv" hreflang="sv" data-title="Naiv bayesiansk klassificerare" data-language-autonym="Svenska" data-language-local-name="Swedish" class="interlanguage-link-target"><span>Svenska</span></a></li><li class="interlanguage-link interwiki-tr mw-list-item"><a href="https://tr.wikipedia.org/wiki/Naive_Bayes_s%C4%B1n%C4%B1fland%C4%B1r%C4%B1c%C4%B1s%C4%B1" title="Naive Bayes sınıflandırıcısı – Turkish" lang="tr" hreflang="tr" data-title="Naive Bayes sınıflandırıcısı" data-language-autonym="Türkçe" data-language-local-name="Turkish" class="interlanguage-link-target"><span>Türkçe</span></a></li><li class="interlanguage-link interwiki-uk mw-list-item"><a href="https://uk.wikipedia.org/wiki/%D0%9D%D0%B0%D1%97%D0%B2%D0%BD%D0%B8%D0%B9_%D0%B1%D0%B0%D1%94%D1%81%D1%96%D0%B2_%D0%BA%D0%BB%D0%B0%D1%81%D0%B8%D1%84%D1%96%D0%BA%D0%B0%D1%82%D0%BE%D1%80" title="Наївний баєсів класифікатор – Ukrainian" lang="uk" hreflang="uk" data-title="Наївний баєсів класифікатор" data-language-autonym="Українська" data-language-local-name="Ukrainian" class="interlanguage-link-target"><span>Українська</span></a></li><li class="interlanguage-link interwiki-zh mw-list-item"><a href="https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8" title="朴素贝叶斯分类器 – Chinese" lang="zh" hreflang="zh" data-title="朴素贝叶斯分类器" data-language-autonym="中文" data-language-local-name="Chinese" class="interlanguage-link-target"><span>中文</span></a></li>
			</ul>
			<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q812530#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>
		</div>

	</div>
</div>
</header>
				<div class="vector-page-toolbar vector-feature-custom-font-size-clientpref--excluded">
					<div class="vector-page-toolbar-container">
						<div id="left-navigation">
							<nav aria-label="Namespaces">
								
<div id="p-associated-pages" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-associated-pages"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-nstab-main" class="selected vector-tab-noicon mw-list-item"><a href="/wiki/Naive_Bayes_classifier" title="View the content page [c]" accesskey="c"><span>Article</span></a></li><li id="ca-talk" class="vector-tab-noicon mw-list-item"><a href="/wiki/Talk:Naive_Bayes_classifier" rel="discussion" title="Discuss improvements to the content page [t]" accesskey="t"><span>Talk</span></a></li>
		</ul>
		
	</div>
</div>

								
<div id="vector-variants-dropdown" class="vector-dropdown emptyPortlet"  >
	<input type="checkbox" id="vector-variants-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-variants-dropdown" class="vector-dropdown-checkbox " aria-label="Change language variant"   >
	<label id="vector-variants-dropdown-label" for="vector-variants-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet" aria-hidden="true"  ><span class="vector-dropdown-label-text">English</span>
	</label>
	<div class="vector-dropdown-content">


					
<div id="p-variants" class="vector-menu mw-portlet mw-portlet-variants emptyPortlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

				
	</div>
</div>

							</nav>
						</div>
						<div id="right-navigation" class="vector-collapsible">
							<nav aria-label="Views">
								
<div id="p-views" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-views"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-view" class="selected vector-tab-noicon mw-list-item"><a href="/wiki/Naive_Bayes_classifier"><span>Read</span></a></li><li id="ca-edit" class="vector-tab-noicon mw-list-item"><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit" title="Edit this page [e]" accesskey="e"><span>Edit</span></a></li><li id="ca-history" class="vector-tab-noicon mw-list-item"><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=history" title="Past revisions of this page [h]" accesskey="h"><span>View history</span></a></li>
		</ul>
		
	</div>
</div>

							</nav>
				
							<nav class="vector-page-tools-landmark" aria-label="Page tools">
								
<div id="vector-page-tools-dropdown" class="vector-dropdown vector-page-tools-dropdown"  >
	<input type="checkbox" id="vector-page-tools-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-page-tools-dropdown" class="vector-dropdown-checkbox "  aria-label="Tools"  >
	<label id="vector-page-tools-dropdown-label" for="vector-page-tools-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet" aria-hidden="true"  ><span class="vector-dropdown-label-text">Tools</span>
	</label>
	<div class="vector-dropdown-content">


									<div id="vector-page-tools-unpinned-container" class="vector-unpinned-container">
						
<div id="vector-page-tools" class="vector-page-tools vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-page-tools-pinnable-header vector-pinnable-header-unpinned"
	data-feature-name="page-tools-pinned"
	data-pinnable-element-id="vector-page-tools"
	data-pinned-container-id="vector-page-tools-pinned-container"
	data-unpinned-container-id="vector-page-tools-unpinned-container"
>
	<div class="vector-pinnable-header-label">Tools</div>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-page-tools.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-page-tools.unpin">hide</button>
</div>

	
<div id="p-cactions" class="vector-menu mw-portlet mw-portlet-cactions emptyPortlet vector-has-collapsible-items"  title="More options" >
	<div class="vector-menu-heading">
		Actions
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-more-view" class="selected vector-more-collapsible-item mw-list-item"><a href="/wiki/Naive_Bayes_classifier"><span>Read</span></a></li><li id="ca-more-edit" class="vector-more-collapsible-item mw-list-item"><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit" title="Edit this page [e]" accesskey="e"><span>Edit</span></a></li><li id="ca-more-history" class="vector-more-collapsible-item mw-list-item"><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=history"><span>View history</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-tb" class="vector-menu mw-portlet mw-portlet-tb"  >
	<div class="vector-menu-heading">
		General
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="t-whatlinkshere" class="mw-list-item"><a href="/wiki/Special:WhatLinksHere/Naive_Bayes_classifier" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j"><span>What links here</span></a></li><li id="t-recentchangeslinked" class="mw-list-item"><a href="/wiki/Special:RecentChangesLinked/Naive_Bayes_classifier" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k"><span>Related changes</span></a></li><li id="t-upload" class="mw-list-item"><a href="//en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u"><span>Upload file</span></a></li><li id="t-permalink" class="mw-list-item"><a href="/w/index.php?title=Naive_Bayes_classifier&amp;oldid=1335953607" title="Permanent link to this revision of this page"><span>Permanent link</span></a></li><li id="t-info" class="mw-list-item"><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=info" title="More information about this page"><span>Page information</span></a></li><li id="t-cite" class="mw-list-item"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Naive_Bayes_classifier&amp;id=1335953607&amp;wpFormIdentifier=titleform" title="Information on how to cite this page"><span>Cite this page</span></a></li><li id="t-urlshortener" class="mw-list-item"><a href="/w/index.php?title=Special:UrlShortener&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FNaive_Bayes_classifier"><span>Get shortened URL</span></a></li><li id="t-urlshortener-qrcode" class="mw-list-item"><a href="/w/index.php?title=Special:QrCode&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FNaive_Bayes_classifier"><span>Download QR code</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-coll-print_export" class="vector-menu mw-portlet mw-portlet-coll-print_export"  >
	<div class="vector-menu-heading">
		Print/export
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="coll-download-as-rl" class="mw-list-item"><a href="/w/index.php?title=Special:DownloadAsPdf&amp;page=Naive_Bayes_classifier&amp;action=show-download-screen" title="Download this page as a PDF file"><span>Download as PDF</span></a></li><li id="t-print" class="mw-list-item"><a href="/w/index.php?title=Naive_Bayes_classifier&amp;printable=yes" title="Printable version of this page [p]" accesskey="p"><span>Printable version</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-wikibase-otherprojects" class="vector-menu mw-portlet mw-portlet-wikibase-otherprojects"  >
	<div class="vector-menu-heading">
		In other projects
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="t-wikibase" class="wb-otherproject-link wb-otherproject-wikibase-dataitem mw-list-item"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q812530" title="Structured data on this page hosted by Wikidata [g]" accesskey="g"><span>Wikidata item</span></a></li>
		</ul>
		
	</div>
</div>

</div>

									</div>
				
	</div>
</div>

							</nav>
						</div>
					</div>
				</div>
				<div class="vector-column-end no-font-mode-scale">
					<div class="vector-sticky-pinned-container">
						<div class="wp25eastereggs-vector-sitenotice-landmark"></div>
						<nav class="vector-page-tools-landmark" aria-label="Page tools">
							<div id="vector-page-tools-pinned-container" class="vector-pinned-container">
				
							</div>
		</nav>
						<nav class="vector-appearance-landmark" aria-label="Appearance">
							<div id="vector-appearance-pinned-container" class="vector-pinned-container">
				<div id="vector-appearance" class="vector-appearance vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-appearance-pinnable-header vector-pinnable-header-pinned"
	data-feature-name="appearance-pinned"
	data-pinnable-element-id="vector-appearance"
	data-pinned-container-id="vector-appearance-pinned-container"
	data-unpinned-container-id="vector-appearance-unpinned-container"
>
	<div class="vector-pinnable-header-label">Appearance</div>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-appearance.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-appearance.unpin">hide</button>
</div>


</div>

							</div>
		</nav>
					</div>
				</div>
				<div id="bodyContent" class="vector-body" aria-labelledby="firstHeading" data-mw-ve-target-container>
					<div class="vector-body-before-content">
							<div class="mw-indicators">
		</div>

						<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
					</div>
					<div id="contentSub"><div id="mw-content-subtitle"></div></div>
					
					
					<div id="mw-content-text" class="mw-body-content"><div class="mw-subjectpageheader">
</div><div class="mw-content-ltr mw-parser-output" lang="en" dir="ltr"><div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">Probabilistic classification algorithm</div>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="/wiki/File:Naive_corral.png" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/d/de/Naive_corral.png/250px-Naive_corral.png" decoding="async" width="250" height="200" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/d/de/Naive_corral.png/500px-Naive_corral.png 1.5x" data-file-width="647" data-file-height="518" /></a><figcaption>Example of a naive Bayes classifier depicted as a Bayesian Network</figcaption></figure>
<p>In <a href="/wiki/Statistics" title="Statistics">statistics</a>, <b>naive</b> (sometimes <b>simple</b> or <b>idiot's</b>) <b>Bayes classifiers</b> are a family of "<a href="/wiki/Probabilistic_classification" title="Probabilistic classification">probabilistic classifiers</a>" which assumes that the features are conditionally independent, given the target class.<sup id="cite&#95;ref-idiots&#95;1-0" class="reference"><a href="#cite_note-idiots-1"><span class="cite-bracket">&#91;</span>1<span class="cite-bracket">&#93;</span></a></sup> In other words, a naive Bayes model assumes the information about the class provided by each variable is unrelated to the information from the others, with no information shared between the predictors. The highly unrealistic nature of this assumption, called the <b>naive independence assumption</b>, is what gives the classifier its name. These classifiers are some of the simplest <a href="/wiki/Bayesian_network" title="Bayesian network">Bayesian network</a> models.<sup id="cite&#95;ref-2" class="reference"><a href="#cite_note-2"><span class="cite-bracket">&#91;</span>2<span class="cite-bracket">&#93;</span></a></sup>
</p><p>Naive Bayes classifiers generally perform worse than more advanced models like <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regressions</a>, especially at <a href="/wiki/Uncertainty_quantification" title="Uncertainty quantification">quantifying uncertainty</a> (with naive Bayes models often producing wildly overconfident probabilities). However, they are highly scalable, requiring only one parameter for each feature or predictor in a learning problem. <a href="/wiki/Maximum-likelihood_estimation" class="mw-redirect" title="Maximum-likelihood estimation">Maximum-likelihood</a> training can be done by evaluating a <a href="/wiki/Closed-form_expression" title="Closed-form expression">closed-form expression</a> (simply by counting observations in each group),<sup id="cite&#95;ref-aima&#95;3-0" class="reference"><a href="#cite_note-aima-3"><span class="cite-bracket">&#91;</span>3<span class="cite-bracket">&#93;</span></a></sup><sup class="reference nowrap"><span title="Page: 718">&#58;&#8202;718&#8202;</span></sup> rather than the expensive <a href="/wiki/Iterative_method" title="Iterative method">iterative approximation</a> algorithms required by most other models.
</p><p>Despite the use of <a href="/wiki/Bayes%27_theorem" title="Bayes&#39; theorem">Bayes' theorem</a> in the classifier's decision rule, naive Bayes is not (necessarily) a <a href="/wiki/Bayesian_probability" title="Bayesian probability">Bayesian</a> method, and naive Bayes models can be fit to data using either <a href="/wiki/Bayesian_inference" title="Bayesian inference">Bayesian</a> or <a href="/wiki/Frequentist" class="mw-redirect" title="Frequentist">frequentist</a> methods.<sup id="cite&#95;ref-idiots&#95;1-1" class="reference"><a href="#cite_note-idiots-1"><span class="cite-bracket">&#91;</span>1<span class="cite-bracket">&#93;</span></a></sup><sup id="cite&#95;ref-aima&#95;3-1" class="reference"><a href="#cite_note-aima-3"><span class="cite-bracket">&#91;</span>3<span class="cite-bracket">&#93;</span></a></sup>
</p>
<meta property="mw:PageProp/toc" />
<div class="mw-heading mw-heading2"><h2 id="Introduction">Introduction</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=1" title="Edit section: Introduction"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>Naive Bayes is a simple technique for constructing classifiers: models that assign class labels to problem instances, represented as vectors of <a href="/wiki/Feature_vector" class="mw-redirect" title="Feature vector">feature</a> values, where the class labels are drawn from some finite set. There is not a single <a href="/wiki/Algorithm" title="Algorithm">algorithm</a> for training such classifiers, but a family of algorithms based on a common principle: all naive Bayes classifiers assume that the value of a particular feature is <a href="/wiki/Independence_(probability_theory)" title="Independence (probability theory)">independent</a> of the value of any other feature, given the class variable. For example, a fruit may be considered to be an apple if it is red, round, and about 10&#160;cm in diameter.  A naive Bayes classifier considers each of these features to contribute independently to the probability that this fruit is an apple, regardless of any possible <a href="/wiki/Correlation_and_dependence" class="mw-redirect" title="Correlation and dependence">correlations</a> between the color, roundness, and diameter features.
</p><p>In many practical applications, parameter estimation for naive Bayes models uses the method of <a href="/wiki/Maximum_likelihood" class="mw-redirect" title="Maximum likelihood">maximum likelihood</a>; in other words, one can work with the naive Bayes model without accepting <a href="/wiki/Bayesian_probability" title="Bayesian probability">Bayesian probability</a> or using any Bayesian methods.
</p><p>Despite their naive design and apparently oversimplified assumptions, naive Bayes classifiers have worked quite well in many complex real-world situations. In 2004, an analysis of the Bayesian classification problem showed that there are sound theoretical reasons for the apparently implausible <a href="/wiki/Efficacy" title="Efficacy">efficacy</a> of naive Bayes classifiers.<sup id="cite&#95;ref-4" class="reference"><a href="#cite_note-4"><span class="cite-bracket">&#91;</span>4<span class="cite-bracket">&#93;</span></a></sup> Still, a comprehensive comparison with other classification algorithms in 2006 showed that Bayes classification is outperformed by other approaches, such as <a href="/wiki/Boosted_trees" class="mw-redirect" title="Boosted trees">boosted trees</a> or <a href="/wiki/Random_forests" class="mw-redirect" title="Random forests">random forests</a>.<sup id="cite&#95;ref-5" class="reference"><a href="#cite_note-5"><span class="cite-bracket">&#91;</span>5<span class="cite-bracket">&#93;</span></a></sup>
</p><p>An advantage of naive Bayes is that it only requires a small amount of training data to estimate the parameters necessary for classification.<sup id="cite&#95;ref-6" class="reference"><a href="#cite_note-6"><span class="cite-bracket">&#91;</span>6<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading2"><h2 id="Probabilistic_model">Probabilistic model</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=2" title="Edit section: Probabilistic model"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>Abstractly, naive Bayes is a <a href="/wiki/Conditional_probability" title="Conditional probability">conditional probability</a> model: it assigns probabilities <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(C_{k}\mid x_{1},\ldots ,x_{n})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(C_{k}\mid x_{1},\ldots ,x_{n})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a4996a88846087a637cb449742ecf97cb3d47cac" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:17.866ex; height:2.843ex;" alt="{\displaystyle p(C_{k}\mid x_{1},\ldots ,x_{n})}"></span> for each of the <span class="texhtml mvar" style="font-style:italic;">K</span> possible outcomes or <i>classes</i> <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C_{k}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C_{k}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a0887b56787ba96e79de2b9f5c6ff30aabad1c6" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.751ex; height:2.509ex;" alt="{\displaystyle C_{k}}"></span> given a problem instance to be classified, represented by a vector <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {x} =(x_{1},\ldots ,x_{n})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>=</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {x} =(x_{1},\ldots ,x_{n})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4ba26911a84d2e1f83ef34ba5c0488fc67cf33a3" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:16.429ex; height:2.843ex;" alt="{\displaystyle \mathbf {x} =(x_{1},\ldots ,x_{n})}"></span> encoding some <span class="texhtml mvar" style="font-style:italic;">n</span> features (independent variables).<sup id="cite&#95;ref-7" class="reference"><a href="#cite_note-7"><span class="cite-bracket">&#91;</span>7<span class="cite-bracket">&#93;</span></a></sup>
</p><p>The problem with the above formulation is that if the number of features <span class="texhtml mvar" style="font-style:italic;">n</span> is large or if a feature can take on a large number of values, then basing such a model on <a href="/wiki/Conditional_probability_table" title="Conditional probability table">probability tables</a> is infeasible. The model must therefore be reformulated to make it more tractable. Using <a href="/wiki/Bayes%27_theorem" title="Bayes&#39; theorem">Bayes' theorem</a>, the conditional probability can be decomposed as:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(C_{k}\mid \mathbf {x} )={\frac {p(C_{k})\ p(\mathbf {x} \mid C_{k})}{p(\mathbf {x} )}}\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>C</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>k</mi>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
              <mtext>&#xA0;</mtext>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi mathvariant="bold">x</mi>
              </mrow>
              <mo>&#x2223;<!-- ∣ --></mo>
              <msub>
                <mi>C</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>k</mi>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi mathvariant="bold">x</mi>
              </mrow>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(C_{k}\mid \mathbf {x} )={\frac {p(C_{k})\ p(\mathbf {x} \mid C_{k})}{p(\mathbf {x} )}}\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/52bd0ca5938da89d7f9bf388dc7edcbd546c118e" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.671ex; margin-left: -0.089ex; width:28.876ex; height:6.509ex;" alt="{\displaystyle p(C_{k}\mid \mathbf {x} )={\frac {p(C_{k})\ p(\mathbf {x} \mid C_{k})}{p(\mathbf {x} )}}\,}"></span>
</p><p>In plain English, using <a href="/wiki/Bayesian_probability" title="Bayesian probability">Bayesian probability</a> terminology, the above equation can be written as
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\text{posterior}}={\frac {{\text{prior}}\times {\text{likelihood}}}{\text{evidence}}}\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>posterior</mtext>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>prior</mtext>
              </mrow>
              <mo>&#x00D7;<!-- × --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>likelihood</mtext>
              </mrow>
            </mrow>
            <mtext>evidence</mtext>
          </mfrac>
        </mrow>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\text{posterior}}={\frac {{\text{prior}}\times {\text{likelihood}}}{\text{evidence}}}\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d0d9f596ba491384422716b01dbe74472060d0d7" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.005ex; width:30.785ex; height:5.509ex;" alt="{\displaystyle {\text{posterior}}={\frac {{\text{prior}}\times {\text{likelihood}}}{\text{evidence}}}\,}"></span>
</p><p>In practice, there is interest only in the numerator of that fraction, because the denominator does not depend on <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4fc55753007cd3c18576f7933f6f089196732029" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="{\displaystyle C}"></span> and the values of the features <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;" alt="{\displaystyle x_{i}}"></span> are given, so that the denominator is effectively constant.
The numerator is equivalent to the <a href="/wiki/Joint_probability" class="mw-redirect" title="Joint probability">joint probability</a> model
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(C_{k},x_{1},\ldots ,x_{n})\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(C_{k},x_{1},\ldots ,x_{n})\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5fdd0a0b04a5177f9cd2eb6b79f7d651cb67f9a2" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:17.35ex; height:2.843ex;" alt="{\displaystyle p(C_{k},x_{1},\ldots ,x_{n})\,}"></span>
which can be rewritten as follows, using the <a href="/wiki/Chain_rule_(probability)" title="Chain rule (probability)">chain rule</a> for repeated applications of the definition of <a href="/wiki/Conditional_probability" title="Conditional probability">conditional probability</a>:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{aligned}p(C_{k},x_{1},\ldots ,x_{n})&amp;=p(x_{1},\ldots ,x_{n},C_{k})\\&amp;=p(x_{1}\mid x_{2},\ldots ,x_{n},C_{k})\ p(x_{2},\ldots ,x_{n},C_{k})\\&amp;=p(x_{1}\mid x_{2},\ldots ,x_{n},C_{k})\ p(x_{2}\mid x_{3},\ldots ,x_{n},C_{k})\ p(x_{3},\ldots ,x_{n},C_{k})\\&amp;=\cdots \\&amp;=p(x_{1}\mid x_{2},\ldots ,x_{n},C_{k})\ p(x_{2}\mid x_{3},\ldots ,x_{n},C_{k})\cdots p(x_{n-1}\mid x_{n},C_{k})\ p(x_{n}\mid C_{k})\ p(C_{k})\\\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;<!-- … --></mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;<!-- … --></mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo>,</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd />
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>&#x2223;<!-- ∣ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;<!-- … --></mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo>,</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mtext>&#xA0;</mtext>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;<!-- … --></mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo>,</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd />
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>&#x2223;<!-- ∣ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;<!-- … --></mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo>,</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mtext>&#xA0;</mtext>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo>&#x2223;<!-- ∣ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>3</mn>
                  </mrow>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;<!-- … --></mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo>,</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mtext>&#xA0;</mtext>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>3</mn>
                  </mrow>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;<!-- … --></mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo>,</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd />
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <mo>&#x22EF;<!-- ⋯ --></mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd />
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>&#x2223;<!-- ∣ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;<!-- … --></mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo>,</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mtext>&#xA0;</mtext>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo>&#x2223;<!-- ∣ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>3</mn>
                  </mrow>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;<!-- … --></mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo>,</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>&#x22EF;<!-- ⋯ --></mo>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                    <mo>&#x2212;<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>&#x2223;<!-- ∣ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo>,</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mtext>&#xA0;</mtext>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo>&#x2223;<!-- ∣ --></mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mtext>&#xA0;</mtext>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}p(C_{k},x_{1},\ldots ,x_{n})&amp;=p(x_{1},\ldots ,x_{n},C_{k})\\&amp;=p(x_{1}\mid x_{2},\ldots ,x_{n},C_{k})\ p(x_{2},\ldots ,x_{n},C_{k})\\&amp;=p(x_{1}\mid x_{2},\ldots ,x_{n},C_{k})\ p(x_{2}\mid x_{3},\ldots ,x_{n},C_{k})\ p(x_{3},\ldots ,x_{n},C_{k})\\&amp;=\cdots \\&amp;=p(x_{1}\mid x_{2},\ldots ,x_{n},C_{k})\ p(x_{2}\mid x_{3},\ldots ,x_{n},C_{k})\cdots p(x_{n-1}\mid x_{n},C_{k})\ p(x_{n}\mid C_{k})\ p(C_{k})\\\end{aligned}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/952da10da33bae76714178cbae4435933e48fdcb" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -7.171ex; width:100.193ex; height:15.509ex;" alt="{\displaystyle {\begin{aligned}p(C_{k},x_{1},\ldots ,x_{n})&amp;=p(x_{1},\ldots ,x_{n},C_{k})\\&amp;=p(x_{1}\mid x_{2},\ldots ,x_{n},C_{k})\ p(x_{2},\ldots ,x_{n},C_{k})\\&amp;=p(x_{1}\mid x_{2},\ldots ,x_{n},C_{k})\ p(x_{2}\mid x_{3},\ldots ,x_{n},C_{k})\ p(x_{3},\ldots ,x_{n},C_{k})\\&amp;=\cdots \\&amp;=p(x_{1}\mid x_{2},\ldots ,x_{n},C_{k})\ p(x_{2}\mid x_{3},\ldots ,x_{n},C_{k})\cdots p(x_{n-1}\mid x_{n},C_{k})\ p(x_{n}\mid C_{k})\ p(C_{k})\\\end{aligned}}}"></span>
</p><p>Now the "naive" <a href="/wiki/Conditional_independence" title="Conditional independence">conditional independence</a> assumptions come into play: assume that all features in <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {x} }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {x} }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/32adf004df5eb0a8c7fd8c0b6b7405183c5a5ef2" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.411ex; height:1.676ex;" alt="{\displaystyle \mathbf {x} }"></span> are <a href="/wiki/Mutually_independent" class="mw-redirect" title="Mutually independent">mutually independent</a>, conditional on the category <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C_{k}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C_{k}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a0887b56787ba96e79de2b9f5c6ff30aabad1c6" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.751ex; height:2.509ex;" alt="{\displaystyle C_{k}}"></span>. Under this assumption,
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(x_{i}\mid x_{i+1},\ldots ,x_{n},C_{k})=p(x_{i}\mid C_{k})\,.}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>+</mo>
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mspace width="thinmathspace" />
        <mo>.</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(x_{i}\mid x_{i+1},\ldots ,x_{n},C_{k})=p(x_{i}\mid C_{k})\,.}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f1da10f64def81c2b9f15903183434b9c136cf39" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:36.804ex; height:2.843ex;" alt="{\displaystyle p(x_{i}\mid x_{i+1},\ldots ,x_{n},C_{k})=p(x_{i}\mid C_{k})\,.}"></span>
</p><p>Thus, the joint model can be expressed as
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{aligned}p(C_{k}\mid x_{1},\ldots ,x_{n})\varpropto \ &amp;p(C_{k},x_{1},\ldots ,x_{n})\\&amp;=p(C_{k})\ p(x_{1}\mid C_{k})\ p(x_{2}\mid C_{k})\ p(x_{3}\mid C_{k})\ \cdots \\&amp;=p(C_{k})\prod _{i=1}^{n}p(x_{i}\mid C_{k})\,,\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo>&#x2223;<!-- ∣ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;<!-- … --></mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>&#x221D;<!-- ∝ --></mo>
                <mtext>&#xA0;</mtext>
              </mtd>
              <mtd>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>,</mo>
                <mo>&#x2026;<!-- … --></mo>
                <mo>,</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd />
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mtext>&#xA0;</mtext>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>&#x2223;<!-- ∣ --></mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mtext>&#xA0;</mtext>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo>&#x2223;<!-- ∣ --></mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mtext>&#xA0;</mtext>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>3</mn>
                  </mrow>
                </msub>
                <mo>&#x2223;<!-- ∣ --></mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mtext>&#xA0;</mtext>
                <mo>&#x22EF;<!-- ⋯ --></mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd />
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <munderover>
                  <mo>&#x220F;<!-- ∏ --></mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                    <mo>=</mo>
                    <mn>1</mn>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </munderover>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo>&#x2223;<!-- ∣ --></mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mspace width="thinmathspace" />
                <mo>,</mo>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}p(C_{k}\mid x_{1},\ldots ,x_{n})\varpropto \ &amp;p(C_{k},x_{1},\ldots ,x_{n})\\&amp;=p(C_{k})\ p(x_{1}\mid C_{k})\ p(x_{2}\mid C_{k})\ p(x_{3}\mid C_{k})\ \cdots \\&amp;=p(C_{k})\prod _{i=1}^{n}p(x_{i}\mid C_{k})\,,\end{aligned}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d95fa16e60a206378016de0c462badaef0d2beab" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -6.005ex; width:66.619ex; height:13.176ex;" alt="{\displaystyle {\begin{aligned}p(C_{k}\mid x_{1},\ldots ,x_{n})\varpropto \ &amp;p(C_{k},x_{1},\ldots ,x_{n})\\&amp;=p(C_{k})\ p(x_{1}\mid C_{k})\ p(x_{2}\mid C_{k})\ p(x_{3}\mid C_{k})\ \cdots \\&amp;=p(C_{k})\prod _{i=1}^{n}p(x_{i}\mid C_{k})\,,\end{aligned}}}"></span>
where <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \varpropto }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo>&#x221D;<!-- ∝ --></mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \varpropto }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/58991f136ed1597d3d16badb8bb3c63d79bf6513" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.808ex; height:1.676ex;" alt="{\displaystyle \varpropto }"></span> denotes <a href="/wiki/Proportionality_(mathematics)" title="Proportionality (mathematics)">proportionality</a> since the denominator <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(\mathbf {x} )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(\mathbf {x} )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3f65e748c482303ddd568038c9a3baafc05f28e4" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:4.479ex; height:2.843ex;" alt="{\displaystyle p(\mathbf {x} )}"></span> is omitted.
</p><p>This means that under the above independence assumptions, the conditional distribution over the class variable <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4fc55753007cd3c18576f7933f6f089196732029" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.766ex; height:2.176ex;" alt="{\displaystyle C}"></span> is:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(C_{k}\mid x_{1},\ldots ,x_{n})={\frac {1}{Z}}\ p(C_{k})\prod _{i=1}^{n}p(x_{i}\mid C_{k})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mi>Z</mi>
          </mfrac>
        </mrow>
        <mtext>&#xA0;</mtext>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <munderover>
          <mo>&#x220F;<!-- ∏ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </munderover>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(C_{k}\mid x_{1},\ldots ,x_{n})={\frac {1}{Z}}\ p(C_{k})\prod _{i=1}^{n}p(x_{i}\mid C_{k})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/13b831cabfd134b1e6ed984d1eeabac4d8541963" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.005ex; margin-left: -0.089ex; width:43.33ex; height:6.843ex;" alt="{\displaystyle p(C_{k}\mid x_{1},\ldots ,x_{n})={\frac {1}{Z}}\ p(C_{k})\prod _{i=1}^{n}p(x_{i}\mid C_{k})}"></span>
where the evidence <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle Z=p(\mathbf {x} )=\sum _{k}p(C_{k})\ p(\mathbf {x} \mid C_{k})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Z</mi>
        <mo>=</mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <munder>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </munder>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mtext>&#xA0;</mtext>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Z=p(\mathbf {x} )=\sum _{k}p(C_{k})\ p(\mathbf {x} \mid C_{k})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/58e7d135abe9883f49a4748e75756b33b3a5b621" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.005ex; width:31.396ex; height:5.509ex;" alt="{\displaystyle Z=p(\mathbf {x} )=\sum _{k}p(C_{k})\ p(\mathbf {x} \mid C_{k})}"></span> is a scaling factor dependent only on <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x_{1},\ldots ,x_{n}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{1},\ldots ,x_{n}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/737e02a5fbf8bc31d443c91025339f9fd1de1065" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:10.11ex; height:2.009ex;" alt="{\displaystyle x_{1},\ldots ,x_{n}}"></span>, that is, a constant if the values of the feature variables are known.
</p><p>Often, it is only necessary to <a href="/wiki/Discriminative_model" title="Discriminative model">discriminate</a> between classes. In that case, the scaling factor is irrelevant, and it is sufficient to calculate the log-probability up to a factor:<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \ln p(C_{k}\mid x_{1},\ldots ,x_{n})=\ln p(C_{k})+\sum _{i=1}^{n}\ln p(x_{i}\mid C_{k})\underbrace {-\ln Z} _{\text{irrelevant}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>+</mo>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </munderover>
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <munder>
          <mrow class="MJX-TeXAtom-OP MJX-fixedlimits">
            <munder>
              <mrow>
                <mo>&#x2212;<!-- − --></mo>
                <mi>ln</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <mi>Z</mi>
              </mrow>
              <mo>&#x23DF;<!-- ⏟ --></mo>
            </munder>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mtext>irrelevant</mtext>
          </mrow>
        </munder>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \ln p(C_{k}\mid x_{1},\ldots ,x_{n})=\ln p(C_{k})+\sum _{i=1}^{n}\ln p(x_{i}\mid C_{k})\underbrace {-\ln Z} _{\text{irrelevant}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/77f4cefe07cc1172406230c8fabe381ab62aa619" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.838ex; width:56.87ex; height:7.676ex;" alt="{\displaystyle \ln p(C_{k}\mid x_{1},\ldots ,x_{n})=\ln p(C_{k})+\sum _{i=1}^{n}\ln p(x_{i}\mid C_{k})\underbrace {-\ln Z} _{\text{irrelevant}}}"></span>The scaling factor is irrelevant, since discrimination subtracts it away:<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \ln {\frac {p(C_{k}\mid x_{1},\ldots ,x_{n})}{p(C_{l}\mid x_{1},\ldots ,x_{n})}}=\left(\ln p(C_{k})+\sum _{i=1}^{n}\ln p(x_{i}\mid C_{k})\right)-\left(\ln p(C_{l})+\sum _{i=1}^{n}\ln p(x_{i}\mid C_{l})\right)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>C</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>k</mi>
                </mrow>
              </msub>
              <mo>&#x2223;<!-- ∣ --></mo>
              <msub>
                <mi>x</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo>,</mo>
              <mo>&#x2026;<!-- … --></mo>
              <mo>,</mo>
              <msub>
                <mi>x</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>n</mi>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>C</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>l</mi>
                </mrow>
              </msub>
              <mo>&#x2223;<!-- ∣ --></mo>
              <msub>
                <mi>x</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo>,</mo>
              <mo>&#x2026;<!-- … --></mo>
              <mo>,</mo>
              <msub>
                <mi>x</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>n</mi>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mo>=</mo>
        <mrow>
          <mo>(</mo>
          <mrow>
            <mi>ln</mi>
            <mo>&#x2061;<!-- ⁡ --></mo>
            <mi>p</mi>
            <mo stretchy="false">(</mo>
            <msub>
              <mi>C</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>k</mi>
              </mrow>
            </msub>
            <mo stretchy="false">)</mo>
            <mo>+</mo>
            <munderover>
              <mo>&#x2211;<!-- ∑ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>n</mi>
              </mrow>
            </munderover>
            <mi>ln</mi>
            <mo>&#x2061;<!-- ⁡ --></mo>
            <mi>p</mi>
            <mo stretchy="false">(</mo>
            <msub>
              <mi>x</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
            <mo>&#x2223;<!-- ∣ --></mo>
            <msub>
              <mi>C</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>k</mi>
              </mrow>
            </msub>
            <mo stretchy="false">)</mo>
          </mrow>
          <mo>)</mo>
        </mrow>
        <mo>&#x2212;<!-- − --></mo>
        <mrow>
          <mo>(</mo>
          <mrow>
            <mi>ln</mi>
            <mo>&#x2061;<!-- ⁡ --></mo>
            <mi>p</mi>
            <mo stretchy="false">(</mo>
            <msub>
              <mi>C</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>l</mi>
              </mrow>
            </msub>
            <mo stretchy="false">)</mo>
            <mo>+</mo>
            <munderover>
              <mo>&#x2211;<!-- ∑ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>n</mi>
              </mrow>
            </munderover>
            <mi>ln</mi>
            <mo>&#x2061;<!-- ⁡ --></mo>
            <mi>p</mi>
            <mo stretchy="false">(</mo>
            <msub>
              <mi>x</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
            <mo>&#x2223;<!-- ∣ --></mo>
            <msub>
              <mi>C</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>l</mi>
              </mrow>
            </msub>
            <mo stretchy="false">)</mo>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \ln {\frac {p(C_{k}\mid x_{1},\ldots ,x_{n})}{p(C_{l}\mid x_{1},\ldots ,x_{n})}}=\left(\ln p(C_{k})+\sum _{i=1}^{n}\ln p(x_{i}\mid C_{k})\right)-\left(\ln p(C_{l})+\sum _{i=1}^{n}\ln p(x_{i}\mid C_{l})\right)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/38627eaa4670ece41b68ea81c213174a18443c0a" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.171ex; width:87.029ex; height:7.509ex;" alt="{\displaystyle \ln {\frac {p(C_{k}\mid x_{1},\ldots ,x_{n})}{p(C_{l}\mid x_{1},\ldots ,x_{n})}}=\left(\ln p(C_{k})+\sum _{i=1}^{n}\ln p(x_{i}\mid C_{k})\right)-\left(\ln p(C_{l})+\sum _{i=1}^{n}\ln p(x_{i}\mid C_{l})\right)}"></span>There are two benefits of using log-probability. One is that it allows an interpretation in information theory, where log-probabilities are units of information in <a href="/wiki/Nat_(unit)" title="Nat (unit)">nats</a>. Another is that it avoids <a href="/wiki/Arithmetic_underflow" title="Arithmetic underflow">arithmetic underflow</a>.
</p>
<div class="mw-heading mw-heading3"><h3 id="Constructing_a_classifier_from_the_probability_model">Constructing a classifier from the probability model</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=3" title="Edit section: Constructing a classifier from the probability model"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>The discussion so far has derived the independent feature model, that is, the naive Bayes <a href="/wiki/Probability_model" class="mw-redirect" title="Probability model">probability model</a>. The naive Bayes <a href="/wiki/Statistical_classification" title="Statistical classification">classifier</a> combines this model with a <a href="/wiki/Decision_rule" title="Decision rule">decision rule</a>. One common rule is to pick the hypothesis that is most probable so as to minimize the probability of misclassification; this is known as the <i><a href="/wiki/Maximum_a_posteriori" class="mw-redirect" title="Maximum a posteriori">maximum <i>a posteriori</i></a></i> or <i>MAP</i> decision rule. The corresponding classifier, a <a href="/wiki/Bayes_classifier" title="Bayes classifier">Bayes classifier</a>, is the function that assigns a class label <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\hat {y}}=C_{k}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>y</mi>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>=</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\hat {y}}=C_{k}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6fe719eda4ce62ee2f2104455abc5233fdf69e01" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:7.151ex; height:2.509ex;" alt="{\displaystyle {\hat {y}}=C_{k}}"></span> for some <span class="texhtml mvar" style="font-style:italic;">k</span> as follows:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\hat {y}}={\underset {k\in \{1,\ldots ,K\}}{\operatorname {argmax} }}\ p(C_{k})\displaystyle \prod _{i=1}^{n}p(x_{i}\mid C_{k}).}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>y</mi>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <munder>
            <mi>argmax</mi>
            <mrow>
              <mi>k</mi>
              <mo>&#x2208;<!-- ∈ --></mo>
              <mo fence="false" stretchy="false">{</mo>
              <mn>1</mn>
              <mo>,</mo>
              <mo>&#x2026;<!-- … --></mo>
              <mo>,</mo>
              <mi>K</mi>
              <mo fence="false" stretchy="false">}</mo>
            </mrow>
          </munder>
        </mrow>
        <mtext>&#xA0;</mtext>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mstyle displaystyle="true" scriptlevel="0">
          <munderover>
            <mo>&#x220F;<!-- ∏ --></mo>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>i</mi>
              <mo>=</mo>
              <mn>1</mn>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>n</mi>
            </mrow>
          </munderover>
          <mi>p</mi>
          <mo stretchy="false">(</mo>
          <msub>
            <mi>x</mi>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>i</mi>
            </mrow>
          </msub>
          <mo>&#x2223;<!-- ∣ --></mo>
          <msub>
            <mi>C</mi>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>k</mi>
            </mrow>
          </msub>
          <mo stretchy="false">)</mo>
          <mo>.</mo>
        </mstyle>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\hat {y}}={\underset {k\in \{1,\ldots ,K\}}{\operatorname {argmax} }}\ p(C_{k})\displaystyle \prod _{i=1}^{n}p(x_{i}\mid C_{k}).}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1eaed580cf7c29f044a9e517f1cd4a7dd69c4b1f" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.005ex; width:33.617ex; height:6.843ex;" alt="{\displaystyle {\hat {y}}={\underset {k\in \{1,\ldots ,K\}}{\operatorname {argmax} }}\ p(C_{k})\displaystyle \prod _{i=1}^{n}p(x_{i}\mid C_{k}).}"></span>
</p>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="/wiki/File:ROC_curves.svg" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/4/4f/ROC_curves.svg/250px-ROC_curves.svg.png" decoding="async" width="250" height="228" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/4/4f/ROC_curves.svg/500px-ROC_curves.svg.png 1.5x" data-file-width="651" data-file-height="593" /></a><figcaption><a href="/wiki/Likelihood_function" title="Likelihood function">Likelihood functions</a> <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(\mathbf {x} \mid Y)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>Y</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(\mathbf {x} \mid Y)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8ae8c2cd313d754e6fc6e6b5e3ff5d6bab0adcb6" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:8.19ex; height:2.843ex;" alt="{\displaystyle p(\mathbf {x} \mid Y)}"></span>, <a href="/wiki/Confusion_matrix" title="Confusion matrix">Confusion matrix</a> and <a href="/wiki/ROC_curve" class="mw-redirect" title="ROC curve">ROC curve</a>. For the naive Bayes classifier and given that the a priori probabilities <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(Y)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(Y)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9dfa36f22174f8b1fc08b151fec6511430933850" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:4.841ex; height:2.843ex;" alt="{\displaystyle p(Y)}"></span> are the same for all classes, then the <a href="/wiki/Decision_boundary" title="Decision boundary">decision boundary</a> (green line) would be placed on the point where the two probability densities intersect, due to <span class="nowrap"><span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(Y\mid \mathbf {x} )={\frac {p(Y)\ p(\mathbf {x} \mid Y)}{p(\mathbf {x} )}}\propto p(\mathbf {x} \mid Y)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>Y</mi>
              <mo stretchy="false">)</mo>
              <mtext>&#xA0;</mtext>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi mathvariant="bold">x</mi>
              </mrow>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi>Y</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi mathvariant="bold">x</mi>
              </mrow>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mo>&#x221D;<!-- ∝ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>Y</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(Y\mid \mathbf {x} )={\frac {p(Y)\ p(\mathbf {x} \mid Y)}{p(\mathbf {x} )}}\propto p(\mathbf {x} \mid Y)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a629d83e6c8b0a5f239e0d05791ed3acb8321175" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.671ex; margin-left: -0.089ex; width:36.756ex; height:6.509ex;" alt="{\displaystyle p(Y\mid \mathbf {x} )={\frac {p(Y)\ p(\mathbf {x} \mid Y)}{p(\mathbf {x} )}}\propto p(\mathbf {x} \mid Y)}"></span>.</span></figcaption></figure>
<div class="mw-heading mw-heading2"><h2 id="Parameter_estimation_and_event_models">Parameter estimation and event models</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=4" title="Edit section: Parameter estimation and event models"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>A class's prior may be calculated by assuming equiprobable classes, i.e., <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(C_{k})={\frac {1}{K}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mi>K</mi>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(C_{k})={\frac {1}{K}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/31d686a8f569bf5d2f9606d1b5f0b31336adcd06" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -1.838ex; margin-left: -0.089ex; width:11.819ex; height:5.176ex;" alt="{\displaystyle p(C_{k})={\frac {1}{K}}}"></span>, or by calculating an estimate for the class probability from the training set:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\text{prior for a given class}}={\frac {\text{no. of samples in that class}}{\text{total no. of samples}}}\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>prior for a given class</mtext>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mtext>no. of samples in that class</mtext>
            <mtext>total no. of samples</mtext>
          </mfrac>
        </mrow>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\text{prior for a given class}}={\frac {\text{no. of samples in that class}}{\text{total no. of samples}}}\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cb201b38d36ec25485d47921f04149fb4eceed92" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.338ex; width:52.213ex; height:5.843ex;" alt="{\displaystyle {\text{prior for a given class}}={\frac {\text{no. of samples in that class}}{\text{total no. of samples}}}\,}"></span>
To estimate the parameters for a feature's distribution, one must assume a distribution or generate <a href="/wiki/Nonparametric" class="mw-redirect" title="Nonparametric">nonparametric</a> models for the features from the training set.<sup id="cite&#95;ref-john95&#95;8-0" class="reference"><a href="#cite_note-john95-8"><span class="cite-bracket">&#91;</span>8<span class="cite-bracket">&#93;</span></a></sup>
</p><p>The assumptions on distributions of features are called the "event model" of the naive Bayes classifier. For discrete features like the ones encountered in document classification (include spam filtering), <a href="/wiki/Multinomial_distribution" title="Multinomial distribution">multinomial</a> and <a href="/wiki/Bernoulli_distribution" title="Bernoulli distribution">Bernoulli</a> distributions are popular. These assumptions lead to two distinct models, which are often confused.<sup id="cite&#95;ref-mccallum&#95;9-0" class="reference"><a href="#cite_note-mccallum-9"><span class="cite-bracket">&#91;</span>9<span class="cite-bracket">&#93;</span></a></sup><sup id="cite&#95;ref-10" class="reference"><a href="#cite_note-10"><span class="cite-bracket">&#91;</span>10<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading3"><h3 id="Gaussian_naive_Bayes">Gaussian naive Bayes</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=5" title="Edit section: Gaussian naive Bayes"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>When dealing with continuous data, a typical assumption is that the continuous values associated with each class are distributed according to a <a href="/wiki/Normal_distribution" title="Normal distribution">normal</a> (or Gaussian) distribution. For example, suppose the training data contains a continuous attribute, <b><span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="{\displaystyle x}"></span></b>. The data is first segmented by the class, and then the mean and <a href="/wiki/Variance#Estimating_the_variance" title="Variance">variance</a> of <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="{\displaystyle x}"></span> is computed in each class. Let <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mu _{k}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>&#x03BC;<!-- μ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mu _{k}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/25f9c464114cfcd7e31e53de202703377b7c5ffb" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:2.49ex; height:2.176ex;" alt="{\displaystyle \mu _{k}}"></span> be the mean of the values in <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="{\displaystyle x}"></span> associated with class <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C_{k}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C_{k}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a0887b56787ba96e79de2b9f5c6ff30aabad1c6" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.751ex; height:2.509ex;" alt="{\displaystyle C_{k}}"></span>, and let <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \sigma _{k}^{2}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msubsup>
          <mi>&#x03C3;<!-- σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msubsup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma _{k}^{2}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/065426e4746772f367e2476d16fa02f11460a70d" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -1.005ex; width:2.416ex; height:3.176ex;" alt="{\displaystyle \sigma _{k}^{2}}"></span> be the <a href="/wiki/Bessel%27s_correction" title="Bessel&#39;s correction">Bessel corrected variance</a> of the values in <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="{\displaystyle x}"></span> associated with class <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C_{k}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C_{k}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a0887b56787ba96e79de2b9f5c6ff30aabad1c6" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.751ex; height:2.509ex;" alt="{\displaystyle C_{k}}"></span>. Suppose one has collected some observation value <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle v}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>v</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle v}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e07b00e7fc0847fbd16391c778d65bc25c452597" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.128ex; height:1.676ex;" alt="{\displaystyle v}"></span>. Then, the probability <i>density</i> of <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle v}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>v</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle v}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e07b00e7fc0847fbd16391c778d65bc25c452597" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.128ex; height:1.676ex;" alt="{\displaystyle v}"></span> given a class <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C_{k}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C_{k}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a0887b56787ba96e79de2b9f5c6ff30aabad1c6" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.751ex; height:2.509ex;" alt="{\displaystyle C_{k}}"></span>, i.e., <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(x=v\mid C_{k})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo>=</mo>
        <mi>v</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(x=v\mid C_{k})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1f95b7770313dcc9d175c882b6023cc25171944e" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:13.312ex; height:2.843ex;" alt="{\displaystyle p(x=v\mid C_{k})}"></span>, can be computed by plugging <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle v}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>v</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle v}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e07b00e7fc0847fbd16391c778d65bc25c452597" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.128ex; height:1.676ex;" alt="{\displaystyle v}"></span> into the equation for a <a href="/wiki/Normal_distribution" title="Normal distribution">normal distribution</a> parameterized by <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mu _{k}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>&#x03BC;<!-- μ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mu _{k}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/25f9c464114cfcd7e31e53de202703377b7c5ffb" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:2.49ex; height:2.176ex;" alt="{\displaystyle \mu _{k}}"></span> and <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \sigma _{k}^{2}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msubsup>
          <mi>&#x03C3;<!-- σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msubsup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma _{k}^{2}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/065426e4746772f367e2476d16fa02f11460a70d" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -1.005ex; width:2.416ex; height:3.176ex;" alt="{\displaystyle \sigma _{k}^{2}}"></span>. Formally,
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(x=v\mid C_{k})={\frac {1}{\sqrt {2\pi \sigma _{k}^{2}}}}\,e^{-{\frac {(v-\mu _{k})^{2}}{2\sigma _{k}^{2}}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo>=</mo>
        <mi>v</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <msqrt>
              <mn>2</mn>
              <mi>&#x03C0;<!-- π --></mi>
              <msubsup>
                <mi>&#x03C3;<!-- σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>k</mi>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>2</mn>
                </mrow>
              </msubsup>
            </msqrt>
          </mfrac>
        </mrow>
        <mspace width="thinmathspace" />
        <msup>
          <mi>e</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mrow class="MJX-TeXAtom-ORD">
              <mfrac>
                <mrow>
                  <mo stretchy="false">(</mo>
                  <mi>v</mi>
                  <mo>&#x2212;<!-- − --></mo>
                  <msub>
                    <mi>&#x03BC;<!-- μ --></mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>k</mi>
                    </mrow>
                  </msub>
                  <msup>
                    <mo stretchy="false">)</mo>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mn>2</mn>
                    </mrow>
                  </msup>
                </mrow>
                <mrow>
                  <mn>2</mn>
                  <msubsup>
                    <mi>&#x03C3;<!-- σ --></mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>k</mi>
                    </mrow>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mn>2</mn>
                    </mrow>
                  </msubsup>
                </mrow>
              </mfrac>
            </mrow>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(x=v\mid C_{k})={\frac {1}{\sqrt {2\pi \sigma _{k}^{2}}}}\,e^{-{\frac {(v-\mu _{k})^{2}}{2\sigma _{k}^{2}}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/685339e22f57b18d804f2e0a9c507421da59e2ab" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -4.671ex; margin-left: -0.089ex; width:33.456ex; height:10.009ex;" alt="{\displaystyle p(x=v\mid C_{k})={\frac {1}{\sqrt {2\pi \sigma _{k}^{2}}}}\,e^{-{\frac {(v-\mu _{k})^{2}}{2\sigma _{k}^{2}}}}}"></span>
</p><p>Another common technique for handling continuous values is to use binning to <a href="/wiki/Discretization_of_continuous_features" title="Discretization of continuous features">discretize</a> the feature values and obtain a new set of Bernoulli-distributed features. Some literature suggests that this is required in order to use naive Bayes, but it is not true, as the discretization may <a href="/wiki/Discretization_error" title="Discretization error">throw away discriminative information</a>.<sup id="cite&#95;ref-idiots&#95;1-2" class="reference"><a href="#cite_note-idiots-1"><span class="cite-bracket">&#91;</span>1<span class="cite-bracket">&#93;</span></a></sup>
</p><p>Sometimes the distribution of class-conditional marginal densities is far from normal. In these cases, <a href="/wiki/Kernel_density_estimation" title="Kernel density estimation">kernel density estimation</a> can be used for a more realistic estimate of the marginal densities of each class. This method, which was introduced by John and Langley,<sup id="cite&#95;ref-john95&#95;8-1" class="reference"><a href="#cite_note-john95-8"><span class="cite-bracket">&#91;</span>8<span class="cite-bracket">&#93;</span></a></sup> can boost the accuracy of the classifier considerably.<sup id="cite&#95;ref-piryonesi2020&#95;11-0" class="reference"><a href="#cite_note-piryonesi2020-11"><span class="cite-bracket">&#91;</span>11<span class="cite-bracket">&#93;</span></a></sup><sup id="cite&#95;ref-hastie01&#95;12-0" class="reference"><a href="#cite_note-hastie01-12"><span class="cite-bracket">&#91;</span>12<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading3"><h3 id="Multinomial_naive_Bayes">Multinomial naive Bayes</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=6" title="Edit section: Multinomial naive Bayes"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>With a multinomial event model, samples (feature vectors) represent the frequencies with which certain events have been generated by a <a href="/wiki/Multinomial_distribution" title="Multinomial distribution">multinomial</a> <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (p_{1},\dots ,p_{n})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (p_{1},\dots ,p_{n})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f4efffc36fb81a4a36512a0c39586b172b21a69b" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:11.599ex; height:2.843ex;" alt="{\displaystyle (p_{1},\dots ,p_{n})}"></span> where <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5bab39399bf5424f25d957cdc57c84a0622626d2" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.089ex; width:2.059ex; height:2.009ex;" alt="{\displaystyle p_{i}}"></span> is the probability that event <span class="texhtml mvar" style="font-style:italic;">i</span> occurs (or <span class="texhtml mvar" style="font-style:italic;">K</span> such multinomials in the multiclass case). A feature vector <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {x} =(x_{1},\dots ,x_{n})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>=</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {x} =(x_{1},\dots ,x_{n})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e981fc14b75616a87b281b37b73dd1b9f713ec68" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:16.429ex; height:2.843ex;" alt="{\displaystyle \mathbf {x} =(x_{1},\dots ,x_{n})}"></span> is then a <a href="/wiki/Histogram" title="Histogram">histogram</a>, with <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;" alt="{\displaystyle x_{i}}"></span> counting the number of times event <span class="texhtml mvar" style="font-style:italic;">i</span> was observed in a particular instance. This is the event model typically used for document classification, with events representing the occurrence of a word in a single document (see <a href="/wiki/Bag_of_words" class="mw-redirect" title="Bag of words">bag of words</a> assumption).<sup id="cite&#95;ref-13" class="reference"><a href="#cite_note-13"><span class="cite-bracket">&#91;</span>13<span class="cite-bracket">&#93;</span></a></sup> The likelihood of observing a histogram <span class="texhtml"><b>x</b></span> is given by:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(\mathbf {x} \mid C_{k})={\frac {(\sum _{i=1}^{n}x_{i})!}{\prod _{i=1}^{n}x_{i}!}}\prod _{i=1}^{n}{p_{ki}}^{x_{i}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mo stretchy="false">(</mo>
              <munderover>
                <mo>&#x2211;<!-- ∑ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>n</mi>
                </mrow>
              </munderover>
              <msub>
                <mi>x</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
              <mo>!</mo>
            </mrow>
            <mrow>
              <munderover>
                <mo>&#x220F;<!-- ∏ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>n</mi>
                </mrow>
              </munderover>
              <msub>
                <mi>x</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <mo>!</mo>
            </mrow>
          </mfrac>
        </mrow>
        <munderover>
          <mo>&#x220F;<!-- ∏ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </munderover>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mi>p</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>k</mi>
                <mi>i</mi>
              </mrow>
            </msub>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mi>x</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(\mathbf {x} \mid C_{k})={\frac {(\sum _{i=1}^{n}x_{i})!}{\prod _{i=1}^{n}x_{i}!}}\prod _{i=1}^{n}{p_{ki}}^{x_{i}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8967b34cca6aeffe1820bc5f2624cee311dccaeb" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.005ex; margin-left: -0.089ex; width:31.795ex; height:7.009ex;" alt="{\displaystyle p(\mathbf {x} \mid C_{k})={\frac {(\sum _{i=1}^{n}x_{i})!}{\prod _{i=1}^{n}x_{i}!}}\prod _{i=1}^{n}{p_{ki}}^{x_{i}}}"></span>
where <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p_{ki}:=p(i\mid C_{k})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>:=</mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>i</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p_{ki}:=p(i\mid C_{k})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a5bfda86371585224fb430e9a3c40ef4e7e8a00f" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:15.129ex; height:2.843ex;" alt="{\displaystyle p_{ki}:=p(i\mid C_{k})}"></span>. 
</p><p>The multinomial naive Bayes classifier becomes a <a href="/wiki/Linear_classifier" title="Linear classifier">linear classifier</a> when expressed in log-space:<sup id="cite&#95;ref-rennie&#95;14-0" class="reference"><a href="#cite_note-rennie-14"><span class="cite-bracket">&#91;</span>14<span class="cite-bracket">&#93;</span></a></sup>
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{aligned}\log p(C_{k}\mid \mathbf {x} )&amp;\varpropto \log \left(p(C_{k})\prod _{i=1}^{n}{p_{ki}}^{x_{i}}\right)\\&amp;=\log p(C_{k})+\sum _{i=1}^{n}x_{i}\cdot \log p_{ki}\\&amp;=b+\mathbf {w} _{k}^{\top }\mathbf {x} \end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd>
                <mi>log</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo>&#x2223;<!-- ∣ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi mathvariant="bold">x</mi>
                </mrow>
                <mo stretchy="false">)</mo>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>&#x221D;<!-- ∝ --></mo>
                <mi>log</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <mi>p</mi>
                    <mo stretchy="false">(</mo>
                    <msub>
                      <mi>C</mi>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mi>k</mi>
                      </mrow>
                    </msub>
                    <mo stretchy="false">)</mo>
                    <munderover>
                      <mo>&#x220F;<!-- ∏ --></mo>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mi>i</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mi>n</mi>
                      </mrow>
                    </munderover>
                    <msup>
                      <mrow class="MJX-TeXAtom-ORD">
                        <msub>
                          <mi>p</mi>
                          <mrow class="MJX-TeXAtom-ORD">
                            <mi>k</mi>
                            <mi>i</mi>
                          </mrow>
                        </msub>
                      </mrow>
                      <mrow class="MJX-TeXAtom-ORD">
                        <msub>
                          <mi>x</mi>
                          <mrow class="MJX-TeXAtom-ORD">
                            <mi>i</mi>
                          </mrow>
                        </msub>
                      </mrow>
                    </msup>
                  </mrow>
                  <mo>)</mo>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd />
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <mi>log</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>C</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>+</mo>
                <munderover>
                  <mo>&#x2211;<!-- ∑ --></mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                    <mo>=</mo>
                    <mn>1</mn>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </munderover>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo>&#x22C5;<!-- ⋅ --></mo>
                <mi>log</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <msub>
                  <mi>p</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                    <mi>i</mi>
                  </mrow>
                </msub>
              </mtd>
            </mtr>
            <mtr>
              <mtd />
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <mi>b</mi>
                <mo>+</mo>
                <msubsup>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi mathvariant="bold">w</mi>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi mathvariant="normal">&#x22A4;<!-- ⊤ --></mi>
                  </mrow>
                </msubsup>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi mathvariant="bold">x</mi>
                </mrow>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}\log p(C_{k}\mid \mathbf {x} )&amp;\varpropto \log \left(p(C_{k})\prod _{i=1}^{n}{p_{ki}}^{x_{i}}\right)\\&amp;=\log p(C_{k})+\sum _{i=1}^{n}x_{i}\cdot \log p_{ki}\\&amp;=b+\mathbf {w} _{k}^{\top }\mathbf {x} \end{aligned}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e53303c0644c3d64e5eb86210023e76198285e0c" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -8.338ex; width:41.95ex; height:17.843ex;" alt="{\displaystyle {\begin{aligned}\log p(C_{k}\mid \mathbf {x} )&amp;\varpropto \log \left(p(C_{k})\prod _{i=1}^{n}{p_{ki}}^{x_{i}}\right)\\&amp;=\log p(C_{k})+\sum _{i=1}^{n}x_{i}\cdot \log p_{ki}\\&amp;=b+\mathbf {w} _{k}^{\top }\mathbf {x} \end{aligned}}}"></span>
where <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle b=\log p(C_{k})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>b</mi>
        <mo>=</mo>
        <mi>log</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle b=\log p(C_{k})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/947bd8a4b1d68dbc8422855b8640984073002b0b" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:13.184ex; height:2.843ex;" alt="{\displaystyle b=\log p(C_{k})}"></span> and <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle w_{ki}=\log p_{ki}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>w</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mi>log</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle w_{ki}=\log p_{ki}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/65e8a886e8bd08a6723094ced0e8350dc315a86b" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:12.603ex; height:2.509ex;" alt="{\displaystyle w_{ki}=\log p_{ki}}"></span>. Estimating the parameters in log space is advantageous since multiplying a large number of small values can lead to significant rounding error. Applying a log transform reduces the effect of this rounding error.
</p><p>If a given class and feature value never occur together in the training data, then the frequency-based probability estimate will be zero, because the probability estimate is directly proportional to the number of occurrences of a feature's value. This is problematic because it will wipe out all information in the other probabilities when they are multiplied. Therefore, it is often desirable to incorporate a small-sample correction, called <a href="/wiki/Pseudocount" class="mw-redirect" title="Pseudocount">pseudocount</a>, in all probability estimates such that no probability is ever set to be exactly zero. This way of <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularizing</a> naive Bayes is called <a href="/wiki/Laplace_smoothing" class="mw-redirect" title="Laplace smoothing">Laplace smoothing</a> when the pseudocount is one, and <a href="/wiki/Lidstone_smoothing" class="mw-redirect" title="Lidstone smoothing">Lidstone smoothing</a> in the general case.
</p><p>Rennie <i>et al.</i> discuss problems with the multinomial assumption in the context of document classification and possible ways to alleviate those problems, including the use of <a href="/wiki/Tf%E2%80%93idf" title="Tf–idf">tf–idf</a> weights instead of raw term frequencies and document length normalization, to produce a naive Bayes classifier that is competitive with <a href="/wiki/Support_vector_machine" title="Support vector machine">support vector machines</a>.<sup id="cite&#95;ref-rennie&#95;14-1" class="reference"><a href="#cite_note-rennie-14"><span class="cite-bracket">&#91;</span>14<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading3"><h3 id="Bernoulli_naive_Bayes">Bernoulli naive Bayes</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=7" title="Edit section: Bernoulli naive Bayes"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>In the multivariate <a href="/wiki/Bernoulli_distribution" title="Bernoulli distribution">Bernoulli</a> event model, features are independent <a href="/wiki/Boolean_data_type" title="Boolean data type">Boolean variables</a> (<a href="/wiki/Binary_data" title="Binary data">binary variables</a>) describing inputs. Like the multinomial model, this model is popular for document classification tasks,<sup id="cite&#95;ref-mccallum&#95;9-1" class="reference"><a href="#cite_note-mccallum-9"><span class="cite-bracket">&#91;</span>9<span class="cite-bracket">&#93;</span></a></sup> where binary term occurrence features are used rather than term frequencies. If <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;" alt="{\displaystyle x_{i}}"></span> is a Boolean expressing the occurrence or absence of the <span class="texhtml mvar" style="font-style:italic;">i</span>'th term from the vocabulary, then the likelihood of a document given a class <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C_{k}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C_{k}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a0887b56787ba96e79de2b9f5c6ff30aabad1c6" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.751ex; height:2.509ex;" alt="{\displaystyle C_{k}}"></span> is given by:<sup id="cite&#95;ref-mccallum&#95;9-2" class="reference"><a href="#cite_note-mccallum-9"><span class="cite-bracket">&#91;</span>9<span class="cite-bracket">&#93;</span></a></sup>
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(\mathbf {x} \mid C_{k})=\prod _{i=1}^{n}p_{ki}^{x_{i}}(1-p_{ki})^{(1-x_{i})}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <munderover>
          <mo>&#x220F;<!-- ∏ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </munderover>
        <msubsup>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
            <mi>i</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mi>x</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mrow>
        </msubsup>
        <mo stretchy="false">(</mo>
        <mn>1</mn>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
            <mi>i</mi>
          </mrow>
        </msub>
        <msup>
          <mo stretchy="false">)</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mo stretchy="false">(</mo>
            <mn>1</mn>
            <mo>&#x2212;<!-- − --></mo>
            <msub>
              <mi>x</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
            <mo stretchy="false">)</mo>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(\mathbf {x} \mid C_{k})=\prod _{i=1}^{n}p_{ki}^{x_{i}}(1-p_{ki})^{(1-x_{i})}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2b23b8affe1fa31b1ce499d5d2944d9763ff2e6e" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.005ex; margin-left: -0.089ex; width:32.404ex; height:6.843ex;" alt="{\displaystyle p(\mathbf {x} \mid C_{k})=\prod _{i=1}^{n}p_{ki}^{x_{i}}(1-p_{ki})^{(1-x_{i})}}"></span>
where <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p_{ki}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>p</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p_{ki}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8e043cc1fad255f27aa1376296db9d1436f0c9c8" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.089ex; width:2.915ex; height:2.009ex;" alt="{\displaystyle p_{ki}}"></span> is the probability of class <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C_{k}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C_{k}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a0887b56787ba96e79de2b9f5c6ff30aabad1c6" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.751ex; height:2.509ex;" alt="{\displaystyle C_{k}}"></span> generating the term <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;" alt="{\displaystyle x_{i}}"></span>. This event model is especially popular for classifying short texts. It has the benefit of explicitly modelling the absence of terms. Note that a naive Bayes classifier with a Bernoulli event model is not the same as a multinomial NB classifier with frequency counts truncated to one.
</p>
<div class="mw-heading mw-heading3"><h3 id="Semi-supervised_parameter_estimation">Semi-supervised parameter estimation</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=8" title="Edit section: Semi-supervised parameter estimation"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>Given a way to train a naive Bayes classifier from labeled data, it's possible to construct a <a href="/wiki/Semi-supervised_learning" class="mw-redirect" title="Semi-supervised learning">semi-supervised</a> training algorithm that can learn from a combination of labeled and unlabeled data by running the supervised learning algorithm in a loop:<sup id="cite&#95;ref-em&#95;15-0" class="reference"><a href="#cite_note-em-15"><span class="cite-bracket">&#91;</span>15<span class="cite-bracket">&#93;</span></a></sup>
</p>
<ol><li>Given a collection <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle D=L\uplus U}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>D</mi>
        <mo>=</mo>
        <mi>L</mi>
        <mo>&#x228E;<!-- ⊎ --></mo>
        <mi>U</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle D=L\uplus U}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/53324463b6e50ceb9ef846ec06e41d7e6e0b397f" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:10.971ex; height:2.176ex;" alt="{\displaystyle D=L\uplus U}"></span> of labeled samples <span class="texhtml mvar" style="font-style:italic;">L</span> and unlabeled samples <span class="texhtml mvar" style="font-style:italic;">U</span>, start by training a naive Bayes classifier on <span class="texhtml mvar" style="font-style:italic;">L</span>.</li>
<li>Until convergence, do:
<ol><li>Predict class probabilities <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle P(C\mid x)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>C</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(C\mid x)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d2f8cfe523d36ae049971e925459a0231e131d1e" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:8.588ex; height:2.843ex;" alt="{\displaystyle P(C\mid x)}"></span> for all examples <span class="texhtml mvar" style="font-style:italic;">x</span> in <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle D}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>D</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle D}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f34a0c600395e5d4345287e21fb26efd386990e6" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.924ex; height:2.176ex;" alt="{\displaystyle D}"></span>.</li>
<li>Re-train the model based on the <i>probabilities</i> (not the labels) predicted in the previous step.</li></ol></li></ol>
<p>Convergence is determined based on improvement to the model likelihood <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle P(D\mid \theta )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mi>D</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>&#x03B8;<!-- θ --></mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P(D\mid \theta )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/169e6a9bcf7fdb0156eb1d01271f8d94c83d1df5" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:8.507ex; height:2.843ex;" alt="{\displaystyle P(D\mid \theta )}"></span>, where <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \theta }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03B8;<!-- θ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \theta }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.09ex; height:2.176ex;" alt="{\displaystyle \theta }"></span> denotes the parameters of the naive Bayes model.
</p><p>This training algorithm is an instance of the more general <a href="/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation–maximization algorithm">expectation–maximization algorithm</a> (EM): the prediction step inside the loop is the <i>E</i>-step of EM, while the re-training of naive Bayes is the <i>M</i>-step. The algorithm is formally justified by the assumption that the data are generated by a <a href="/wiki/Mixture_model" title="Mixture model">mixture model</a>, and the components of this mixture model are exactly the classes of the classification problem.<sup id="cite&#95;ref-em&#95;15-1" class="reference"><a href="#cite_note-em-15"><span class="cite-bracket">&#91;</span>15<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading2"><h2 id="Discussion">Discussion</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=9" title="Edit section: Discussion"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>Despite the fact that the far-reaching independence assumptions are often inaccurate, the naive Bayes classifier has several properties that make it surprisingly useful in practice. In particular, the decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one-dimensional distribution. This helps alleviate problems stemming from the <a href="/wiki/Curse_of_dimensionality" title="Curse of dimensionality">curse of dimensionality</a>, such as the need for data sets that scale exponentially with the number of features. While naive Bayes often fails to produce a good estimate for the correct class probabilities,<sup id="cite&#95;ref-16" class="reference"><a href="#cite_note-16"><span class="cite-bracket">&#91;</span>16<span class="cite-bracket">&#93;</span></a></sup> this may not be a requirement for many applications. For example, the naive Bayes classifier will make the correct <a href="/wiki/Maximum_a_posteriori_estimation" title="Maximum a posteriori estimation">MAP</a> decision rule classification so long as the correct class is predicted as more probable than any other class. This is true regardless of whether the probability estimate is slightly, or even grossly inaccurate. In this manner, the overall classifier can be robust enough to ignore serious deficiencies in its underlying naive probability model.<sup id="cite&#95;ref-rish&#95;17-0" class="reference"><a href="#cite_note-rish-17"><span class="cite-bracket">&#91;</span>17<span class="cite-bracket">&#93;</span></a></sup> Other reasons for the observed success of the naive Bayes classifier are discussed in the literature cited below.
</p>
<div class="mw-heading mw-heading3"><h3 id="Relation_to_logistic_regression">Relation to logistic regression</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=10" title="Edit section: Relation to logistic regression"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>In the case of discrete inputs (indicator or frequency features for discrete events), naive Bayes classifiers form a <i>generative-discriminative</i> pair with <a href="/wiki/Multinomial_logistic_regression" title="Multinomial logistic regression">multinomial logistic regression</a> classifiers: each naive Bayes classifier can be considered a way of fitting a probability model that optimizes the joint likelihood <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(C,\mathbf {x} )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>C</mi>
        <mo>,</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(C,\mathbf {x} )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/488f4d23e9744cb0b5609bcf7055ce54402855ed" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:7.279ex; height:2.843ex;" alt="{\displaystyle p(C,\mathbf {x} )}"></span>, while logistic regression fits the same probability model to optimize the conditional <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(C\mid \mathbf {x} )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>C</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(C\mid \mathbf {x} )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/80877fa91c750a7115f9394dd3cd6ee85f598a0f" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:8.183ex; height:2.843ex;" alt="{\displaystyle p(C\mid \mathbf {x} )}"></span>.<sup id="cite&#95;ref-pair&#95;18-0" class="reference"><a href="#cite_note-pair-18"><span class="cite-bracket">&#91;</span>18<span class="cite-bracket">&#93;</span></a></sup>
</p><p>More formally, we have the following:
</p>
<style data-mw-deduplicate="TemplateStyles:r1110004140">.mw-parser-output .math_theorem{margin:1em 2em;padding:0.5em 1em 0.4em;border:1px solid #aaa;overflow:hidden}@media(max-width:500px){.mw-parser-output .math_theorem{margin:1em 0em;padding:0.5em 0.5em 0.4em}}</style><div class="math&#95;theorem" style="">
<p><strong class="theorem-name">Theorem</strong><span class="theoreme-tiret">—</span>Naive Bayes classifiers on binary features are subsumed by logistic regression classifiers.
</p>
</div>
<style data-mw-deduplicate="TemplateStyles:r1174254338">.mw-parser-output .math_proof{border:thin solid #aaa;margin:1em 2em;padding:0.5em 1em 0.4em}@media(max-width:500px){.mw-parser-output .math_proof{margin:1em 0;padding:0.5em 0.5em 0.4em}}</style><div class="math&#95;proof" style=""><strong>Proof</strong>
<p>Consider a generic multiclass classification problem, with possible classes <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle Y\in \{1,...,n\}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
        <mo>&#x2208;<!-- ∈ --></mo>
        <mo fence="false" stretchy="false">{</mo>
        <mn>1</mn>
        <mo>,</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>.</mo>
        <mo>,</mo>
        <mi>n</mi>
        <mo fence="false" stretchy="false">}</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y\in \{1,...,n\}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b835c57686df2fb513468d924e4e14e5b80a72b7" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:14.666ex; height:2.843ex;" alt="{\displaystyle Y\in \{1,...,n\}}"></span>, then the (non-naive) Bayes classifier gives, by Bayes theorem:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(Y\mid X=x)={\text{softmax}}(\{\ln p(Y=k)+\ln p(X=x\mid Y=k)\}_{k})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>X</mi>
        <mo>=</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>softmax</mtext>
        </mrow>
        <mo stretchy="false">(</mo>
        <mo fence="false" stretchy="false">{</mo>
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>Y</mi>
        <mo>=</mo>
        <mi>k</mi>
        <mo stretchy="false">)</mo>
        <mo>+</mo>
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>X</mi>
        <mo>=</mo>
        <mi>x</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>Y</mi>
        <mo>=</mo>
        <mi>k</mi>
        <mo stretchy="false">)</mo>
        <msub>
          <mo fence="false" stretchy="false">}</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(Y\mid X=x)={\text{softmax}}(\{\ln p(Y=k)+\ln p(X=x\mid Y=k)\}_{k})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5ceb5d8b890ed4fb2afd4b0529d8ccd86cca4a06" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:63.491ex; height:2.843ex;" alt="{\displaystyle p(Y\mid X=x)={\text{softmax}}(\{\ln p(Y=k)+\ln p(X=x\mid Y=k)\}_{k})}"></span>
</p><p>The naive Bayes classifier gives  
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\text{softmax}}\left(\left\{\ln p(Y=k)+{\frac {1}{2}}\sum _{i}(a_{i,k}^{+}-a_{i,k}^{-})x_{i}+(a_{i,k}^{+}+a_{i,k}^{-})\right\}_{k}\right)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>softmax</mtext>
        </mrow>
        <mrow>
          <mo>(</mo>
          <msub>
            <mrow>
              <mo>{</mo>
              <mrow>
                <mi>ln</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <mi>Y</mi>
                <mo>=</mo>
                <mi>k</mi>
                <mo stretchy="false">)</mo>
                <mo>+</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mfrac>
                    <mn>1</mn>
                    <mn>2</mn>
                  </mfrac>
                </mrow>
                <munder>
                  <mo>&#x2211;<!-- ∑ --></mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </munder>
                <mo stretchy="false">(</mo>
                <msubsup>
                  <mi>a</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                    <mo>,</mo>
                    <mi>k</mi>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo>+</mo>
                  </mrow>
                </msubsup>
                <mo>&#x2212;<!-- − --></mo>
                <msubsup>
                  <mi>a</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                    <mo>,</mo>
                    <mi>k</mi>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo>&#x2212;<!-- − --></mo>
                  </mrow>
                </msubsup>
                <mo stretchy="false">)</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <mo stretchy="false">(</mo>
                <msubsup>
                  <mi>a</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                    <mo>,</mo>
                    <mi>k</mi>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo>+</mo>
                  </mrow>
                </msubsup>
                <mo>+</mo>
                <msubsup>
                  <mi>a</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                    <mo>,</mo>
                    <mi>k</mi>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo>&#x2212;<!-- − --></mo>
                  </mrow>
                </msubsup>
                <mo stretchy="false">)</mo>
              </mrow>
              <mo>}</mo>
            </mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>k</mi>
            </mrow>
          </msub>
          <mo>)</mo>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\text{softmax}}\left(\left\{\ln p(Y=k)+{\frac {1}{2}}\sum _{i}(a_{i,k}^{+}-a_{i,k}^{-})x_{i}+(a_{i,k}^{+}+a_{i,k}^{-})\right\}_{k}\right)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/42aae9b53cfdd2cc9a99eb0a8edf481a0ce90342" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.338ex; width:64.536ex; height:7.676ex;" alt="{\displaystyle {\text{softmax}}\left(\left\{\ln p(Y=k)+{\frac {1}{2}}\sum _{i}(a_{i,k}^{+}-a_{i,k}^{-})x_{i}+(a_{i,k}^{+}+a_{i,k}^{-})\right\}_{k}\right)}"></span>
where   
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle a_{i,s}^{+}=\ln p(X_{i}=+1\mid Y=s);\quad a_{i,s}^{-}=\ln p(X_{i}=-1\mid Y=s)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msubsup>
          <mi>a</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>,</mo>
            <mi>s</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>+</mo>
          </mrow>
        </msubsup>
        <mo>=</mo>
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mo>+</mo>
        <mn>1</mn>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>Y</mi>
        <mo>=</mo>
        <mi>s</mi>
        <mo stretchy="false">)</mo>
        <mo>;</mo>
        <mspace width="1em" />
        <msubsup>
          <mi>a</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>,</mo>
            <mi>s</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
          </mrow>
        </msubsup>
        <mo>=</mo>
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mn>1</mn>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>Y</mi>
        <mo>=</mo>
        <mi>s</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle a_{i,s}^{+}=\ln p(X_{i}=+1\mid Y=s);\quad a_{i,s}^{-}=\ln p(X_{i}=-1\mid Y=s)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ba817f911a5373395a9cb60da870fd3379af3813" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -1.338ex; width:60.064ex; height:3.509ex;" alt="{\displaystyle a_{i,s}^{+}=\ln p(X_{i}=+1\mid Y=s);\quad a_{i,s}^{-}=\ln p(X_{i}=-1\mid Y=s)}"></span>
</p><p>This is exactly a logistic regression classifier.
</p>
</div>
<p>The link between the two can be seen by observing that the decision function for naive Bayes (in the binary case) can be rewritten as "predict class <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C_{1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C_{1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/babf569931f1a7b5182b9bec51873c2f5692fbb8" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.716ex; height:2.509ex;" alt="{\displaystyle C_{1}}"></span> if the <a href="/wiki/Odds" title="Odds">odds</a> of <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(C_{1}\mid \mathbf {x} )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(C_{1}\mid \mathbf {x} )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/83b34fd01d5b9727ccff40007802207b11984036" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:9.132ex; height:2.843ex;" alt="{\displaystyle p(C_{1}\mid \mathbf {x} )}"></span> exceed those of <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(C_{2}\mid \mathbf {x} )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(C_{2}\mid \mathbf {x} )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6268f020c484ee3ab0c3be4c3a79cbe73ab7b5ec" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:9.132ex; height:2.843ex;" alt="{\displaystyle p(C_{2}\mid \mathbf {x} )}"></span>". Expressing this in log-space gives:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \log {\frac {p(C_{1}\mid \mathbf {x} )}{p(C_{2}\mid \mathbf {x} )}}=\log p(C_{1}\mid \mathbf {x} )-\log p(C_{2}\mid \mathbf {x} )&gt;0}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>log</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>C</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi mathvariant="bold">x</mi>
              </mrow>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>C</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>2</mn>
                </mrow>
              </msub>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi mathvariant="bold">x</mi>
              </mrow>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mo>=</mo>
        <mi>log</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mi>log</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>&gt;</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \log {\frac {p(C_{1}\mid \mathbf {x} )}{p(C_{2}\mid \mathbf {x} )}}=\log p(C_{1}\mid \mathbf {x} )-\log p(C_{2}\mid \mathbf {x} )&gt;0}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/37124050a930aaa468f14ebf14a7ebac1a455438" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.671ex; width:48.241ex; height:6.509ex;" alt="{\displaystyle \log {\frac {p(C_{1}\mid \mathbf {x} )}{p(C_{2}\mid \mathbf {x} )}}=\log p(C_{1}\mid \mathbf {x} )-\log p(C_{2}\mid \mathbf {x} )&gt;0}"></span>
</p><p>The left-hand side of this equation is the log-odds, or <i><a href="/wiki/Logit" title="Logit">logit</a></i>, the quantity predicted by the linear model that underlies logistic regression. Since naive Bayes is also a linear model for the two "discrete" event models, it can be reparametrised as a linear function <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle b+\mathbf {w} ^{\top }x&gt;0}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>b</mi>
        <mo>+</mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="bold">w</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x22A4;<!-- ⊤ --></mi>
          </mrow>
        </msup>
        <mi>x</mi>
        <mo>&gt;</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle b+\mathbf {w} ^{\top }x&gt;0}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/40c61e5290816a7a0b5977ada0443c6bd8c75a6a" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.505ex; width:12.871ex; height:2.843ex;" alt="{\displaystyle b+\mathbf {w} ^{\top }x&gt;0}"></span>. Obtaining the probabilities is then a matter of applying the <a href="/wiki/Logistic_function" title="Logistic function">logistic function</a> to <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle b+\mathbf {w} ^{\top }x}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>b</mi>
        <mo>+</mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="bold">w</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x22A4;<!-- ⊤ --></mi>
          </mrow>
        </msup>
        <mi>x</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle b+\mathbf {w} ^{\top }x}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4d0dbb7fb3c5b7e0649fc1c4e758da91fa8447d5" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.505ex; width:8.61ex; height:2.843ex;" alt="{\displaystyle b+\mathbf {w} ^{\top }x}"></span>, or in the multiclass case, the <a href="/wiki/Softmax_function" title="Softmax function">softmax function</a>.
</p><p>Discriminative classifiers have lower asymptotic error than generative ones; however, research by <a href="/wiki/Andrew_Ng" title="Andrew Ng">Ng</a> and <a href="/wiki/Michael_I._Jordan" title="Michael I. Jordan">Jordan</a> has shown that in some practical cases naive Bayes can outperform logistic regression because it reaches its asymptotic error faster.<sup id="cite&#95;ref-pair&#95;18-1" class="reference"><a href="#cite_note-pair-18"><span class="cite-bracket">&#91;</span>18<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading2"><h2 id="Examples">Examples</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=11" title="Edit section: Examples"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<div class="mw-heading mw-heading3"><h3 id="Person_classification">Person classification</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=12" title="Edit section: Person classification"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>Problem: classify whether a given person is a male or a female based on the measured features.
The features include height, weight, and foot size. Although with NB classifier we treat them as independent, they are not in reality.
</p>
<div class="mw-heading mw-heading4"><h4 id="Training">Training</h4><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=13" title="Edit section: Training"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>Example training set below.
</p>
<table class="wikitable">

<tbody><tr>
<th>Person</th>
<th>height (feet)</th>
<th>weight (lbs)</th>
<th>foot size (inches)
</th></tr>
<tr>
<td>male</td>
<td>6</td>
<td>180</td>
<td>12
</td></tr>
<tr>
<td>male</td>
<td>5.92 (5'11")</td>
<td>190</td>
<td>11
</td></tr>
<tr>
<td>male</td>
<td>5.58 (5'7")</td>
<td>170</td>
<td>12
</td></tr>
<tr>
<td>male</td>
<td>5.92 (5'11")</td>
<td>165</td>
<td>10
</td></tr>
<tr>
<td>female</td>
<td>5</td>
<td>100</td>
<td>6
</td></tr>
<tr>
<td>female</td>
<td>5.5 (5'6")</td>
<td>150</td>
<td>8
</td></tr>
<tr>
<td>female</td>
<td>5.42 (5'5")</td>
<td>130</td>
<td>7
</td></tr>
<tr>
<td>female</td>
<td>5.75 (5'9")</td>
<td>150</td>
<td>9
</td></tr>
</tbody></table>
<p>The classifier created from the training set using a Gaussian distribution assumption would be (given variances are <i>unbiased</i> <a href="/wiki/Variance#Population_variance_and_sample_variance" title="Variance">sample variances</a>):
</p>
<table class="wikitable">

<tbody><tr>
<th>Person</th>
<th>mean (height)</th>
<th>variance (height)</th>
<th>mean (weight)</th>
<th>variance (weight)</th>
<th>mean (foot size)</th>
<th>variance (foot size)
</th></tr>
<tr>
<td>male</td>
<td>5.855</td>
<td>3.5033 × 10<sup>−2</sup></td>
<td>176.25</td>
<td>12.292</td>
<td>11.25</td>
<td>9.1667 × 10<sup>−1</sup>
</td></tr>
<tr>
<td>female</td>
<td>5.4175</td>
<td>9.7225 × 10<sup>−2</sup></td>
<td>132.5</td>
<td>5.5833</td>
<td>7.5</td>
<td>1.6667
</td></tr></tbody></table>
<p>The following example assumes equiprobable classes so that P(male)= P(female) = 0.5. This prior <a href="/wiki/Probability_distribution" title="Probability distribution">probability distribution</a> might be based on prior knowledge of frequencies in the larger population or in the training set.
</p>
<div class="mw-heading mw-heading4"><h4 id="Testing">Testing</h4><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=14" title="Edit section: Testing"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>Below is a sample to be classified as male or female.
</p>
<table class="wikitable">

<tbody><tr>
<th>Person</th>
<th>height (feet)</th>
<th>weight (lbs)</th>
<th>foot size (inches)
</th></tr>
<tr>
<td>sample</td>
<td>6</td>
<td>130</td>
<td>8
</td></tr></tbody></table>
<p>In order to classify the sample, one has to determine which posterior is greater, male or female. For the classification as male the posterior is given by
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\text{posterior (male)}}={\frac {P({\text{male}})\,p({\text{height}}\mid {\text{male}})\,p({\text{weight}}\mid {\text{male}})\,p({\text{foot size}}\mid {\text{male}})}{\text{evidence}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>posterior (male)</mtext>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>male</mtext>
              </mrow>
              <mo stretchy="false">)</mo>
              <mspace width="thinmathspace" />
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>height</mtext>
              </mrow>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>male</mtext>
              </mrow>
              <mo stretchy="false">)</mo>
              <mspace width="thinmathspace" />
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>weight</mtext>
              </mrow>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>male</mtext>
              </mrow>
              <mo stretchy="false">)</mo>
              <mspace width="thinmathspace" />
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>foot size</mtext>
              </mrow>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>male</mtext>
              </mrow>
              <mo stretchy="false">)</mo>
            </mrow>
            <mtext>evidence</mtext>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\text{posterior (male)}}={\frac {P({\text{male}})\,p({\text{height}}\mid {\text{male}})\,p({\text{weight}}\mid {\text{male}})\,p({\text{foot size}}\mid {\text{male}})}{\text{evidence}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dc2d12c469e62e9ea617e65a0edf87d3fcfb13eb" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.005ex; width:79.815ex; height:5.843ex;" alt="{\displaystyle {\text{posterior (male)}}={\frac {P({\text{male}})\,p({\text{height}}\mid {\text{male}})\,p({\text{weight}}\mid {\text{male}})\,p({\text{foot size}}\mid {\text{male}})}{\text{evidence}}}}"></span>
</p><p>For the classification as female the posterior is given by
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\text{posterior (female)}}={\frac {P({\text{female}})\,p({\text{height}}\mid {\text{female}})\,p({\text{weight}}\mid {\text{female}})\,p({\text{foot size}}\mid {\text{female}})}{\text{evidence}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>posterior (female)</mtext>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>P</mi>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>female</mtext>
              </mrow>
              <mo stretchy="false">)</mo>
              <mspace width="thinmathspace" />
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>height</mtext>
              </mrow>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>female</mtext>
              </mrow>
              <mo stretchy="false">)</mo>
              <mspace width="thinmathspace" />
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>weight</mtext>
              </mrow>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>female</mtext>
              </mrow>
              <mo stretchy="false">)</mo>
              <mspace width="thinmathspace" />
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>foot size</mtext>
              </mrow>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mtext>female</mtext>
              </mrow>
              <mo stretchy="false">)</mo>
            </mrow>
            <mtext>evidence</mtext>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\text{posterior (female)}}={\frac {P({\text{female}})\,p({\text{height}}\mid {\text{female}})\,p({\text{weight}}\mid {\text{female}})\,p({\text{foot size}}\mid {\text{female}})}{\text{evidence}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e3f355ca64c1dc356b3f4cdd5e2d5b13cc2b80e5" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.005ex; width:88.536ex; height:5.843ex;" alt="{\displaystyle {\text{posterior (female)}}={\frac {P({\text{female}})\,p({\text{height}}\mid {\text{female}})\,p({\text{weight}}\mid {\text{female}})\,p({\text{foot size}}\mid {\text{female}})}{\text{evidence}}}}"></span>
</p><p>The evidence (also termed normalizing constant) may be calculated:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{aligned}{\text{evidence}}=P({\text{male}})\,p({\text{height}}\mid {\text{male}})\,p({\text{weight}}\mid {\text{male}})\,p({\text{foot size}}\mid {\text{male}})\\+P({\text{female}})\,p({\text{height}}\mid {\text{female}})\,p({\text{weight}}\mid {\text{female}})\,p({\text{foot size}}\mid {\text{female}})\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>evidence</mtext>
                </mrow>
                <mo>=</mo>
                <mi>P</mi>
                <mo stretchy="false">(</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>male</mtext>
                </mrow>
                <mo stretchy="false">)</mo>
                <mspace width="thinmathspace" />
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>height</mtext>
                </mrow>
                <mo>&#x2223;<!-- ∣ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>male</mtext>
                </mrow>
                <mo stretchy="false">)</mo>
                <mspace width="thinmathspace" />
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>weight</mtext>
                </mrow>
                <mo>&#x2223;<!-- ∣ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>male</mtext>
                </mrow>
                <mo stretchy="false">)</mo>
                <mspace width="thinmathspace" />
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>foot size</mtext>
                </mrow>
                <mo>&#x2223;<!-- ∣ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>male</mtext>
                </mrow>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mo>+</mo>
                <mi>P</mi>
                <mo stretchy="false">(</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>female</mtext>
                </mrow>
                <mo stretchy="false">)</mo>
                <mspace width="thinmathspace" />
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>height</mtext>
                </mrow>
                <mo>&#x2223;<!-- ∣ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>female</mtext>
                </mrow>
                <mo stretchy="false">)</mo>
                <mspace width="thinmathspace" />
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>weight</mtext>
                </mrow>
                <mo>&#x2223;<!-- ∣ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>female</mtext>
                </mrow>
                <mo stretchy="false">)</mo>
                <mspace width="thinmathspace" />
                <mi>p</mi>
                <mo stretchy="false">(</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>foot size</mtext>
                </mrow>
                <mo>&#x2223;<!-- ∣ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>female</mtext>
                </mrow>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}{\text{evidence}}=P({\text{male}})\,p({\text{height}}\mid {\text{male}})\,p({\text{weight}}\mid {\text{male}})\,p({\text{foot size}}\mid {\text{male}})\\+P({\text{female}})\,p({\text{height}}\mid {\text{female}})\,p({\text{weight}}\mid {\text{female}})\,p({\text{foot size}}\mid {\text{female}})\end{aligned}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5e55a93d4e843a327a0fc8ba9e478ee83ce224bb" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.505ex; width:72.211ex; height:6.176ex;" alt="{\displaystyle {\begin{aligned}{\text{evidence}}=P({\text{male}})\,p({\text{height}}\mid {\text{male}})\,p({\text{weight}}\mid {\text{male}})\,p({\text{foot size}}\mid {\text{male}})\\+P({\text{female}})\,p({\text{height}}\mid {\text{female}})\,p({\text{weight}}\mid {\text{female}})\,p({\text{foot size}}\mid {\text{female}})\end{aligned}}}"></span>
</p><p>However, given the sample, the evidence is a constant and thus scales both posteriors equally. It therefore does not affect classification and can be ignored.  The <a href="/wiki/Probability_distribution" title="Probability distribution">probability distribution</a> for the sex of the sample can now be determined:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle P({\text{male}})=0.5}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>male</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>0.5</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P({\text{male}})=0.5}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/432fe7ff8c39338bf617ba38a15d5abbe93d4c9d" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:14.403ex; height:2.843ex;" alt="{\displaystyle P({\text{male}})=0.5}"></span>
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p({\text{height}}\mid {\text{male}})={\frac {1}{\sqrt {2\pi \sigma ^{2}}}}\exp \left({\frac {-(6-\mu )^{2}}{2\sigma ^{2}}}\right)\approx 1.5789,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>height</mtext>
        </mrow>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>male</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <msqrt>
              <mn>2</mn>
              <mi>&#x03C0;<!-- π --></mi>
              <msup>
                <mi>&#x03C3;<!-- σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>2</mn>
                </mrow>
              </msup>
            </msqrt>
          </mfrac>
        </mrow>
        <mi>exp</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow>
          <mo>(</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mfrac>
              <mrow>
                <mo>&#x2212;<!-- − --></mo>
                <mo stretchy="false">(</mo>
                <mn>6</mn>
                <mo>&#x2212;<!-- − --></mo>
                <mi>&#x03BC;<!-- μ --></mi>
                <msup>
                  <mo stretchy="false">)</mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msup>
              </mrow>
              <mrow>
                <mn>2</mn>
                <msup>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msup>
              </mrow>
            </mfrac>
          </mrow>
          <mo>)</mo>
        </mrow>
        <mo>&#x2248;<!-- ≈ --></mo>
        <mn>1.5789</mn>
        <mo>,</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p({\text{height}}\mid {\text{male}})={\frac {1}{\sqrt {2\pi \sigma ^{2}}}}\exp \left({\frac {-(6-\mu )^{2}}{2\sigma ^{2}}}\right)\approx 1.5789,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e19b6779eb5083dee1770685332835f9726b1c56" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.171ex; margin-left: -0.089ex; width:55.601ex; height:7.509ex;" alt="{\displaystyle p({\text{height}}\mid {\text{male}})={\frac {1}{\sqrt {2\pi \sigma ^{2}}}}\exp \left({\frac {-(6-\mu )^{2}}{2\sigma ^{2}}}\right)\approx 1.5789,}"></span>
where <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mu =5.855}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03BC;<!-- μ --></mi>
        <mo>=</mo>
        <mn>5.855</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mu =5.855}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ae507e8985601ea0c677ef30b682a857501dce0c" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:9.797ex; height:2.676ex;" alt="{\displaystyle \mu =5.855}"></span> and <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \sigma ^{2}=3.5033\cdot 10^{-2}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>&#x03C3;<!-- σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msup>
        <mo>=</mo>
        <mn>3.5033</mn>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <msup>
          <mn>10</mn>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>2</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma ^{2}=3.5033\cdot 10^{-2}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a0a1653c6992afe8681759a949dd56686c9b5fc0" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:18.279ex; height:2.676ex;" alt="{\displaystyle \sigma ^{2}=3.5033\cdot 10^{-2}}"></span> are the parameters of normal distribution which have been previously determined from the training set. Note that a value greater than 1 is OK here – it is a probability density rather than a probability, because <i>height</i> is a continuous variable.
</p><p><span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p({\text{weight}}\mid {\text{male}})={\frac {1}{\sqrt {2\pi \sigma ^{2}}}}\exp \left({\frac {-(130-\mu )^{2}}{2\sigma ^{2}}}\right)=5.9881\cdot 10^{-6}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>weight</mtext>
        </mrow>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>male</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <msqrt>
              <mn>2</mn>
              <mi>&#x03C0;<!-- π --></mi>
              <msup>
                <mi>&#x03C3;<!-- σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>2</mn>
                </mrow>
              </msup>
            </msqrt>
          </mfrac>
        </mrow>
        <mi>exp</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow>
          <mo>(</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mfrac>
              <mrow>
                <mo>&#x2212;<!-- − --></mo>
                <mo stretchy="false">(</mo>
                <mn>130</mn>
                <mo>&#x2212;<!-- − --></mo>
                <mi>&#x03BC;<!-- μ --></mi>
                <msup>
                  <mo stretchy="false">)</mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msup>
              </mrow>
              <mrow>
                <mn>2</mn>
                <msup>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msup>
              </mrow>
            </mfrac>
          </mrow>
          <mo>)</mo>
        </mrow>
        <mo>=</mo>
        <mn>5.9881</mn>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <msup>
          <mn>10</mn>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>6</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p({\text{weight}}\mid {\text{male}})={\frac {1}{\sqrt {2\pi \sigma ^{2}}}}\exp \left({\frac {-(130-\mu )^{2}}{2\sigma ^{2}}}\right)=5.9881\cdot 10^{-6}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d8fec29de1aa07efe199c32c8efa01a54c8e5330" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.171ex; margin-left: -0.089ex; width:64.002ex; height:7.509ex;" alt="{\displaystyle p({\text{weight}}\mid {\text{male}})={\frac {1}{\sqrt {2\pi \sigma ^{2}}}}\exp \left({\frac {-(130-\mu )^{2}}{2\sigma ^{2}}}\right)=5.9881\cdot 10^{-6}}"></span>
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p({\text{foot size}}\mid {\text{male}})={\frac {1}{\sqrt {2\pi \sigma ^{2}}}}\exp \left({\frac {-(8-\mu )^{2}}{2\sigma ^{2}}}\right)=1.3112\cdot 10^{-3}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>foot size</mtext>
        </mrow>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>male</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <msqrt>
              <mn>2</mn>
              <mi>&#x03C0;<!-- π --></mi>
              <msup>
                <mi>&#x03C3;<!-- σ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>2</mn>
                </mrow>
              </msup>
            </msqrt>
          </mfrac>
        </mrow>
        <mi>exp</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow>
          <mo>(</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mfrac>
              <mrow>
                <mo>&#x2212;<!-- − --></mo>
                <mo stretchy="false">(</mo>
                <mn>8</mn>
                <mo>&#x2212;<!-- − --></mo>
                <mi>&#x03BC;<!-- μ --></mi>
                <msup>
                  <mo stretchy="false">)</mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msup>
              </mrow>
              <mrow>
                <mn>2</mn>
                <msup>
                  <mi>&#x03C3;<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msup>
              </mrow>
            </mfrac>
          </mrow>
          <mo>)</mo>
        </mrow>
        <mo>=</mo>
        <mn>1.3112</mn>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <msup>
          <mn>10</mn>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>3</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p({\text{foot size}}\mid {\text{male}})={\frac {1}{\sqrt {2\pi \sigma ^{2}}}}\exp \left({\frac {-(8-\mu )^{2}}{2\sigma ^{2}}}\right)=1.3112\cdot 10^{-3}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/95d723e278cff4af8b6ba16bf69c041cedc9eeec" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.171ex; margin-left: -0.089ex; width:63.11ex; height:7.509ex;" alt="{\displaystyle p({\text{foot size}}\mid {\text{male}})={\frac {1}{\sqrt {2\pi \sigma ^{2}}}}\exp \left({\frac {-(8-\mu )^{2}}{2\sigma ^{2}}}\right)=1.3112\cdot 10^{-3}}"></span>
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\text{posterior numerator (male)}}={\text{their product}}=6.1984\cdot 10^{-9}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>posterior numerator (male)</mtext>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>their product</mtext>
        </mrow>
        <mo>=</mo>
        <mn>6.1984</mn>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <msup>
          <mn>10</mn>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>9</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\text{posterior numerator (male)}}={\text{their product}}=6.1984\cdot 10^{-9}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ce53bbf9519d178e25b85b2fcaa4ecfcb9da8c9e" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:59.545ex; height:3.176ex;" alt="{\displaystyle {\text{posterior numerator (male)}}={\text{their product}}=6.1984\cdot 10^{-9}}"></span>
</p><p><span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle P({\text{female}})=0.5}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>female</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>0.5</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle P({\text{female}})=0.5}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1d0763834e7529a745b9d25c6061ca9cc0844633" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:16.147ex; height:2.843ex;" alt="{\displaystyle P({\text{female}})=0.5}"></span>
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p({\text{height}}\mid {\text{female}})=2.23\cdot 10^{-1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>height</mtext>
        </mrow>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>female</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>2.23</mn>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <msup>
          <mn>10</mn>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p({\text{height}}\mid {\text{female}})=2.23\cdot 10^{-1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/33a7426eeeaaef1291401e8b74eeb9089e19944f" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:31.428ex; height:3.176ex;" alt="{\displaystyle p({\text{height}}\mid {\text{female}})=2.23\cdot 10^{-1}}"></span>
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p({\text{weight}}\mid {\text{female}})=1.6789\cdot 10^{-2}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>weight</mtext>
        </mrow>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>female</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>1.6789</mn>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <msup>
          <mn>10</mn>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>2</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p({\text{weight}}\mid {\text{female}})=1.6789\cdot 10^{-2}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/59266284704ac3adb7c49bf3c68d3a1490da643f" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:34.138ex; height:3.176ex;" alt="{\displaystyle p({\text{weight}}\mid {\text{female}})=1.6789\cdot 10^{-2}}"></span>
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p({\text{foot size}}\mid {\text{female}})=2.8669\cdot 10^{-1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>foot size</mtext>
        </mrow>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>female</mtext>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mn>2.8669</mn>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <msup>
          <mn>10</mn>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p({\text{foot size}}\mid {\text{female}})=2.8669\cdot 10^{-1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e268d08bcbb136cadcccd6381493938c118d77c7" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:35.571ex; height:3.176ex;" alt="{\displaystyle p({\text{foot size}}\mid {\text{female}})=2.8669\cdot 10^{-1}}"></span>
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\text{posterior numerator (female)}}={\text{their product}}=5.3778\cdot 10^{-4}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>posterior numerator (female)</mtext>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>their product</mtext>
        </mrow>
        <mo>=</mo>
        <mn>5.3778</mn>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <msup>
          <mn>10</mn>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>4</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\text{posterior numerator (female)}}={\text{their product}}=5.3778\cdot 10^{-4}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0970c41d887243c6eecd02463e714b97c986483c" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:61.29ex; height:3.176ex;" alt="{\displaystyle {\text{posterior numerator (female)}}={\text{their product}}=5.3778\cdot 10^{-4}}"></span>
</p><p>Since posterior numerator is greater in the female case, the prediction is that the sample is female.
</p>
<div class="mw-heading mw-heading3"><h3 id="Document_classification">Document classification</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=15" title="Edit section: Document classification"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>Here is a worked example of naive Bayesian classification to the <a href="/wiki/Document_classification" title="Document classification">document classification</a> problem.
Consider the problem of classifying documents by their content, for example into <a href="/wiki/Spamming" title="Spamming">spam</a> and non-spam <a href="/wiki/E-mail" class="mw-redirect" title="E-mail">e-mails</a>. Imagine that documents are drawn from a number of classes of documents which can be modeled as sets of words where the (independent) probability that the i-th word of a given document occurs in a document from class <i>C</i> can be written as
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(w_{i}\mid C)\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>w</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>C</mi>
        <mo stretchy="false">)</mo>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(w_{i}\mid C)\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/31d6dee54454209ba0810f0ce4f43bc087a89a9c" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:9.623ex; height:2.843ex;" alt="{\displaystyle p(w_{i}\mid C)\,}"></span>
</p><p>(For this treatment, things are further simplified by assuming that words are randomly distributed in the document - that is, words are not dependent on the length of the document, position within the document with relation to other words, or other document-context.)
</p><p>Then the probability that a given document <i>D</i> contains all of the words <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle w_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>w</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle w_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fe22f0329d3ecb2e1880d44d191aba0e5475db68" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.464ex; height:2.009ex;" alt="{\displaystyle w_{i}}"></span>, given a class <i>C</i>, is
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(D\mid C)=\prod _{i}p(w_{i}\mid C)\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>D</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>C</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <munder>
          <mo>&#x220F;<!-- ∏ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </munder>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>w</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>C</mi>
        <mo stretchy="false">)</mo>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(D\mid C)=\prod _{i}p(w_{i}\mid C)\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/da8731e764229a04435495b39e054009c9bc6ed9" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.005ex; margin-left: -0.089ex; width:24.684ex; height:5.509ex;" alt="{\displaystyle p(D\mid C)=\prod _{i}p(w_{i}\mid C)\,}"></span>
</p><p>The question that has to be answered is: "what is the probability that a given document <i>D</i> belongs to a given class <i>C</i>?" In other words, what is <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(C\mid D)\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>C</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>D</mi>
        <mo stretchy="false">)</mo>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(C\mid D)\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d7bdbec03513d9cf8a883cee71fdb2ff4641f31b" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:9.083ex; height:2.843ex;" alt="{\displaystyle p(C\mid D)\,}"></span>?
</p><p>Now <a href="/wiki/Conditional_probability" title="Conditional probability">by definition</a>
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(D\mid C)={p(D\cap C) \over p(C)}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>D</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>C</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>D</mi>
              <mo>&#x2229;<!-- ∩ --></mo>
              <mi>C</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>C</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(D\mid C)={p(D\cap C) \over p(C)}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b1bdbedbaf6ff0a18e80e86fa3ce0b50e3c79f68" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.671ex; margin-left: -0.089ex; width:21.882ex; height:6.509ex;" alt="{\displaystyle p(D\mid C)={p(D\cap C) \over p(C)}}"></span>
and
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(C\mid D)={p(D\cap C) \over p(D)}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>C</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>D</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>D</mi>
              <mo>&#x2229;<!-- ∩ --></mo>
              <mi>C</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>D</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(C\mid D)={p(D\cap C) \over p(D)}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3aa5049dfe735fc4cef7b54c43e41f9d9a1da327" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.671ex; margin-left: -0.089ex; width:21.882ex; height:6.509ex;" alt="{\displaystyle p(C\mid D)={p(D\cap C) \over p(D)}}"></span>
</p><p>Bayes' theorem manipulates these into a statement of probability in terms of <a href="/wiki/Likelihood" class="mw-redirect" title="Likelihood">likelihood</a>.
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(C\mid D)={\frac {p(C)\,p(D\mid C)}{p(D)}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>C</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>D</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>C</mi>
              <mo stretchy="false">)</mo>
              <mspace width="thinmathspace" />
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>D</mi>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi>C</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>D</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(C\mid D)={\frac {p(C)\,p(D\mid C)}{p(D)}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/89d6c6a3bc80cc0c768c81c37f268789ecd594c7" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.671ex; margin-left: -0.089ex; width:26.369ex; height:6.509ex;" alt="{\displaystyle p(C\mid D)={\frac {p(C)\,p(D\mid C)}{p(D)}}}"></span>
</p><p>Assume for the moment that there are only two mutually exclusive classes, <i>S</i> and ¬<i>S</i> (e.g. spam and not spam), such that every element (email) is in either one or the other;
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(D\mid S)=\prod _{i}p(w_{i}\mid S)\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>D</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>S</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <munder>
          <mo>&#x220F;<!-- ∏ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </munder>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>w</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>S</mi>
        <mo stretchy="false">)</mo>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(D\mid S)=\prod _{i}p(w_{i}\mid S)\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/153fa96d71a4a1773b8f02278be0c26a2629604d" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.005ex; margin-left: -0.089ex; width:24.15ex; height:5.509ex;" alt="{\displaystyle p(D\mid S)=\prod _{i}p(w_{i}\mid S)\,}"></span>
and
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(D\mid \neg S)=\prod _{i}p(w_{i}\mid \neg S)\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>D</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
        <mi>S</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <munder>
          <mo>&#x220F;<!-- ∏ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </munder>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>w</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
        <mi>S</mi>
        <mo stretchy="false">)</mo>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(D\mid \neg S)=\prod _{i}p(w_{i}\mid \neg S)\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2a1a235b9001dbcb715b445c24c14587c9a647be" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.005ex; margin-left: -0.089ex; width:27.25ex; height:5.509ex;" alt="{\displaystyle p(D\mid \neg S)=\prod _{i}p(w_{i}\mid \neg S)\,}"></span>
</p><p>Using the Bayesian result above, one can write:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(S\mid D)={p(S) \over p(D)}\,\prod _{i}p(w_{i}\mid S)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>S</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>D</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>D</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mspace width="thinmathspace" />
        <munder>
          <mo>&#x220F;<!-- ∏ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </munder>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>w</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>S</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(S\mid D)={p(S) \over p(D)}\,\prod _{i}p(w_{i}\mid S)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5a01664a790045539b08954de73e64872c9f0487" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.005ex; margin-left: -0.089ex; width:30.276ex; height:6.843ex;" alt="{\displaystyle p(S\mid D)={p(S) \over p(D)}\,\prod _{i}p(w_{i}\mid S)}"></span>
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(\neg S\mid D)={p(\neg S) \over p(D)}\,\prod _{i}p(w_{i}\mid \neg S)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
        <mi>S</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>D</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>D</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mspace width="thinmathspace" />
        <munder>
          <mo>&#x220F;<!-- ∏ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </munder>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>w</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
        <mi>S</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(\neg S\mid D)={p(\neg S) \over p(D)}\,\prod _{i}p(w_{i}\mid \neg S)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/81344b6278dae8f3977e11244a660653d0705089" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.005ex; margin-left: -0.089ex; width:34.502ex; height:6.843ex;" alt="{\displaystyle p(\neg S\mid D)={p(\neg S) \over p(D)}\,\prod _{i}p(w_{i}\mid \neg S)}"></span>
</p><p>Dividing one by the other gives:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {p(S\mid D) \over p(\neg S\mid D)}={p(S)\,\prod _{i}p(w_{i}\mid S) \over p(\neg S)\,\prod _{i}p(w_{i}\mid \neg S)}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>S</mi>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi>D</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
              <mi>S</mi>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi>D</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
              <mspace width="thinmathspace" />
              <munder>
                <mo>&#x220F;<!-- ∏ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </munder>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>w</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
              <mspace width="thinmathspace" />
              <munder>
                <mo>&#x220F;<!-- ∏ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </munder>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>w</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {p(S\mid D) \over p(\neg S\mid D)}={p(S)\,\prod _{i}p(w_{i}\mid S) \over p(\neg S)\,\prod _{i}p(w_{i}\mid \neg S)}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c7e3cf05dff52d55fe1a416d68c32f8366b97a27" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.671ex; width:35.273ex; height:6.509ex;" alt="{\displaystyle {p(S\mid D) \over p(\neg S\mid D)}={p(S)\,\prod _{i}p(w_{i}\mid S) \over p(\neg S)\,\prod _{i}p(w_{i}\mid \neg S)}}"></span>
</p><p>Which can be re-factored as:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {p(S\mid D) \over p(\neg S\mid D)}={p(S) \over p(\neg S)}\,\prod _{i}{p(w_{i}\mid S) \over p(w_{i}\mid \neg S)}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>S</mi>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi>D</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
              <mi>S</mi>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi>D</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mspace width="thinmathspace" />
        <munder>
          <mo>&#x220F;<!-- ∏ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </munder>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>w</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>w</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {p(S\mid D) \over p(\neg S\mid D)}={p(S) \over p(\neg S)}\,\prod _{i}{p(w_{i}\mid S) \over p(w_{i}\mid \neg S)}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fdca5b69fef4a3c1af7c74a424a2c82d16d35834" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.005ex; width:36.085ex; height:6.843ex;" alt="{\displaystyle {p(S\mid D) \over p(\neg S\mid D)}={p(S) \over p(\neg S)}\,\prod _{i}{p(w_{i}\mid S) \over p(w_{i}\mid \neg S)}}"></span>
</p><p>Thus, the probability ratio p(<i>S</i> | <i>D</i>) / p(¬<i>S</i> | <i>D</i>) can be expressed in terms of a series of <a href="/wiki/Likelihood_function" title="Likelihood function">likelihood ratios</a>.
The actual probability p(<i>S</i> | <i>D</i>) can be easily computed from log (p(<i>S</i> | <i>D</i>) / p(¬<i>S</i> | <i>D</i>)) based on the observation that p(<i>S</i> | <i>D</i>) + p(¬<i>S</i> | <i>D</i>) = 1.
</p><p>Taking the <a href="/wiki/Logarithm" title="Logarithm">logarithm</a> of all these ratios, one obtains:
<span class="mwe-math-element mwe-math-element-block"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \ln {p(S\mid D) \over p(\neg S\mid D)}=\ln {p(S) \over p(\neg S)}+\sum _{i}\ln {p(w_{i}\mid S) \over p(w_{i}\mid \neg S)}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>S</mi>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi>D</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
              <mi>S</mi>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi>D</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mo>=</mo>
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mo>+</mo>
        <munder>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </munder>
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>w</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <msub>
                <mi>w</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \ln {p(S\mid D) \over p(\neg S\mid D)}=\ln {p(S) \over p(\neg S)}+\sum _{i}\ln {p(w_{i}\mid S) \over p(w_{i}\mid \neg S)}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/27a7c76f2ac006bb0b5b0bfbece6be527826751c" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.005ex; width:45.516ex; height:6.843ex;" alt="{\displaystyle \ln {p(S\mid D) \over p(\neg S\mid D)}=\ln {p(S) \over p(\neg S)}+\sum _{i}\ln {p(w_{i}\mid S) \over p(w_{i}\mid \neg S)}}"></span>
</p><p>(This technique of "<a href="/wiki/Log-likelihood_ratio" class="mw-redirect" title="Log-likelihood ratio">log-likelihood ratios</a>" is a common technique in statistics.
In the case of two mutually exclusive alternatives (such as this example), the conversion of a log-likelihood ratio to a probability takes the form of a <a href="/wiki/Sigmoid_curve" class="mw-redirect" title="Sigmoid curve">sigmoid curve</a>: see <a href="/wiki/Logit" title="Logit">logit</a> for details.)
</p><p>Finally, the document can be classified as follows.  It is spam if <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p(S\mid D)&gt;p(\neg S\mid D)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi>S</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>D</mi>
        <mo stretchy="false">)</mo>
        <mo>&gt;</mo>
        <mi>p</mi>
        <mo stretchy="false">(</mo>
        <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
        <mi>S</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mi>D</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p(S\mid D)&gt;p(\neg S\mid D)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3093d4746120e1b7bb3c4b9631bb4b6ada452374" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:21.417ex; height:2.843ex;" alt="{\displaystyle p(S\mid D)&gt;p(\neg S\mid D)}"></span> (i. e., <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \ln {p(S\mid D) \over p(\neg S\mid D)}&gt;0}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi>S</mi>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi>D</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>p</mi>
              <mo stretchy="false">(</mo>
              <mi mathvariant="normal">&#x00AC;<!-- ¬ --></mi>
              <mi>S</mi>
              <mo>&#x2223;<!-- ∣ --></mo>
              <mi>D</mi>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <mo>&gt;</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \ln {p(S\mid D) \over p(\neg S\mid D)}&gt;0}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b85897fb33ae5412b69b7370ea932b1753795c26" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.671ex; width:17.313ex; height:6.509ex;" alt="{\displaystyle \ln {p(S\mid D) \over p(\neg S\mid D)}&gt;0}"></span>), otherwise it is not spam.
</p>
<div class="mw-heading mw-heading3"><h3 id="Spam_filtering">Spam filtering</h3><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=16" title="Edit section: Spam filtering"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>Naive Bayes classifiers are a popular <a href="/wiki/Statistics" title="Statistics">statistical</a> technique of <a href="/wiki/E-mail_filtering" class="mw-redirect" title="E-mail filtering">e-mail filtering</a>. They typically use <a href="/wiki/Bag-of-words_model" title="Bag-of-words model">bag-of-words</a> features to identify <a href="/wiki/Email_spam" title="Email spam">email spam</a>, an approach commonly used in <a href="/wiki/Document_classification" title="Document classification">text classification</a>. Naive Bayes classifiers work by correlating the use of tokens (typically words, or sometimes other things), with spam and non-spam e-mails and then using <a href="/wiki/Bayes%27_theorem" title="Bayes&#39; theorem">Bayes' theorem</a> to calculate a probability that an email is or is not spam.
</p><p><b>Naive Bayes spam filtering</b> is a baseline technique for dealing with spam that can tailor itself to the email needs of individual users and give low <a href="/wiki/False_positive" class="mw-redirect" title="False positive">false positive</a> spam detection rates that are generally acceptable to users. Bayesian algorithms were used for email filtering as early as 1996.  Although naive Bayesian filters did not become popular until later, multiple programs were released in 1998 to address the growing problem of unwanted email.<sup id="cite&#95;ref-19" class="reference"><a href="#cite_note-19"><span class="cite-bracket">&#91;</span>19<span class="cite-bracket">&#93;</span></a></sup>  The first scholarly publication on Bayesian spam filtering was by Sahami et al. in 1998.<sup id="cite&#95;ref-20" class="reference"><a href="#cite_note-20"><span class="cite-bracket">&#91;</span>20<span class="cite-bracket">&#93;</span></a></sup>
</p><p>Variants of the basic technique have been implemented in a number of research works and commercial <a href="/wiki/Computer_software" class="mw-redirect" title="Computer software">software</a> products.<sup id="cite&#95;ref-21" class="reference"><a href="#cite_note-21"><span class="cite-bracket">&#91;</span>21<span class="cite-bracket">&#93;</span></a></sup> Many modern mail <a href="/wiki/Client_(computing)" title="Client (computing)">clients</a> implement Bayesian spam filtering. Users can also install separate <a href="/wiki/E-mail_filtering" class="mw-redirect" title="E-mail filtering">email filtering programs</a>. <a href="/wiki/Server-side" class="mw-redirect" title="Server-side">Server-side</a> email filters, such as <a href="/w/index.php?title=DSPAM&amp;action=edit&amp;redlink=1" class="new" title="DSPAM (page does not exist)">DSPAM</a>, <a href="/wiki/Rspamd" title="Rspamd">Rspamd</a>,<sup id="cite&#95;ref-22" class="reference"><a href="#cite_note-22"><span class="cite-bracket">&#91;</span>22<span class="cite-bracket">&#93;</span></a></sup> <a href="/wiki/SpamAssassin" class="mw-redirect" title="SpamAssassin">SpamAssassin</a>,<sup id="cite&#95;ref-twsSep14yy&#95;23-0" class="reference"><a href="#cite_note-twsSep14yy-23"><span class="cite-bracket">&#91;</span>23<span class="cite-bracket">&#93;</span></a></sup> <a href="/wiki/SpamBayes" title="SpamBayes">SpamBayes</a>,<sup id="cite&#95;ref-twsSep2&#95;24-0" class="reference"><a href="#cite_note-twsSep2-24"><span class="cite-bracket">&#91;</span>24<span class="cite-bracket">&#93;</span></a></sup> <a href="/wiki/Bogofilter" title="Bogofilter">Bogofilter</a>, and <a href="/wiki/Anti-Spam_SMTP_Proxy" title="Anti-Spam SMTP Proxy">ASSP</a>, make use of Bayesian spam filtering techniques, and the functionality is sometimes embedded within <a href="/wiki/Mail_server" class="mw-redirect" title="Mail server">mail server</a> software itself. <a href="/wiki/CRM114_(program)" title="CRM114 (program)">CRM114</a>, often cited as a Bayesian filter, is not intended to use a Bayes filter in production, but includes the ″unigram″ feature for reference.<sup id="cite&#95;ref-25" class="reference"><a href="#cite_note-25"><span class="cite-bracket">&#91;</span>25<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading4"><h4 id="Dealing_with_rare_words">Dealing with rare words</h4><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=17" title="Edit section: Dealing with rare words"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>In the case a word has never been met during the learning phase, both the numerator and the denominator are equal to zero, both in the general formula and in the spamicity formula. The software can decide to discard such words for which there is no information available.
</p><p>More generally, the words that were encountered only a few times during the learning phase cause a problem, because it would be an error to trust blindly the information they provide. A simple solution is to simply avoid taking such unreliable words into account as well.
</p><p>Applying again Bayes' theorem, and assuming the classification between spam and ham of the emails containing a given word ("replica") is a <a href="/wiki/Random_variable" title="Random variable">random variable</a> with <a href="/wiki/Beta_distribution" title="Beta distribution">beta distribution</a>, some programs decide to use a corrected probability:
</p>
<dl><dd><span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Pr '(S|W)={\frac {s\cdot \Pr(S)+n\cdot \Pr(S|W)}{s+n}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mo movablelimits="true" form="prefix">Pr</mo>
          <mo>&#x2032;</mo>
        </msup>
        <mo stretchy="false">(</mo>
        <mi>S</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>W</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>s</mi>
              <mo>&#x22C5;<!-- ⋅ --></mo>
              <mo movablelimits="true" form="prefix">Pr</mo>
              <mo stretchy="false">(</mo>
              <mi>S</mi>
              <mo stretchy="false">)</mo>
              <mo>+</mo>
              <mi>n</mi>
              <mo>&#x22C5;<!-- ⋅ --></mo>
              <mo movablelimits="true" form="prefix">Pr</mo>
              <mo stretchy="false">(</mo>
              <mi>S</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mo stretchy="false">|</mo>
              </mrow>
              <mi>W</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mi>s</mi>
              <mo>+</mo>
              <mi>n</mi>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Pr '(S|W)={\frac {s\cdot \Pr(S)+n\cdot \Pr(S|W)}{s+n}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3a72cb7b3554c99fb476f67528af37da66924199" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.005ex; width:36.876ex; height:5.843ex;" alt="{\displaystyle \Pr &#039;(S|W)={\frac {s\cdot \Pr(S)+n\cdot \Pr(S|W)}{s+n}}}"></span></dd></dl>
<p>where:
</p>
<ul><li><span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Pr '(S|W)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mo movablelimits="true" form="prefix">Pr</mo>
          <mo>&#x2032;</mo>
        </msup>
        <mo stretchy="false">(</mo>
        <mi>S</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>W</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Pr '(S|W)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6367ded9fe3ff619a0a89e52fc97b0e52397fe3c" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:9.57ex; height:3.009ex;" alt="{\displaystyle \Pr &#039;(S|W)}"></span> is the corrected probability for the message to be spam, knowing that it contains a given word&#160;;</li>
<li><span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle s}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>s</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle s}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/01d131dfd7673938b947072a13a9744fe997e632" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.09ex; height:1.676ex;" alt="{\displaystyle s}"></span> is the <i>strength</i> we give to background information about incoming spam&#160;;</li>
<li><span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Pr(S)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo movablelimits="true" form="prefix">Pr</mo>
        <mo stretchy="false">(</mo>
        <mi>S</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Pr(S)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/92d3cac5f21efd8c3b89149a016c38f1a612867a" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:5.803ex; height:2.843ex;" alt="{\displaystyle \Pr(S)}"></span> is the probability of any incoming message to be spam&#160;;</li>
<li><span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle n}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>n</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle n}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.395ex; height:1.676ex;" alt="{\displaystyle n}"></span> is the number of occurrences of this word during the learning phase&#160;;</li>
<li><span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Pr(S|W)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo movablelimits="true" form="prefix">Pr</mo>
        <mo stretchy="false">(</mo>
        <mi>S</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mi>W</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Pr(S|W)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/43b2b14c009a5866c86fc11e9e71e77e43da431a" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:8.885ex; height:2.843ex;" alt="{\displaystyle \Pr(S|W)}"></span> is the spamicity of this word.</li></ul>
<p>(Demonstration:<sup id="cite&#95;ref-26" class="reference"><a href="#cite_note-26"><span class="cite-bracket">&#91;</span>26<span class="cite-bracket">&#93;</span></a></sup>)
</p><p>This corrected probability is used instead of the spamicity in the combining formula.
</p><p>This formula can be extended to the case where <i>n</i> is equal to zero (and where the spamicity is not defined), and evaluates in this case to <span class="mwe-math-element mwe-math-element-inline"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle Pr(S)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>P</mi>
        <mi>r</mi>
        <mo stretchy="false">(</mo>
        <mi>S</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Pr(S)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dfdb16eb7924be680cf7168572c413b74f3e6f4e" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:6.103ex; height:2.843ex;" alt="{\displaystyle Pr(S)}"></span>.
</p>
<div class="mw-heading mw-heading4"><h4 id="Other_heuristics">Other heuristics</h4><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=18" title="Edit section: Other heuristics"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>"Neutral" words like "the", "a", "some", or "is" (in English), or their equivalents in other languages, can be ignored. These are also known as <a href="/wiki/Stop_words" class="mw-redirect" title="Stop words">Stop words</a>. More generally, some bayesian filtering filters simply ignore all the words which have a spamicity next to 0.5, as they contribute little to a good decision. The words taken into consideration are those whose spamicity is next to 0.0 (distinctive signs of legitimate messages), or next to 1.0 (distinctive signs of spam). A method can be for example to keep only those ten words, in the examined message, which have the greatest <a href="/wiki/Absolute_value" title="Absolute value">absolute value</a>&#160;|0.5&#160;−&#160;<i>pI</i>|.
</p><p>Some software products take into account the fact that a given word appears several times in the examined message,<sup id="cite&#95;ref-27" class="reference"><a href="#cite_note-27"><span class="cite-bracket">&#91;</span>27<span class="cite-bracket">&#93;</span></a></sup> others don't.
</p><p>Some software products use <i>patterns</i> (sequences of words) instead of isolated natural languages words.<sup id="cite&#95;ref-28" class="reference"><a href="#cite_note-28"><span class="cite-bracket">&#91;</span>28<span class="cite-bracket">&#93;</span></a></sup> For example, with a "context window" of four words, they compute the spamicity of "Viagra is good for", instead of computing the spamicities of "Viagra", "is", "good", and "for". This method gives more sensitivity to context and eliminates the Bayesian noise better, at the expense of a bigger database.
</p>
<div class="mw-heading mw-heading4"><h4 id="Disadvantages">Disadvantages</h4><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=19" title="Edit section: Disadvantages"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<p>Depending on the implementation, Bayesian spam filtering may be susceptible to <a href="/wiki/Bayesian_poisoning" title="Bayesian poisoning">Bayesian poisoning</a>, a technique used by spammers in an attempt to degrade the effectiveness of spam filters that rely on Bayesian filtering. A spammer practicing Bayesian poisoning will send out emails with large amounts of legitimate text (gathered from legitimate news or literary sources). <a href="/wiki/E-mail_spam" class="mw-redirect" title="E-mail spam">Spammer</a> tactics include insertion of random innocuous words that are not normally associated with spam, thereby decreasing the email's spam score, making it more likely to slip past a Bayesian spam filter. However, with (for example) <a href="/wiki/Paul_Graham_(programmer)" title="Paul Graham (programmer)">Paul Graham</a>'s scheme only the most significant probabilities are used, so that padding the text out with non-spam-related words does not affect the detection probability significantly.
</p><p>Words that normally appear in large quantities in spam may also be transformed by spammers. For example, «Viagra» would be replaced with «Viaagra» or «V!agra» in the spam message. The recipient of the message can still read the changed words, but each of these words is met more rarely by the Bayesian filter, which hinders its learning process. As a general rule, this spamming technique does not work very well, because the derived words end up recognized by the filter just like the normal ones.<sup id="cite&#95;ref-29" class="reference"><a href="#cite_note-29"><span class="cite-bracket">&#91;</span>29<span class="cite-bracket">&#93;</span></a></sup>
</p><p>Another technique used to try to defeat Bayesian spam filters is to replace text with pictures, either directly included or linked. The whole text of the message, or some part of it, is replaced with a picture where the same text is "drawn". The spam filter is usually unable to analyze this picture, which would contain the sensitive words like «Viagra». However, since many mail clients disable the display of linked pictures for security reasons, the spammer sending links to distant pictures might reach fewer targets. Also, a picture's size in bytes is bigger than the equivalent text's size, so the spammer needs more bandwidth to send messages directly including pictures. Some filters are more inclined to decide that a message is spam if it has mostly graphical contents. A solution used by <a href="/wiki/Google" title="Google">Google</a> in its <a href="/wiki/Gmail" title="Gmail">Gmail</a> email system is to perform an <a href="/wiki/Optical_character_recognition" title="Optical character recognition">OCR (Optical Character Recognition)</a> on every mid to large size image, analyzing the text inside.<sup id="cite&#95;ref-30" class="reference"><a href="#cite_note-30"><span class="cite-bracket">&#91;</span>30<span class="cite-bracket">&#93;</span></a></sup><sup id="cite&#95;ref-31" class="reference"><a href="#cite_note-31"><span class="cite-bracket">&#91;</span>31<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading2"><h2 id="See_also">See also</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=20" title="Edit section: See also"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<ul><li><a href="/wiki/AODE" class="mw-redirect" title="AODE">AODE</a></li>
<li><a href="/wiki/Anti-spam_techniques" title="Anti-spam techniques">Anti-spam techniques</a></li>
<li><a href="/wiki/Bayes_classifier" title="Bayes classifier">Bayes classifier</a></li>
<li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayesian network</a></li>
<li><a href="/wiki/Bayesian_poisoning" title="Bayesian poisoning">Bayesian poisoning</a></li>
<li><a href="/wiki/Email_filtering" title="Email filtering">Email filtering</a></li>
<li><a href="/wiki/Linear_classifier" title="Linear classifier">Linear classifier</a></li>
<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>
<li><a href="/wiki/Markovian_discrimination" title="Markovian discrimination">Markovian discrimination</a></li>
<li><a href="/wiki/Mozilla_Thunderbird" title="Mozilla Thunderbird">Mozilla Thunderbird</a> mail client with native implementation of Bayes filters<sup id="cite&#95;ref-General&#95;Reference&#95;32-0" class="reference"><a href="#cite_note-General_Reference-32"><span class="cite-bracket">&#91;</span>32<span class="cite-bracket">&#93;</span></a></sup><sup id="cite&#95;ref-Conference&#95;paper&#95;33-0" class="reference"><a href="#cite_note-Conference_paper-33"><span class="cite-bracket">&#91;</span>33<span class="cite-bracket">&#93;</span></a></sup></li>
<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>
<li><a href="/wiki/Random_naive_Bayes" class="mw-redirect" title="Random naive Bayes">Random naive Bayes</a></li>
<li><a href="/wiki/Take-the-best_heuristic" title="Take-the-best heuristic">Take-the-best heuristic</a></li></ul>
<div class="mw-heading mw-heading2"><h2 id="References">References</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=21" title="Edit section: References"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<style data-mw-deduplicate="TemplateStyles:r1327269900">.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}body.skin-vector-2022 .mw-parser-output .reflist-columns-2{column-width:27em}body.skin-vector-2022 .mw-parser-output .reflist-columns-3{column-width:22.5em}.mw-parser-output .references[data-mw-group=upper-alpha]{list-style-type:upper-alpha}.mw-parser-output .references[data-mw-group=upper-roman]{list-style-type:upper-roman}.mw-parser-output .references[data-mw-group=lower-alpha]{list-style-type:lower-alpha}.mw-parser-output .references[data-mw-group=lower-greek]{list-style-type:lower-greek}.mw-parser-output .references[data-mw-group=lower-roman]{list-style-type:lower-roman}.mw-parser-output div.reflist-liststyle-upper-alpha .references{list-style-type:upper-alpha}.mw-parser-output div.reflist-liststyle-upper-roman .references{list-style-type:upper-roman}.mw-parser-output div.reflist-liststyle-lower-alpha .references{list-style-type:lower-alpha}.mw-parser-output div.reflist-liststyle-lower-greek .references{list-style-type:lower-greek}.mw-parser-output div.reflist-liststyle-lower-roman .references{list-style-type:lower-roman}</style><div>
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite&#95;note-idiots-1"><span class="mw-cite-backlink">^ <a href="#cite_ref-idiots_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-idiots_1-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-idiots_1-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><style data-mw-deduplicate="TemplateStyles:r1333433106">.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#bf3c2c)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#bf3c2c)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}</style><cite id="CITEREFHandYu2001" class="citation journal cs1">Hand, D. J.; Yu, K. (2001). "Idiot's Bayes — not so stupid after all?". <i>International Statistical Review</i>. <b>69</b> (3): <span class="nowrap">385–</span>399. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.2307%2F1403452">10.2307/1403452</a>. <a href="/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&#160;<a rel="nofollow" class="external text" href="https://search.worldcat.org/issn/0306-7734">0306-7734</a>. <a href="/wiki/JSTOR_(identifier)" class="mw-redirect" title="JSTOR (identifier)">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="https://www.jstor.org/stable/1403452">1403452</a>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=International+Statistical+Review&amp;rft.atitle=Idiot%27s+Bayes+%E2%80%94+not+so+stupid+after+all%3F&amp;rft.volume=69&amp;rft.issue=3&amp;rft.pages=385-399&amp;rft.date=2001&amp;rft.issn=0306-7734&amp;rft&#95;id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F1403452%23id-name%3DJSTOR&amp;rft&#95;id=info%3Adoi%2F10.2307%2F1403452&amp;rft.aulast=Hand&amp;rft.aufirst=D.+J.&amp;rft.au=Yu%2C+K.&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFMcCallum" class="citation web cs1">McCallum, Andrew. <a rel="nofollow" class="external text" href="https://people.cs.umass.edu/~mccallum/courses/gm2011/02-bn-rep.pdf">"Graphical Models, Lecture2: Bayesian Network Representation"</a> <span class="cs1-format">(PDF)</span>. <a rel="nofollow" class="external text" href="https://ghostarchive.org/archive/20221009/https://people.cs.umass.edu/~mccallum/courses/gm2011/02-bn-rep.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2022-10-09<span class="reference-accessdate">. Retrieved <span class="nowrap">22 October</span> 2019</span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Graphical+Models%2C+Lecture2%3A+Bayesian+Network+Representation&amp;rft.aulast=McCallum&amp;rft.aufirst=Andrew&amp;rft&#95;id=https%3A%2F%2Fpeople.cs.umass.edu%2F~mccallum%2Fcourses%2Fgm2011%2F02-bn-rep.pdf&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-aima-3"><span class="mw-cite-backlink">^ <a href="#cite_ref-aima_3-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-aima_3-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFRussellNorvig2003" class="citation book cs1"><a href="/wiki/Stuart_J._Russell" title="Stuart J. Russell">Russell, Stuart</a>; <a href="/wiki/Peter_Norvig" title="Peter Norvig">Norvig, Peter</a> (2003) [1995]. <i><a href="/wiki/Artificial_Intelligence:_A_Modern_Approach" title="Artificial Intelligence: A Modern Approach">Artificial Intelligence: A Modern Approach</a></i> (2nd&#160;ed.). Prentice Hall. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0137903955" title="Special:BookSources/978-0137903955"><bdi>978-0137903955</bdi></a>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence%3A+A+Modern+Approach&amp;rft.edition=2nd&amp;rft.pub=Prentice+Hall&amp;rft.date=2003&amp;rft.isbn=978-0137903955&amp;rft.aulast=Russell&amp;rft.aufirst=Stuart&amp;rft.au=Norvig%2C+Peter&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFZhang" class="citation conference cs1">Zhang, Harry. <a rel="nofollow" class="external text" href="http://www.cs.unb.ca/profs/hzhang/publications/FLAIRS04ZhangH.pdf"><i>The Optimality of Naive Bayes</i></a> <span class="cs1-format">(PDF)</span>. FLAIRS2004 conference.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=The+Optimality+of+Naive+Bayes&amp;rft.aulast=Zhang&amp;rft.aufirst=Harry&amp;rft&#95;id=http%3A%2F%2Fwww.cs.unb.ca%2Fprofs%2Fhzhang%2Fpublications%2FFLAIRS04ZhangH.pdf&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFCaruanaNiculescu-Mizil2006" class="citation conference cs1">Caruana, R.; Niculescu-Mizil, A. (2006). <i>An empirical comparison of supervised learning algorithms</i>. Proc. 23rd International Conference on Machine Learning. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.122.5901">10.1.1.122.5901</a></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=An+empirical+comparison+of+supervised+learning+algorithms&amp;rft.date=2006&amp;rft&#95;id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.122.5901%23id-name%3DCiteSeerX&amp;rft.aulast=Caruana&amp;rft.aufirst=R.&amp;rft.au=Niculescu-Mizil%2C+A.&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://stats.stackexchange.com/q/379383">"Why does Naive Bayes work better when the number of features &gt;&gt; sample size compared to more sophisticated ML algorithms?"</a>. <i>Cross Validated Stack Exchange</i><span class="reference-accessdate">. Retrieved <span class="nowrap">24 January</span> 2023</span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Cross+Validated+Stack+Exchange&amp;rft.atitle=Why+does+Naive+Bayes+work+better+when+the+number+of+features+%3E%3E+sample+size+compared+to+more+sophisticated+ML+algorithms%3F&amp;rft&#95;id=https%3A%2F%2Fstats.stackexchange.com%2Fq%2F379383&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFNarasimha&#95;MurtySusheela&#95;Devi2011" class="citation book cs1">Narasimha Murty, M.; Susheela Devi, V. (2011). <i>Pattern Recognition: An Algorithmic Approach</i>. Springer. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0857294944" title="Special:BookSources/978-0857294944"><bdi>978-0857294944</bdi></a>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Pattern+Recognition%3A+An+Algorithmic+Approach&amp;rft.pub=Springer&amp;rft.date=2011&amp;rft.isbn=978-0857294944&amp;rft.aulast=Narasimha+Murty&amp;rft.aufirst=M.&amp;rft.au=Susheela+Devi%2C+V.&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-john95-8"><span class="mw-cite-backlink">^ <a href="#cite_ref-john95_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-john95_8-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFJohnLangley1995" class="citation conference cs1">John, George H.; Langley, Pat (1995). <a rel="nofollow" class="external text" href="https://dl.acm.org/doi/10.5555/2074158.2074196"><i>Estimating Continuous Distributions in Bayesian Classifiers</i></a>. Proc. Eleventh Conf. on Uncertainty in Artificial Intelligence. Morgan Kaufmann. pp.&#160;<span class="nowrap">338–</span>345. <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1302.4964">1302.4964</a></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Estimating+Continuous+Distributions+in+Bayesian+Classifiers&amp;rft.pages=338-345&amp;rft.pub=Morgan+Kaufmann&amp;rft.date=1995&amp;rft&#95;id=info%3Aarxiv%2F1302.4964&amp;rft.aulast=John&amp;rft.aufirst=George+H.&amp;rft.au=Langley%2C+Pat&amp;rft&#95;id=https%3A%2F%2Fdl.acm.org%2Fdoi%2F10.5555%2F2074158.2074196&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-mccallum-9"><span class="mw-cite-backlink">^ <a href="#cite_ref-mccallum_9-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-mccallum_9-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-mccallum_9-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFMcCallumNigam1998" class="citation conference cs1">McCallum, Andrew; Nigam, Kamal (1998). <a rel="nofollow" class="external text" href="http://www.kamalnigam.com/papers/multinomial-aaaiws98.pdf"><i>A comparison of event models for Naive Bayes text classification</i></a> <span class="cs1-format">(PDF)</span>. AAAI-98 workshop on learning for text categorization. Vol.&#160;752. <a rel="nofollow" class="external text" href="https://ghostarchive.org/archive/20221009/http://www.kamalnigam.com/papers/multinomial-aaaiws98.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2022-10-09.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=A+comparison+of+event+models+for+Naive+Bayes+text+classification&amp;rft.date=1998&amp;rft.aulast=McCallum&amp;rft.aufirst=Andrew&amp;rft.au=Nigam%2C+Kamal&amp;rft&#95;id=http%3A%2F%2Fwww.kamalnigam.com%2Fpapers%2Fmultinomial-aaaiws98.pdf&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFMetsisAndroutsopoulosPaliouras2006" class="citation conference cs1">Metsis, Vangelis; Androutsopoulos, Ion; Paliouras, Georgios (2006). <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/221650814"><i>Spam filtering with Naive Bayes—which Naive Bayes?</i></a>. Third conference on email and anti-spam (CEAS). Vol.&#160;17.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Spam+filtering+with+Naive+Bayes%E2%80%94which+Naive+Bayes%3F&amp;rft.date=2006&amp;rft.aulast=Metsis&amp;rft.aufirst=Vangelis&amp;rft.au=Androutsopoulos%2C+Ion&amp;rft.au=Paliouras%2C+Georgios&amp;rft&#95;id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F221650814&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-piryonesi2020-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-piryonesi2020_11-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFPiryonesiEl-Diraby2020" class="citation journal cs1">Piryonesi, S. Madeh; El-Diraby, Tamer E. (2020-06-01). "Role of Data Analytics in Infrastructure Asset Management: Overcoming Data Size and Quality Problems". <i>Journal of Transportation Engineering, Part B: Pavements</i>. <b>146</b> (2): 04020022. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1061%2FJPEODX.0000175">10.1061/JPEODX.0000175</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:216485629">216485629</a>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Transportation+Engineering%2C+Part+B%3A+Pavements&amp;rft.atitle=Role+of+Data+Analytics+in+Infrastructure+Asset+Management%3A+Overcoming+Data+Size+and+Quality+Problems&amp;rft.volume=146&amp;rft.issue=2&amp;rft.pages=04020022&amp;rft.date=2020-06-01&amp;rft&#95;id=info%3Adoi%2F10.1061%2FJPEODX.0000175&amp;rft&#95;id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A216485629%23id-name%3DS2CID&amp;rft.aulast=Piryonesi&amp;rft.aufirst=S.+Madeh&amp;rft.au=El-Diraby%2C+Tamer+E.&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-hastie01-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-hastie01_12-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFHastie,&#95;Trevor.2001" class="citation book cs1">Hastie, Trevor. (2001). <i>The elements of statistical learning&#160;: data mining, inference, and prediction&#160;: with 200 full-color illustrations</i>. Tibshirani, Robert., Friedman, J. H. (Jerome H.). New York: Springer. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-387-95284-5" title="Special:BookSources/0-387-95284-5"><bdi>0-387-95284-5</bdi></a>. <a href="/wiki/OCLC_(identifier)" class="mw-redirect" title="OCLC (identifier)">OCLC</a>&#160;<a rel="nofollow" class="external text" href="https://search.worldcat.org/oclc/46809224">46809224</a>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+elements+of+statistical+learning+%3A+data+mining%2C+inference%2C+and+prediction+%3A+with+200+full-color+illustrations&amp;rft.place=New+York&amp;rft.pub=Springer&amp;rft.date=2001&amp;rft&#95;id=info%3Aoclcnum%2F46809224&amp;rft.isbn=0-387-95284-5&amp;rft.au=Hastie%2C+Trevor.&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFJamesWittenHastieTibshirani2021" class="citation book cs1">James, Gareth; Witten, Daniela; Hastie, Trevor; Tibshirani, Robert (2021). <a rel="nofollow" class="external text" href="https://link.springer.com/book/10.1007/978-1-0716-1418-1"><i>An introduction to statistical learning: with applications in R</i></a> (Second&#160;ed.). New York, NY: Springer. p.&#160;157. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-1-0716-1418-1">10.1007/978-1-0716-1418-1</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-0716-1418-1" title="Special:BookSources/978-1-0716-1418-1"><bdi>978-1-0716-1418-1</bdi></a><span class="reference-accessdate">. Retrieved <span class="nowrap">10 November</span> 2024</span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=An+introduction+to+statistical+learning%3A+with+applications+in+R&amp;rft.place=New+York%2C+NY&amp;rft.pages=157&amp;rft.edition=Second&amp;rft.pub=Springer&amp;rft.date=2021&amp;rft&#95;id=info%3Adoi%2F10.1007%2F978-1-0716-1418-1&amp;rft.isbn=978-1-0716-1418-1&amp;rft.aulast=James&amp;rft.aufirst=Gareth&amp;rft.au=Witten%2C+Daniela&amp;rft.au=Hastie%2C+Trevor&amp;rft.au=Tibshirani%2C+Robert&amp;rft&#95;id=https%3A%2F%2Flink.springer.com%2Fbook%2F10.1007%2F978-1-0716-1418-1&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-rennie-14"><span class="mw-cite-backlink">^ <a href="#cite_ref-rennie_14-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-rennie_14-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFRennieShihTeevanKarger2003" class="citation conference cs1">Rennie, J.; Shih, L.; Teevan, J.; Karger, D. (2003). <a rel="nofollow" class="external text" href="http://people.csail.mit.edu/~jrennie/papers/icml03-nb.pdf"><i>Tackling the poor assumptions of naive Bayes classifiers</i></a> <span class="cs1-format">(PDF)</span>. ICML. <a rel="nofollow" class="external text" href="https://ghostarchive.org/archive/20221009/http://people.csail.mit.edu/~jrennie/papers/icml03-nb.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2022-10-09.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Tackling+the+poor+assumptions+of+naive+Bayes+classifiers&amp;rft.date=2003&amp;rft.aulast=Rennie&amp;rft.aufirst=J.&amp;rft.au=Shih%2C+L.&amp;rft.au=Teevan%2C+J.&amp;rft.au=Karger%2C+D.&amp;rft&#95;id=http%3A%2F%2Fpeople.csail.mit.edu%2F~jrennie%2Fpapers%2Ficml03-nb.pdf&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-em-15"><span class="mw-cite-backlink">^ <a href="#cite_ref-em_15-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-em_15-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFNigamMcCallumThrunMitchell2000" class="citation journal cs1">Nigam, Kamal; McCallum, Andrew; Thrun, Sebastian; Mitchell, Tom (2000). <a rel="nofollow" class="external text" href="http://www.kamalnigam.com/papers/emcat-aaai98.pdf">"Learning to classify text from labeled and unlabeled documents using EM"</a> <span class="cs1-format">(PDF)</span>. <i><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">Machine Learning</a></i>. <b>39</b> (2/3): <span class="nowrap">103–</span>134. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1023%2FA%3A1007692713085">10.1023/A:1007692713085</a></span>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:686980">686980</a>. <a rel="nofollow" class="external text" href="https://ghostarchive.org/archive/20221009/http://www.kamalnigam.com/papers/emcat-aaai98.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2022-10-09.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=Learning+to+classify+text+from+labeled+and+unlabeled+documents+using+EM&amp;rft.volume=39&amp;rft.issue=2%2F3&amp;rft.pages=103-134&amp;rft.date=2000&amp;rft&#95;id=info%3Adoi%2F10.1023%2FA%3A1007692713085&amp;rft&#95;id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A686980%23id-name%3DS2CID&amp;rft.aulast=Nigam&amp;rft.aufirst=Kamal&amp;rft.au=McCallum%2C+Andrew&amp;rft.au=Thrun%2C+Sebastian&amp;rft.au=Mitchell%2C+Tom&amp;rft&#95;id=http%3A%2F%2Fwww.kamalnigam.com%2Fpapers%2Femcat-aaai98.pdf&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFNiculescu-MizilCaruana2005" class="citation conference cs1">Niculescu-Mizil, Alexandru; Caruana, Rich (2005). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20140311005243/http://machinelearning.wustl.edu/mlpapers/paper_files/icml2005_Niculescu-MizilC05.pdf"><i>Predicting good probabilities with supervised learning</i></a> <span class="cs1-format">(PDF)</span>. ICML. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F1102351.1102430">10.1145/1102351.1102430</a>. Archived from <a rel="nofollow" class="external text" href="http://machinelearning.wustl.edu/mlpapers/paper_files/icml2005_Niculescu-MizilC05.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 2014-03-11<span class="reference-accessdate">. Retrieved <span class="nowrap">2016-04-24</span></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Predicting+good+probabilities+with+supervised+learning&amp;rft.date=2005&amp;rft&#95;id=info%3Adoi%2F10.1145%2F1102351.1102430&amp;rft.aulast=Niculescu-Mizil&amp;rft.aufirst=Alexandru&amp;rft.au=Caruana%2C+Rich&amp;rft&#95;id=http%3A%2F%2Fmachinelearning.wustl.edu%2Fmlpapers%2Fpaper&#95;files%2Ficml2005&#95;Niculescu-MizilC05.pdf&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-rish-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-rish_17-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFRish2001" class="citation conference cs1">Rish, Irina (2001). <a rel="nofollow" class="external text" href="http://www.research.ibm.com/people/r/rish/papers/RC22230.pdf"><i>An empirical study of the naive Bayes classifier</i></a> <span class="cs1-format">(PDF)</span>. IJCAI Workshop on Empirical Methods in AI. <a rel="nofollow" class="external text" href="https://ghostarchive.org/archive/20221009/http://www.research.ibm.com/people/r/rish/papers/RC22230.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2022-10-09.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=An+empirical+study+of+the+naive+Bayes+classifier&amp;rft.date=2001&amp;rft.aulast=Rish&amp;rft.aufirst=Irina&amp;rft&#95;id=http%3A%2F%2Fwww.research.ibm.com%2Fpeople%2Fr%2Frish%2Fpapers%2FRC22230.pdf&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-pair-18"><span class="mw-cite-backlink">^ <a href="#cite_ref-pair_18-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-pair_18-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFNgJordan2002" class="citation conference cs1"><a href="/wiki/Andrew_Ng" title="Andrew Ng">Ng, Andrew Y.</a>; <a href="/wiki/Michael_I._Jordan" title="Michael I. Jordan">Jordan, Michael I.</a> (2002). <a rel="nofollow" class="external text" href="http://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes"><i>On discriminative vs. generative classifiers: A comparison of logistic regression and naive Bayes</i></a>. <a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NIPS</a>. Vol.&#160;14.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=On+discriminative+vs.+generative+classifiers%3A+A+comparison+of+logistic+regression+and+naive+Bayes&amp;rft.date=2002&amp;rft.aulast=Ng&amp;rft.aufirst=Andrew+Y.&amp;rft.au=Jordan%2C+Michael+I.&amp;rft&#95;id=http%3A%2F%2Fpapers.nips.cc%2Fpaper%2F2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFBrunton2013" class="citation book cs1">Brunton, Finn (2013). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=QF7EjCRg5CIC&amp;pg=PA136"><i>Spam: A Shadow History of the Internet</i></a>. <a href="/wiki/MIT_Press" title="MIT Press">MIT Press</a>. p.&#160;136. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9780262018876" title="Special:BookSources/9780262018876"><bdi>9780262018876</bdi></a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20190323133300/https://books.google.com/books?id=QF7EjCRg5CIC&amp;pg=PA136">Archived</a> from the original on 2019-03-23<span class="reference-accessdate">. Retrieved <span class="nowrap">2017-09-13</span></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Spam%3A+A+Shadow+History+of+the+Internet&amp;rft.pages=136&amp;rft.pub=MIT+Press&amp;rft.date=2013&amp;rft.isbn=9780262018876&amp;rft.aulast=Brunton&amp;rft.aufirst=Finn&amp;rft&#95;id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DQF7EjCRg5CIC%26pg%3DPA136&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-20">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFM.&#95;SahamiS.&#95;DumaisD.&#95;HeckermanE.&#95;Horvitz1998" class="citation web cs1">M. Sahami; S. Dumais; D. Heckerman; E. Horvitz (1998). <a rel="nofollow" class="external text" href="http://robotics.stanford.edu/users/sahami/papers-dir/spam.pdf">"A Bayesian approach to filtering junk e-mail"</a> <span class="cs1-format">(PDF)</span>. AAAI'98 Workshop on Learning for Text Categorization. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20070927171816/http://robotics.stanford.edu/users/sahami/papers-dir/spam.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2007-09-27<span class="reference-accessdate">. Retrieved <span class="nowrap">2007-08-15</span></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=A+Bayesian+approach+to+filtering+junk+e-mail&amp;rft.pub=AAAI%2798+Workshop+on+Learning+for+Text+Categorization&amp;rft.date=1998&amp;rft.au=M.+Sahami&amp;rft.au=S.+Dumais&amp;rft.au=D.+Heckerman&amp;rft.au=E.+Horvitz&amp;rft&#95;id=http%3A%2F%2Frobotics.stanford.edu%2Fusers%2Fsahami%2Fpapers-dir%2Fspam.pdf&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite class="citation web cs1"><a rel="nofollow" class="external text" href="http://kb.mozillazine.org/Junk_Mail_Controls">"Junk Mail Controls"</a>. MozillaZine. November 2009. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20121023211104/http://kb.mozillazine.org/Junk_Mail_Controls">Archived</a> from the original on 2012-10-23<span class="reference-accessdate">. Retrieved <span class="nowrap">2010-01-16</span></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Junk+Mail+Controls&amp;rft.pub=MozillaZine&amp;rft.date=2009-11&amp;rft&#95;id=http%3A%2F%2Fkb.mozillazine.org%2FJunk&#95;Mail&#95;Controls&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-22">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://docs.rspamd.com/configuration/statistic">"Rspamd statistic settings"</a>. docs.rspamd.com<span class="reference-accessdate">. Retrieved <span class="nowrap">2025-09-25</span></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Rspamd+statistic+settings&amp;rft.pub=docs.rspamd.com&amp;rft&#95;id=https%3A%2F%2Fdocs.rspamd.com%2Fconfiguration%2Fstatistic&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-twsSep14yy-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-twsSep14yy_23-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20100929165032/http://manpages.ubuntu.com/manpages/gutsy/man1/sa-learn.1p.html">"Installation"</a>. Ubuntu manuals. 2010-09-18. Archived from <a rel="nofollow" class="external text" href="http://manpages.ubuntu.com/manpages/gutsy/man1/sa-learn.1p.html">the original</a> on 29 September 2010<span class="reference-accessdate">. Retrieved <span class="nowrap">2010-09-18</span></span>. <q>Gary Robinson's f(x) and combining algorithms, as used in SpamAssassin</q></cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Installation&amp;rft.pub=Ubuntu+manuals&amp;rft.date=2010-09-18&amp;rft&#95;id=http%3A%2F%2Fmanpages.ubuntu.com%2Fmanpages%2Fgutsy%2Fman1%2Fsa-learn.1p.html&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-twsSep2-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-twsSep2_24-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite class="citation news cs1"><a rel="nofollow" class="external text" href="https://spambayes.sourceforge.net/background.html">"Background Reading"</a>. SpamBayes project. 2010-09-18. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20100906031341/http://spambayes.sourceforge.net/background.html">Archived</a> from the original on 6 September 2010<span class="reference-accessdate">. Retrieved <span class="nowrap">2010-09-18</span></span>. <q>Sharpen your pencils, this is the mathematical background (such as it is).* The paper that started the ball rolling: Paul Graham's A Plan for Spam.* Gary Robinson has an interesting essay suggesting some improvements to Graham's original approach.* Gary Robinson's Linux Journal article discussed using the chi squared distribution.</q></cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Background+Reading&amp;rft.date=2010-09-18&amp;rft&#95;id=https%3A%2F%2Fspambayes.sourceforge.net%2Fbackground.html&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://crm114.sourceforge.net/docs/classify_details.txt">"Archived copy"</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20161007063935/http://crm114.sourceforge.net/docs/classify_details.txt">Archived</a> from the original on 2016-10-07<span class="reference-accessdate">. Retrieved <span class="nowrap">2016-07-09</span></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Archived+copy&amp;rft&#95;id=https%3A%2F%2Fcrm114.sourceforge.net%2Fdocs%2Fclassify&#95;details.txt&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span><span class="cs1-maint citation-comment"><code class="cs1-code">{{<a href="/wiki/Template:Cite_web" title="Template:Cite web">cite web</a>}}</code>:  CS1 maint: archived copy as title (<a href="/wiki/Category:CS1_maint:_archived_copy_as_title" title="Category:CS1 maint: archived copy as title">link</a>)</span></span>
</li>
<li id="cite&#95;note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFGary&#95;Robinson2003" class="citation magazine cs1"><a href="/wiki/Gary_Robinson" title="Gary Robinson">Gary Robinson</a> (2003). <a rel="nofollow" class="external text" href="http://www.linuxjournal.com/article/6467">"A statistical approach to the spam problem"</a>. <i>Linux Journal</i>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20101022001749/http://www.linuxjournal.com/article/6467">Archived</a> from the original on 2010-10-22<span class="reference-accessdate">. Retrieved <span class="nowrap">2007-07-19</span></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Linux+Journal&amp;rft.atitle=A+statistical+approach+to+the+spam+problem&amp;rft.date=2003&amp;rft.au=Gary+Robinson&amp;rft&#95;id=http%3A%2F%2Fwww.linuxjournal.com%2Farticle%2F6467&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFBrian&#95;Burton2003" class="citation web cs1">Brian Burton (2003). <a rel="nofollow" class="external text" href="https://spamprobe.sourceforge.net/paper.html">"SpamProbe - Bayesian Spam Filtering Tweaks"</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20120301235828/http://spamprobe.sourceforge.net/paper.html">Archived</a> from the original on 2012-03-01<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-01-19</span></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=SpamProbe+-+Bayesian+Spam+Filtering+Tweaks&amp;rft.date=2003&amp;rft.au=Brian+Burton&amp;rft&#95;id=https%3A%2F%2Fspamprobe.sourceforge.net%2Fpaper.html&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-28">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFJonathan&#95;A.&#95;Zdziarski2004" class="citation web cs1">Jonathan A. Zdziarski (2004). <a rel="nofollow" class="external text" href="http://bnr.nuclearelephant.com/l">"Bayesian Noise Reduction: Contextual Symmetry Logic Utilizing Pattern Consistency Analysis"</a>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Bayesian+Noise+Reduction%3A+Contextual+Symmetry+Logic+Utilizing+Pattern+Consistency+Analysis&amp;rft.date=2004&amp;rft.au=Jonathan+A.+Zdziarski&amp;rft&#95;id=http%3A%2F%2Fbnr.nuclearelephant.com%2Fl&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span><sup class="noprint Inline-Template"><span style="white-space: nowrap;">&#91;<i><a href="/wiki/Wikipedia:Link_rot" title="Wikipedia:Link rot"><span title="&#160;Dead link tagged February 2018">permanent dead link</span></a></i>&#93;</span></sup></span>
</li>
<li id="cite&#95;note-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-29">^</a></b></span> <span class="reference-text">Paul Graham (2002), <a rel="nofollow" class="external text" href="http://www.paulgraham.com/spam.html">A Plan for Spam</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20040404013856/http://www.paulgraham.com/spam.html">Archived</a> 2004-04-04 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a></span>
</li>
<li id="cite&#95;note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite class="citation web cs1"><a rel="nofollow" class="external text" href="http://www.google.com/mail/help/intl/en_GB/fightspam/spamexplained.html">"Gmail uses Google's innovative technology to keep spam out of your inbox"</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20150913070222/http://www.google.com/mail/help/intl/en_GB/fightspam/spamexplained.html">Archived</a> from the original on 2015-09-13<span class="reference-accessdate">. Retrieved <span class="nowrap">2015-09-05</span></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Gmail+uses+Google%27s+innovative+technology+to+keep+spam+out+of+your+inbox&amp;rft&#95;id=http%3A%2F%2Fwww.google.com%2Fmail%2Fhelp%2Fintl%2Fen&#95;GB%2Ffightspam%2Fspamexplained.html&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFZhuJiaXiaoZhang2014" class="citation book cs1">Zhu, Z.; Jia, Z; Xiao, H; Zhang, G; Liang, H.; Wang, P. (2014). "A Modified Minimum Risk Bayes and It's Application in Spam Filtering". In Li, S; Jin, Q; Jiang, X; Park, J (eds.). <i>Frontier and Future Development of Information Technology in Medicine and Education</i>. Lecture Notes in Electrical Engineering. Vol.&#160;269. Dordrecht: Springer. pp.&#160;<span class="nowrap">2155–</span>2159. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-94-007-7618-0_261">10.1007/978-94-007-7618-0_261</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-94-007-7617-3" title="Special:BookSources/978-94-007-7617-3"><bdi>978-94-007-7617-3</bdi></a>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=A+Modified+Minimum+Risk+Bayes+and+It%27s+Application+in+Spam+Filtering&amp;rft.btitle=Frontier+and+Future+Development+of+Information+Technology+in+Medicine+and+Education&amp;rft.place=Dordrecht&amp;rft.series=Lecture+Notes+in+Electrical+Engineering&amp;rft.pages=2155-2159&amp;rft.pub=Springer&amp;rft.date=2014&amp;rft&#95;id=info%3Adoi%2F10.1007%2F978-94-007-7618-0&#95;261&amp;rft.isbn=978-94-007-7617-3&amp;rft.aulast=Zhu&amp;rft.aufirst=Z.&amp;rft.au=Jia%2C+Z&amp;rft.au=Xiao%2C+H&amp;rft.au=Zhang%2C+G&amp;rft.au=Liang%2C+H.&amp;rft.au=Wang%2C+P.&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-General&#95;Reference-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-General_Reference_32-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFHristea2013" class="citation book cs1">Hristea, Florentina T. (2013). <i>The Naïve Bayes Model for Unsupervised Word Sense Disambiguation</i>. London; Berlin: Springer- Verlag Heidelberg Berlin. p.&#160;70. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-642-33692-8" title="Special:BookSources/978-3-642-33692-8"><bdi>978-3-642-33692-8</bdi></a>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Na%C3%AFve+Bayes+Model+for+Unsupervised+Word+Sense+Disambiguation&amp;rft.place=London%3B+Berlin&amp;rft.pages=70&amp;rft.pub=Springer-+Verlag+Heidelberg+Berlin&amp;rft.date=2013&amp;rft.isbn=978-3-642-33692-8&amp;rft.aulast=Hristea&amp;rft.aufirst=Florentina+T.&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
<li id="cite&#95;note-Conference&#95;paper-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-Conference_paper_33-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFZhengTang2005" class="citation book cs1">Zheng, J.; Tang, Yongchuan (2005). "One Generalization of the Naive Bayes to Fuzzy Sets and the Design of the Fuzzy Naive Bayes Classifier". In Mira, Jose; Álvarez, Jose R (eds.). <i>Artificial Intelligence and Knowledge Engineering Applications: A Bioinspired Approach</i>. Lecture Notes in Computer Science. Vol.&#160;3562. Berlin: Springer, Berlin, Heidelberg. p.&#160;281. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F11499305_29">10.1007/11499305_29</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-540-26319-7" title="Special:BookSources/978-3-540-26319-7"><bdi>978-3-540-26319-7</bdi></a>. <a href="/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&#160;<a rel="nofollow" class="external text" href="https://search.worldcat.org/issn/0302-9743">0302-9743</a>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=One+Generalization+of+the+Naive+Bayes+to+Fuzzy+Sets+and+the+Design+of+the+Fuzzy+Naive+Bayes+Classifier&amp;rft.btitle=Artificial+Intelligence+and+Knowledge+Engineering+Applications%3A+A+Bioinspired+Approach&amp;rft.place=Berlin&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=281&amp;rft.pub=Springer%2C+Berlin%2C+Heidelberg&amp;rft.date=2005&amp;rft.issn=0302-9743&amp;rft&#95;id=info%3Adoi%2F10.1007%2F11499305&#95;29&amp;rft.isbn=978-3-540-26319-7&amp;rft.aulast=Zheng&amp;rft.aufirst=J.&amp;rft.au=Tang%2C+Yongchuan&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></span>
</li>
</ol></div></div>
<div class="mw-heading mw-heading2"><h2 id="Further_reading">Further reading</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=22" title="Edit section: Further reading"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<ul><li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFDomingosPazzani1997" class="citation journal cs1">Domingos, Pedro; Pazzani, Michael (1997). <a rel="nofollow" class="external text" href="http://citeseer.ist.psu.edu/domingos97optimality.html">"On the optimality of the simple Bayesian classifier under zero-one loss"</a>. <i><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">Machine Learning</a></i>. <b>29</b> (2/3): <span class="nowrap">103–</span>137. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1023%2FA%3A1007413511361">10.1023/A:1007413511361</a></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=On+the+optimality+of+the+simple+Bayesian+classifier+under+zero-one+loss&amp;rft.volume=29&amp;rft.issue=2%2F3&amp;rft.pages=103-137&amp;rft.date=1997&amp;rft&#95;id=info%3Adoi%2F10.1023%2FA%3A1007413511361&amp;rft.aulast=Domingos&amp;rft.aufirst=Pedro&amp;rft.au=Pazzani%2C+Michael&amp;rft&#95;id=http%3A%2F%2Fciteseer.ist.psu.edu%2Fdomingos97optimality.html&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFWebbBoughtonWang2005" class="citation journal cs1">Webb, G. I.; Boughton, J.; Wang, Z. (2005). <a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fs10994-005-4258-6">"Not So Naive Bayes: Aggregating One-Dependence Estimators"</a>. <i>Machine Learning</i>. <b>58</b> (1): <span class="nowrap">5–</span>24. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fs10994-005-4258-6">10.1007/s10994-005-4258-6</a></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=Not+So+Naive+Bayes%3A+Aggregating+One-Dependence+Estimators&amp;rft.volume=58&amp;rft.issue=1&amp;rft.pages=5-24&amp;rft.date=2005&amp;rft&#95;id=info%3Adoi%2F10.1007%2Fs10994-005-4258-6&amp;rft.aulast=Webb&amp;rft.aufirst=G.+I.&amp;rft.au=Boughton%2C+J.&amp;rft.au=Wang%2C+Z.&amp;rft&#95;id=https%3A%2F%2Fdoi.org%2F10.1007%252Fs10994-005-4258-6&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFMozinaDemsarKattanZupan2004" class="citation conference cs1">Mozina, M.; Demsar, J.; Kattan, M.; Zupan, B. (2004). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20231129120344/http://eprints.fri.uni-lj.si/154/1/PKDD_camera_mozina.pdf"><i>Nomograms for Visualization of Naive Bayesian Classifier</i></a> <span class="cs1-format">(PDF)</span>. Proc. PKDD-2004. pp.&#160;<span class="nowrap">337–</span>348. Archived from <a rel="nofollow" class="external text" href="http://eprints.fri.uni-lj.si/154/01/PKDD_camera_mozina.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 2023-11-29<span class="reference-accessdate">. Retrieved <span class="nowrap">2014-04-01</span></span>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Nomograms+for+Visualization+of+Naive+Bayesian+Classifier&amp;rft.pages=337-348&amp;rft.date=2004&amp;rft.aulast=Mozina&amp;rft.aufirst=M.&amp;rft.au=Demsar%2C+J.&amp;rft.au=Kattan%2C+M.&amp;rft.au=Zupan%2C+B.&amp;rft&#95;id=http%3A%2F%2Feprints.fri.uni-lj.si%2F154%2F01%2FPKDD&#95;camera&#95;mozina.pdf&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFMaron1961" class="citation journal cs1">Maron, M. E. (1961). "Automatic Indexing: An Experimental Inquiry". <i><a href="/wiki/Journal_of_the_ACM" title="Journal of the ACM">Journal of the ACM</a></i>. <b>8</b> (3): <span class="nowrap">404–</span>417. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F321075.321084">10.1145/321075.321084</a>. <a href="/wiki/Hdl_(identifier)" class="mw-redirect" title="Hdl (identifier)">hdl</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://hdl.handle.net/2027%2Fuva.x030748531">2027/uva.x030748531</a></span>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:6692916">6692916</a>.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+ACM&amp;rft.atitle=Automatic+Indexing%3A+An+Experimental+Inquiry&amp;rft.volume=8&amp;rft.issue=3&amp;rft.pages=404-417&amp;rft.date=1961&amp;rft&#95;id=info%3Ahdl%2F2027%2Fuva.x030748531&amp;rft&#95;id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A6692916%23id-name%3DS2CID&amp;rft&#95;id=info%3Adoi%2F10.1145%2F321075.321084&amp;rft.aulast=Maron&amp;rft.aufirst=M.+E.&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333433106" /><cite id="CITEREFMinsky1961" class="citation conference cs1"><a href="/wiki/Marvin_Minsky" title="Marvin Minsky">Minsky, M.</a> (1961). <i>Steps toward Artificial Intelligence</i>. Proc. IRE. Vol.&#160;49. pp.&#160;<span class="nowrap">8–</span>30.</cite><span title="ctx&#95;ver=Z39.88-2004&amp;rft&#95;val&#95;fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Steps+toward+Artificial+Intelligence&amp;rft.pages=8-30&amp;rft.date=1961&amp;rft.aulast=Minsky&amp;rft.aufirst=M.&amp;rfr&#95;id=info%3Asid%2Fen.wikipedia.org%3ANaive+Bayes+classifier" class="Z3988"></span></li></ul>
<div class="mw-heading mw-heading2"><h2 id="External_links">External links</h2><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Naive_Bayes_classifier&amp;action=edit&amp;section=23" title="Edit section: External links"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></div>
<ul><li><a rel="nofollow" class="external text" href="http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html">Book Chapter: Naive Bayes text classification, Introduction to Information Retrieval</a></li>
<li><a rel="nofollow" class="external text" href="http://www.cs.waikato.ac.nz/~eibe/pubs/FrankAndBouckaertPKDD06new.pdf">Naive Bayes for Text Classification with Unbalanced Classes</a></li></ul>
<div class="navbox-styles"><style data-mw-deduplicate="TemplateStyles:r1333133064">.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:": "}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:"\a0 · ";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:" (";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:")";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:" "counter(listitem)"\a0 "}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:" ("counter(listitem)"\a0 "}</style><style data-mw-deduplicate="TemplateStyles:r1314944253">.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd;color:inherit}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf;color:inherit}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf;color:inherit}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff;color:inherit}.mw-parser-output .navbox-even{background-color:#f7f7f7;color:inherit}.mw-parser-output .navbox-odd{background-color:transparent;color:inherit}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}</style></div><div role="navigation" class="navbox" aria-labelledby="Unsolicited&#95;digital&#95;communication2050" style="padding:3px"><table class="nowraplinks mw-collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1333133064" /><style data-mw-deduplicate="TemplateStyles:r1239400231">.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}</style><div class="navbar plainlinks hlist navbar-mini"><ul><li class="nv-view"><a href="/wiki/Template:Spamming" title="Template:Spamming"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Spamming" title="Template talk:Spamming"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a href="/wiki/Special:EditPage/Template:Spamming" title="Special:EditPage/Template:Spamming"><abbr title="Edit this template">e</abbr></a></li></ul></div><div id="Unsolicited&#95;digital&#95;communication2050" style="font-size:114%;margin:0 4em"><a href="/wiki/Spamming" title="Spamming">Unsolicited digital communication</a></div></th></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Communication_protocol" title="Communication protocol">Protocols</a></th><td class="navbox-list-with-group navbox-list navbox-odd hlist" style="width:100%;padding:0"><div style="padding:0 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Email_spam" title="Email spam">Email spam</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Address_munging" title="Address munging">Address munging</a></li>
<li><a href="/wiki/Bulk_email_software" title="Bulk email software">Bulk email software</a></li>
<li><a href="/wiki/Directory_harvest_attack" title="Directory harvest attack">Directory harvest attack</a></li>
<li><a href="/wiki/Domain_Name_System_blocklist" title="Domain Name System blocklist">DNSBL</a></li>
<li><a href="/wiki/DNSWL" class="mw-redirect" title="DNSWL">DNSWL</a></li>
<li><a href="/wiki/Email_spoofing" title="Email spoofing">Email spoofing</a></li>
<li><a href="/wiki/Image_spam" title="Image spam">Image spam</a></li>
<li><a href="/wiki/Joe_job" title="Joe job">Joe job</a></li>
<li><a href="/wiki/Pink_contract" title="Pink contract">Pink contract</a></li>
<li><a href="/wiki/Email-address_harvesting" title="Email-address harvesting">Spambot</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Other</th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Auto_dialer" title="Auto dialer">Auto dialer</a></li>
<li><a href="/wiki/Cold_calling" title="Cold calling">Cold calling</a></li>
<li><a href="/wiki/Flyposting" title="Flyposting">Flyposting</a></li>
<li><a href="/wiki/Junk_fax" title="Junk fax">Junk fax</a></li>
<li><a href="/wiki/Messaging_spam" title="Messaging spam">Messaging</a></li>
<li><a href="/wiki/Mobile_phone_spam" title="Mobile phone spam">Mobile phone</a></li>
<li><a href="/wiki/Newsgroup_spam" title="Newsgroup spam">Newsgroup</a></li>
<li><a href="/wiki/Robocall" title="Robocall">Robocall</a></li>
<li><a href="/wiki/Spambot" title="Spambot">Spambot</a></li>
<li><a href="/wiki/Telemarketing" title="Telemarketing">Telemarketing</a></li>
<li><a href="/wiki/VoIP_spam" title="VoIP spam">VoIP</a></li></ul>
</div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Anti-spam_techniques" title="Anti-spam techniques">Anti-spam</a></th><td class="navbox-list-with-group navbox-list navbox-odd hlist" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Anti-spam_techniques_(users)" class="mw-redirect" title="Anti-spam techniques (users)">Client-side</a></li>
<li><a href="/wiki/Challenge%E2%80%93response_spam_filtering" title="Challenge–response spam filtering">Challenge–response spam filtering</a></li>
<li><a href="/wiki/Context_filtering" title="Context filtering">Context filtering</a></li>
<li><a href="/wiki/Disposable_email_address" title="Disposable email address">Disposable email address</a></li>
<li><a href="/wiki/Distributed_Checksum_Clearinghouse" title="Distributed Checksum Clearinghouse">Distributed Checksum Clearinghouse</a></li>
<li><a href="/wiki/Email_authentication" title="Email authentication">Email authentication</a></li>
<li><a href="/wiki/Greylisting_(email)" title="Greylisting (email)">Greylisting</a></li>
<li><a href="/wiki/List_poisoning" title="List poisoning">List poisoning</a></li>
<li><a href="/wiki/MyWOT" class="mw-redirect" title="MyWOT">MyWOT</a></li>
<li><a href="/wiki/Naive_Bayes_spam_filtering" class="mw-redirect" title="Naive Bayes spam filtering">Naive Bayes spam filtering</a></li>
<li><a href="/wiki/Spam_and_Open_Relay_Blocking_System" title="Spam and Open Relay Blocking System">SORBS</a></li>
<li><a href="/wiki/SpamCop" title="SpamCop">SpamCop</a></li>
<li><a href="/wiki/The_Spamhaus_Project" title="The Spamhaus Project">Spamhaus</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Spam_filter" class="mw-redirect" title="Spam filter">Anti-spam software</a></th><td class="navbox-list-with-group navbox-list navbox-even hlist" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Akismet" title="Akismet">Akismet</a></li>
<li><a href="/wiki/Amavis" title="Amavis">Amavis</a></li>
<li><a href="/wiki/Bogofilter" title="Bogofilter">Bogofilter</a></li>
<li><a href="/wiki/CRM114_(program)" title="CRM114 (program)">CRM114</a></li>
<li><a href="/wiki/MIMEDefang" title="MIMEDefang">MIMEDefang</a></li>
<li><a href="/wiki/Rspamd" title="Rspamd">Rspamd</a></li>
<li><a href="/wiki/SpamAssassin" class="mw-redirect" title="SpamAssassin">SpamAssassin</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Spamdexing" title="Spamdexing">Spamdexing</a></th><td class="navbox-list-with-group navbox-list navbox-odd hlist" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Spam_in_blogs" title="Spam in blogs">Blog spam</a></li>
<li><a href="/wiki/Cloaking" title="Cloaking">Cloaking</a></li>
<li><a href="/wiki/Doorway_page" title="Doorway page">Doorway page</a></li>
<li><a href="/wiki/Forum_spam" title="Forum spam">Forum spam</a></li>
<li><a href="/wiki/Google_bombing" title="Google bombing">Google bombing</a></li>
<li><a href="/wiki/Keyword_stuffing" class="mw-redirect" title="Keyword stuffing">Keyword stuffing</a></li>
<li><a href="/wiki/Link_farm" title="Link farm">Link farm</a></li>
<li><a href="/wiki/Referrer_spam" title="Referrer spam">Referrer spam</a></li>
<li><a href="/wiki/Scraper_site" title="Scraper site">Scraper site</a></li>
<li><a href="/wiki/Social_spam" title="Social spam">Social spam</a></li>
<li><a href="/wiki/Spam_blog" title="Spam blog">Spam blogs</a></li>
<li><a href="/wiki/Sping" title="Sping">Sping</a></li>
<li><a href="/wiki/URL_redirection" title="URL redirection">URL redirection</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Internet_fraud" title="Internet fraud">Internet fraud</a></th><td class="navbox-list-with-group navbox-list navbox-even hlist" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Advance-fee_scam" title="Advance-fee scam">Advance-fee scam</a>
<ul><li><a href="/wiki/Lottery_scam" title="Lottery scam">Lottery scam</a></li></ul></li>
<li><a href="/wiki/Make_Money_Fast" title="Make Money Fast">Make Money Fast</a></li>
<li><a href="/wiki/Phishing" title="Phishing">Phishing</a>
<ul><li><a href="/wiki/Voice_phishing" title="Voice phishing">Voice</a></li></ul></li></ul>
</div></td></tr></tbody></table></div>
<!-- 
NewPP limit report
Parsed by mw‐web.eqiad.main‐6f597bcf‐c9l75
Cached time: 20260224001537
Cache expiry: 85472
Reduced expiry: true
Complications: [vary‐revision‐sha1, prevent‐selective‐update, show‐toc]
CPU time usage: 0.756 seconds
Real time usage: 0.990 seconds
Preprocessor visited node count: 3536/1000000
Revision size: 51112/2097152 bytes
Post‐expand include size: 92943/2097152 bytes
Template argument size: 2523/2097152 bytes
Highest expansion depth: 17/100
Expensive parser function count: 2/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 144670/5000000 bytes
Lua time usage: 0.406/10.000 seconds
Lua memory usage: 6648731/52428800 bytes
Number of Wikibase entities loaded: 0/500
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  646.731      1 -total
 56.60%  366.058      1 Template:Reflist
 21.93%  141.817      6 Template:Cite_journal
 13.77%   89.081      1 Template:Spamming
 13.56%   87.685      2 Template:Navbox
 12.92%   83.551      1 Template:Short_description
 10.11%   65.359     11 Template:Cite_conference
  9.33%   60.351      2 Template:Pagetype
  8.06%   52.150      8 Template:Cite_book
  7.73%   49.985     10 Template:Cite_web
-->

<!-- Saved in parser cache with key enwiki:pcache:87339:|#|:idhash:canonical and timestamp 20260224001537 and revision id 1335953607. Rendering was triggered because: page_view
 -->
</div><noscript><img src="https://en.wikipedia.org/wiki/Special:CentralAutoLogin/start?useformat=desktop&amp;type=1x1&amp;usesul3=1" alt="" width="1" height="1" style="border: none; position: absolute;"></noscript>
<div class="printfooter" data-nosnippet="">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Naive_Bayes_classifier&amp;oldid=1335953607">https://en.wikipedia.org/w/index.php?title=Naive_Bayes_classifier&amp;oldid=1335953607</a>"</div></div>
					<div id="catlinks" class="catlinks" data-mw-interface=""><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Spamming" title="Category:Spamming">Spamming</a></li><li><a href="/wiki/Category:Classification_algorithms" title="Category:Classification algorithms">Classification algorithms</a></li><li><a href="/wiki/Category:Statistical_classification" title="Category:Statistical classification">Statistical classification</a></li><li><a href="/wiki/Category:Bayesian_statistics" title="Category:Bayesian statistics">Bayesian statistics</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:CS1_maint:_archived_copy_as_title" title="Category:CS1 maint: archived copy as title">CS1 maint: archived copy as title</a></li><li><a href="/wiki/Category:All_articles_with_dead_external_links" title="Category:All articles with dead external links">All articles with dead external links</a></li><li><a href="/wiki/Category:Articles_with_dead_external_links_from_February_2018" title="Category:Articles with dead external links from February 2018">Articles with dead external links from February 2018</a></li><li><a href="/wiki/Category:Articles_with_permanently_dead_external_links" title="Category:Articles with permanently dead external links">Articles with permanently dead external links</a></li><li><a href="/wiki/Category:Webarchive_template_wayback_links" title="Category:Webarchive template wayback links">Webarchive template wayback links</a></li><li><a href="/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="/wiki/Category:Short_description_is_different_from_Wikidata" title="Category:Short description is different from Wikidata">Short description is different from Wikidata</a></li></ul></div></div>
				</div>
			</main>
			
		</div>
		<div class="mw-footer-container">
			
<footer id="footer" class="mw-footer" >
	<ul id="footer-info">
	<li id="footer-info-lastmod"> This page was last edited on 1 February 2026, at 03:03<span class="anonymous-show">&#160;(UTC)</span>.</li>
	<li id="footer-info-copyright">Text is available under the <a href="/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License" title="Wikipedia:Text of the Creative Commons Attribution-ShareAlike 4.0 International License">Creative Commons Attribution-ShareAlike 4.0 License</a>;
additional terms may apply. By using this site, you agree to the <a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use" class="extiw" title="foundation:Special:MyLanguage/Policy:Terms of Use">Terms of Use</a> and <a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy" class="extiw" title="foundation:Special:MyLanguage/Policy:Privacy policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a rel="nofollow" class="external text" href="https://wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
</ul>

	<ul id="footer-places">
	<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy">Privacy policy</a></li>
	<li id="footer-places-about"><a href="/wiki/Wikipedia:About">About Wikipedia</a></li>
	<li id="footer-places-disclaimers"><a href="/wiki/Wikipedia:General_disclaimer">Disclaimers</a></li>
	<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
	<li id="footer-places-legal-safety-contacts"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Legal:Wikimedia_Foundation_Legal_and_Safety_Contact_Information">Legal &amp; safety contacts</a></li>
	<li id="footer-places-wm-codeofconduct"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct">Code of Conduct</a></li>
	<li id="footer-places-developers"><a href="https://developer.wikimedia.org">Developers</a></li>
	<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
	<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement">Cookie statement</a></li>
	<li id="footer-places-mobileview"><a href="//en.wikipedia.org/w/index.php?title=Naive_Bayes_classifier&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
</ul>

	<ul id="footer-icons" class="noprint">
	<li id="footer-copyrightico"><a href="https://www.wikimedia.org/" class="cdx-button cdx-button--fake-button cdx-button--size-large cdx-button--fake-button--enabled"><picture><source media="(min-width: 500px)" srcset="/static/images/footer/wikimedia-button.svg" width="84" height="29"><img src="/static/images/footer/wikimedia.svg" width="25" height="25" alt="Wikimedia Foundation" lang="en" loading="lazy"></picture></a></li>
	<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/" class="cdx-button cdx-button--fake-button cdx-button--size-large cdx-button--fake-button--enabled"><picture><source media="(min-width: 500px)" srcset="/w/resources/assets/poweredby_mediawiki.svg" width="88" height="31"><img src="/w/resources/assets/mediawiki_compact.svg" alt="Powered by MediaWiki" lang="en" width="25" height="25" loading="lazy"></picture></a></li>
</ul>

</footer>

		</div>
	</div> 
</div> 
<div class="vector-header-container vector-sticky-header-container no-font-mode-scale">
	<div id="vector-sticky-header" class="vector-sticky-header">
		<div class="vector-sticky-header-start">
			<div class="vector-sticky-header-icon-start vector-button-flush-left" aria-hidden="true">
				<button class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-sticky-header-search-toggle" tabindex="-1" data-event-name="ui.vector-sticky-search-form.icon"><span class="vector-icon mw-ui-icon-search mw-ui-icon-wikimedia-search"></span>

<span>Search</span>
			</button>
		</div>
			
		<div role="search" class="vector-search-box-vue  vector-search-box-show-thumbnail vector-search-box">
			<div class="vector-typeahead-search-container">
				<div class="cdx-typeahead-search cdx-typeahead-search--show-thumbnail">
					<form action="/w/index.php" id="vector-sticky-search-form" class="cdx-search-input cdx-search-input--has-end-button">
						<div  class="cdx-search-input__input-wrapper"  data-search-loc="header-moved">
							<div class="cdx-text-input cdx-text-input--has-start-icon">
								<input
									class="cdx-text-input__input mw-searchInput" autocomplete="off"
									
									type="search" name="search" placeholder="Search Wikipedia">
								<span class="cdx-text-input__icon cdx-text-input__start-icon"></span>
							</div>
							<input type="hidden" name="title" value="Special:Search">
						</div>
						<button class="cdx-button cdx-search-input__end-button">Search</button>
					</form>
				</div>
			</div>
		</div>
		<div class="vector-sticky-header-context-bar">
				<nav aria-label="Contents" class="vector-toc-landmark">
						
					<div id="vector-sticky-header-toc" class="vector-dropdown mw-portlet mw-portlet-sticky-header-toc vector-sticky-header-toc vector-button-flush-left"  >
						<input type="checkbox" id="vector-sticky-header-toc-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-sticky-header-toc" class="vector-dropdown-checkbox "  aria-label="Toggle the table of contents"  >
						<label id="vector-sticky-header-toc-label" for="vector-sticky-header-toc-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-listBullet mw-ui-icon-wikimedia-listBullet"></span>

<span class="vector-dropdown-label-text">Toggle the table of contents</span>
						</label>
						<div class="vector-dropdown-content">
					
						<div id="vector-sticky-header-toc-unpinned-container" class="vector-unpinned-container">
						</div>
					
						</div>
					</div>
			</nav>
				<div class="vector-sticky-header-context-bar-primary" aria-hidden="true" ><span class="mw-page-title-main">Naive Bayes classifier</span></div>
			</div>
		</div>
		<div class="vector-sticky-header-end" aria-hidden="true">
			<div class="vector-sticky-header-icons">
				<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only" id="ca-talk-sticky-header" tabindex="-1" data-event-name="talk-sticky-header"><span class="vector-icon mw-ui-icon-speechBubbles mw-ui-icon-wikimedia-speechBubbles"></span>

<span></span>
			</a>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only" id="ca-subject-sticky-header" tabindex="-1" data-event-name="subject-sticky-header"><span class="vector-icon mw-ui-icon-article mw-ui-icon-wikimedia-article"></span>

<span></span>
			</a>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only" id="ca-history-sticky-header" tabindex="-1" data-event-name="history-sticky-header"><span class="vector-icon mw-ui-icon-wikimedia-history mw-ui-icon-wikimedia-wikimedia-history"></span>

<span></span>
			</a>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only mw-watchlink" id="ca-watchstar-sticky-header" tabindex="-1" data-event-name="watch-sticky-header"><span class="vector-icon mw-ui-icon-wikimedia-star mw-ui-icon-wikimedia-wikimedia-star"></span>

<span></span>
			</a>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only" id="ca-edit-sticky-header" tabindex="-1" data-event-name="wikitext-edit-sticky-header"><span class="vector-icon mw-ui-icon-wikimedia-wikiText mw-ui-icon-wikimedia-wikimedia-wikiText"></span>

<span></span>
			</a>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only" id="ca-ve-edit-sticky-header" tabindex="-1" data-event-name="ve-edit-sticky-header"><span class="vector-icon mw-ui-icon-wikimedia-edit mw-ui-icon-wikimedia-wikimedia-edit"></span>

<span></span>
			</a>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only" id="ca-viewsource-sticky-header" tabindex="-1" data-event-name="ve-edit-protected-sticky-header"><span class="vector-icon mw-ui-icon-wikimedia-editLock mw-ui-icon-wikimedia-wikimedia-editLock"></span>

<span></span>
			</a>
		</div>
			<div class="vector-sticky-header-buttons">
				<button class="cdx-button cdx-button--weight-quiet mw-interlanguage-selector" id="p-lang-btn-sticky-header" tabindex="-1" data-event-name="ui.dropdown-p-lang-btn-sticky-header"><span class="vector-icon mw-ui-icon-wikimedia-language mw-ui-icon-wikimedia-wikimedia-language"></span>

<span>24 languages</span>
			</button>
			<a href="#" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--action-progressive" id="ca-addsection-sticky-header" tabindex="-1" data-event-name="addsection-sticky-header"><span class="vector-icon mw-ui-icon-speechBubbleAdd-progressive mw-ui-icon-wikimedia-speechBubbleAdd-progressive"></span>

<span>Add topic</span>
			</a>
		</div>
			<div class="vector-sticky-header-icon-end">
				<div class="vector-user-links">
				</div>
			</div>
		</div>
	</div>
</div>
<div class="mw-portlet mw-portlet-dock-bottom emptyPortlet" id="p-dock-bottom">
	<ul>
		
	</ul>
</div>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgHostname":"mw-web.eqiad.main-6f597bcf-cb6lm","wgBackendResponseTime":164,"wgPageParseReport":{"limitreport":{"cputime":"0.756","walltime":"0.990","ppvisitednodes":{"value":3536,"limit":1000000},"revisionsize":{"value":51112,"limit":2097152},"postexpandincludesize":{"value":92943,"limit":2097152},"templateargumentsize":{"value":2523,"limit":2097152},"expansiondepth":{"value":17,"limit":100},"expensivefunctioncount":{"value":2,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":144670,"limit":5000000},"entityaccesscount":{"value":0,"limit":500},"timingprofile":["100.00%  646.731      1 -total"," 56.60%  366.058      1 Template:Reflist"," 21.93%  141.817      6 Template:Cite_journal"," 13.77%   89.081      1 Template:Spamming"," 13.56%   87.685      2 Template:Navbox"," 12.92%   83.551      1 Template:Short_description"," 10.11%   65.359     11 Template:Cite_conference","  9.33%   60.351      2 Template:Pagetype","  8.06%   52.150      8 Template:Cite_book","  7.73%   49.985     10 Template:Cite_web"]},"scribunto":{"limitreport-timeusage":{"value":"0.406","limit":"10.000"},"limitreport-memusage":{"value":6648731,"limit":52428800}},"cachereport":{"origin":"mw-web.eqiad.main-6f597bcf-c9l75","timestamp":"20260224001537","ttl":85472,"transientcontent":true}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Naive Bayes classifier","url":"https:\/\/en.wikipedia.org\/wiki\/Naive_Bayes_classifier","sameAs":"http:\/\/www.wikidata.org\/entity\/Q812530","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q812530","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2002-09-18T18:29:12Z","dateModified":"2026-02-01T03:03:53Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/d\/de\/Naive_corral.png","headline":"classification algorithm"}</script>
</body>
</html>